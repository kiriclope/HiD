{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e8f4ac92-0768-47fd-b1de-f666016f1883",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "58ce5437-cc52-496f-a409-a4b7fe607cf9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files from /home/leon/bebopalula/python/dual/data/AP12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg noise over trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sample_odor  dist_odor     tasks   response  laser  day\n",
      "0          1.0        0.0       DPA  incorrect    0.0  1.0\n",
      "1          0.0        0.0       0.0    correct    0.0  1.0\n",
      "2          3.0        4.0  DualNoGo  incorrect    0.0  1.0\n",
      "3          0.0        3.0  DualNoGo  incorrect    0.0  1.0\n",
      "4          2.0        1.0    DualGo    correct    0.0  1.0\n",
      "features sample tasks DualGo trials  days last laser 0\n",
      "X_S1 (64, 741, 115) X_S2 (64, 741, 115)\n",
      "X_S3 (0, 741, 115) X_S4 (0, 741, 115)\n",
      "X (128, 741, 115) y (128,)\n"
     ]
    }
   ],
   "source": [
    "from common.options import set_options\n",
    "from data.get_data import get_X_y_days, get_X_y_S1_S2\n",
    "\n",
    "options = set_options()\n",
    "options['multilabel'] = False\n",
    "options['task'] = 'DualGo'\n",
    "\n",
    "X_days, y_days = get_X_y_days(IF_PREP=1)\n",
    "print(y_days.head())\n",
    "X_S1_S2, y_S1_S2 = get_X_y_S1_S2(X_days, y_days, **options)\n",
    "\n",
    "print('X', X_S1_S2.shape, 'y', y_S1_S2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1ce31a41-2ab1-4af9-b4e3-e69672ec50e2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def array_to_ts(data, batch, length):\n",
    "\n",
    "  out = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    data= data[:-10],    \n",
    "    targets= data[10:],    \n",
    "    sequence_length=length,\n",
    "    sequence_stride=1,\n",
    "    shuffle=False,\n",
    "    batch_size=batch-1)\n",
    "  \n",
    "  return out\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "993e56a1-05cb-43a0-afd9-30c7eb8e620e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prep_df(df):\n",
    "\n",
    "  print('df', df.shape)\n",
    "  batch = df.shape[0]\n",
    "  neurons = df.shape[1]\n",
    "  length = df.shape[-1]\n",
    "  \n",
    "  print('batch', batch, 'length', length)\n",
    "  X = np.vstack(np.swapaxes(df, 1, 2))\n",
    "  print('X', X.shape)\n",
    "  tf_X = array_to_ts(X, batch, length)\n",
    "\n",
    "  return tf_X\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "57e2e495-cd06-4387-8502-0a73d64b88f8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "df (80, 741, 115)\n",
      "batch 80 length 115\n",
      "X (9200, 741)\n",
      "df (23, 741, 115)\n",
      "batch 23 length 115\n",
      "X (2645, 741)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, None, 741), dtype=tf.float64, name=None), TensorSpec(shape=(None, 741), dtype=tf.float64, name=None))\n",
      "(TensorSpec(shape=(None, None, 741), dtype=tf.float64, name=None), TensorSpec(shape=(None, 741), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "n = X_S1_S2.shape[-1]\n",
    "print(n)\n",
    "df_train = X_S1_S2[0:int(n*0.7)]\n",
    "df_val = X_S1_S2[int(n*0.7):int(n*0.9)]\n",
    "\n",
    "tf_train = prep_df(df_train)\n",
    "tf_val = prep_df(df_val)\n",
    "\n",
    "print(tf_train.element_spec)\n",
    "print(tf_val.element_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "f38a6a35-81a4-4bd0-a6a3-7f2fd305e113",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorDataset element_spec=TensorSpec(shape=(80, 115, 741), dtype=tf.float64, name=None)>\n",
      "<TensorDataset element_spec=TensorSpec(shape=(23, 115, 741), dtype=tf.float64, name=None)>\n"
     ]
    }
   ],
   "source": [
    "tf_train = tf.data.Dataset.from_tensors(np.swapaxes(df_train[..., :-10], 1, 2))\n",
    "tf_val = tf.data.Dataset.from_tensors(np.swapaxes(df_val[..., :-10], 1, 2))\n",
    "print(tf_train)\n",
    "print(tf_val)\n",
    "\n",
    "y_train = tf.data.Dataset.from_tensors(np.swapaxes(df_train[..., 10:], 1, 2))\n",
    "y_val = tf.data.Dataset.from_tensors(np.swapaxes(df_val[...,10:], 1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "db0efc31-4a24-4178-9707-7280089483cd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 741, 115)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "41a5f335-3f49-4e5c-b9a3-707f9315c208",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "train = np.hstack(np.vstack(df_train.T))\n",
    "val = np.hstack(np.vstack(df_val.T))\n",
    "\n",
    "gen_train = TimeseriesGenerator(train, train, length=115, batch_size=80)\n",
    "gen_val = TimeseriesGenerator(val, val, length=115, batch_size=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c0c60f9a-9710-4e92-a0c7-a0889b2cdeb5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n"
     ]
    }
   ],
   "source": [
    "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95, 105])\n",
    "# reshape series\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2))\n",
    "\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7f4ab03a-4ec7-4f43-9f60-cd8770f4a8bb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lstm_22 (LSTM)              (None, 115, 741)          4395612   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_22 (Dense)            (None, 115, 741)          549822    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 4,945,434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 4,945,434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(units=741, return_sequences= True, input_shape=(115, neurons)))\n",
    "model.add(tf.keras.layers.Dense(units=741))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "fb7b18a1-f25b-49fc-ad30-9598cbf507ba",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                   optimizer=tf.keras.optimizers.Adam(),\n",
    "                   metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "041e73a0-4ffe-4e97-a051-1fca45736f7e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/leon/mambaforge/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/leon/mambaforge/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/leon/mambaforge/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/leon/mambaforge/lib/python3.8/site-packages/keras/engine/training.py\", line 1025, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"/home/leon/mambaforge/lib/python3.8/site-packages/keras/engine/training.py\", line 979, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: Target data is missing. Your model was compiled with loss=<keras.losses.MeanSquaredError object at 0x7fa6877d1a90>, and therefore expects target data to be provided in `fit()`.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[257], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file0l7jl2rt.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/leon/mambaforge/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/leon/mambaforge/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/leon/mambaforge/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/leon/mambaforge/lib/python3.8/site-packages/keras/engine/training.py\", line 1025, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"/home/leon/mambaforge/lib/python3.8/site-packages/keras/engine/training.py\", line 979, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: Target data is missing. Your model was compiled with loss=<keras.losses.MeanSquaredError object at 0x7fa6877d1a90>, and therefore expects target data to be provided in `fit()`.\n"
     ]
    }
   ],
   "source": [
    "model.fit(tf_train, validation_data=tf_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb2008-8cbf-4e86-98de-906dbd374d6c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # Store the raw data.\n",
    "    print('df', df.shape)\n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "    \n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    n = df.shape[0]\n",
    "    self.train = tf.convert_to_tensor(df[0:int(n*0.7)])\n",
    "    self.val = tf.convert_to_tensor(df[int(n*0.7):int(n*0.9)])\n",
    "    self.test = tf.convert_to_tensor(df[int(n*0.9):])\n",
    "\n",
    "    return self\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/home/leon/mambaforge/bin/python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "name": "mvtsforcast.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
