#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session decoder :kernel dual_data :exports results :output-dir ./figures/landscape :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python

* Imports
#+begin_src ipython
  from sklearn.exceptions import ConvergenceWarning
  warnings.filterwarnings("ignore")

  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import os
  if not sys.warnoptions:
    warnings.simplefilter("ignore")
    os.environ["PYTHONWARNINGS"] = "ignore"

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  import pandas as pd

  from time import perf_counter

  from sklearn.base import clone
  from sklearn.metrics import make_scorer, roc_auc_score
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.model_selection import RepeatedStratifiedKFold, LeaveOneOut, StratifiedKFold

  from src.common.plot_utils import add_vlines, add_vdashed
  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.preprocess.helpers import avg_epochs

  from src.torch.classificationCV import ClassificationCV
  from src.torch.main import get_classification
#+end_src

#+RESULTS:

* Helpers
#+begin_src ipython
def pad_with_nans(array, target_shape):
    result = np.full(target_shape, np.nan)  # Create an array filled with NaNs
    print(result.shape)
    slices = tuple(slice(0, min(dim, target)) for dim, target in zip(array.shape, target_shape))
    result[slices] = array[slices]
    return result
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import numpy as np

  def safe_roc_auc_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return np.nan  # return np.nan where the score cannot be calculated
      return roc_auc_score(y_true, y_score)
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def rescale_coefs(model, coefs, bias):

          try:
                  means = model.named_steps["scaler"].mean_
                  scales = model.named_steps["scaler"].scale_

                  # Rescale the coefficients
                  rescaled_coefs = np.true_divide(coefs, scales)

                  # Adjust the intercept
                  rescaled_bias = bias - np.sum(rescaled_coefs * means)

                  return rescaled_coefs, rescaled_bias
          except:
                  return coefs, bias

#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  from scipy.stats import bootstrap

  def get_bootstrap_ci(data, statistic=np.mean, confidence_level=0.95, n_resamples=1000, random_state=None):
      result = bootstrap((data,), statistic)
      ci_lower, ci_upper = result.confidence_interval
      return np.array([ci_lower, ci_upper])
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      return pkl.load(open(path + "/" + name + '.pkl', "rb"))

#+end_src

#+RESULTS:

* Parameters

#+begin_src ipython
  DEVICE = 'cuda:0'
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  N_NEURONS = [668, 693, 444, 361, 113]

  tasks = ['DPA', 'DualGo', 'DualNoGo']
  params = { 'net__alpha': np.logspace(-4, 4, 10),
             # 'net__l1_ratio': np.linspace(0, 1, 10),
             # 'net__module__dropout_rate': np.linspace(0, 1, 10),
            }

  # ['AP02', 'AP12', 'PP09', 'PP17', 'RP17']

  kwargs = {
      'mouse': 'ACCM04', 'laser': 0,
      'trials': '', 'reload': 0, 'data_type': 'dF',
      'prescreen': None, 'pval': 0.05,
      'preprocess': False, 'scaler_BL': 'robust',
      'avg_noise':True, 'unit_var_BL': True,
      'random_state': None, 'T_WINDOW': 0.0,
      'l1_ratio': 0.95,
      'n_comp': None, 'scaler': None,
      'bootstrap': 1, 'n_boots': 128,
      'n_splits': 3, 'n_repeats': 32,
      'class_weight': 0,
      'multilabel':0,
  }

  kwargs['days'] = ['first', 'middle', 'last']
  options = set_options(**kwargs)
  # days = np.arange(1, options['n_days']+1)
  days = ['first', 'middle', 'last']

  safe_roc_auc = make_scorer(safe_roc_auc_score, needs_proba=True)
  options['hp_scoring'] = safe_roc_auc
  options['n_jobs'] = 30
#+end_src

#+RESULTS:

#+begin_src ipython
def overlaps_scorer(estimator, X_test, y_test, IF_SIGN=0):
    coef = estimator.named_steps["net"].coef_.flatten()
    if IF_SIGN:
        dot_product = (2*y_test -1) * np.dot(X_test, coef) / np.linalg.norm(coef)
    else:
        dot_product = -np.dot(X_test, coef) / np.linalg.norm(coef)

    return dot_product.mean()


options['scoring'] = overlaps_scorer
# options['hp_scoring'] = 'overlaps_scorer'
#+end_src

#+RESULTS:

#+begin_src ipython
def signed_overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1):
    coef = estimator.named_steps["net"].coef_.flatten()
    if IF_SIGN:
        dot_product = (2*y_test -1) * np.dot(X_test, coef) / np.linalg.norm(coef)
    else:
        dot_product = -np.dot(X_test, coef) / np.linalg.norm(coef)

    return dot_product.mean()


options['scoring'] = overlaps_scorer
# options['hp_scoring'] = 'overlaps_scorer'
#+end_src

#+RESULTS:

* Decoding vs days
** Model

#+begin_src ipython
from sklearn.linear_model import LogisticRegression
# net = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', n_jobs=None)
net = LogisticRegression(penalty='elasticnet', solver='saga', class_weight='balanced', n_jobs=None, l1_ratio=0.95, max_iter=100, tol=.001)
# net = LogisticRegression(penalty='elasticnet', solver='saga', class_weight='balanced', n_jobs=None, l1_ratio=0.95, max_iter=100, tol=.001, multi_class='multinomial')

params = {'net__C': np.logspace(-4, 4, 10)}

options['n_jobs'] = -1
options['verbose'] = 0
model = ClassificationCV(net, params, **options)
options['verbose'] = 1
options['cv'] = LeaveOneOut()
#+end_src

#+RESULTS:

** Sample Overlap
*** overlaps
#+begin_src ipython
overlaps_sample = []
options['features'] = 'sample'
options['epochs'] = ['ED']
options['scoring'] = signed_overlaps_scorer

tasks = ['DPA', 'DualGo', 'DualNoGo']
for task in tasks:
    options['task'] = task
    overlaps_sample_task = []
    dum = 0
    for day in days:
        options['day'] = day
        overlaps = get_classification(model, RETURN='scores', **options)

        if dum==1:
            overlaps = pad_with_nans(overlaps, overlaps_sample_task[-1].shape)

        overlaps_sample_task.append(overlaps)
        dum=1

    overlaps_sample.append(overlaps_sample_task)
   #+end_src

#+RESULTS:
#+begin_example
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS first LASER 0
multiple days 0 2 2
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
X (128, 113, 84) y (128,) [0. 1.]
X_test==X_train
scores (128, 84, 84)
scores (128, 84, 84)
Elapsed (with compilation) = 0h 0m 17s
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS middle LASER 0
multiple days 0 2 2
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
X (128, 113, 84) y (128,) [0. 1.]
X_test==X_train
scores (128, 84, 84)
scores (128, 84, 84)
Elapsed (with compilation) = 0h 0m 17s
(128, 84, 84)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS last LASER 0
multiple days 0 2 2
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
scores (64, 84, 84)
Elapsed (with compilation) = 0h 0m 13s
(128, 84, 84)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DualGo TRIALS  DAYS first LASER 0
multiple days 0 2 2
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
X (128, 113, 84) y (128,) [0. 1.]
X_test==X_train
scores (128, 84, 84)
scores (128, 84, 84)
Elapsed (with compilation) = 0h 0m 16s
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DualGo TRIALS  DAYS middle LASER 0
multiple days 0 2 2
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
X (128, 113, 84) y (128,) [0. 1.]
X_test==X_train
scores (128, 84, 84)
scores (128, 84, 84)
Elapsed (with compilation) = 0h 0m 16s
(128, 84, 84)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DualGo TRIALS  DAYS last LASER 0
multiple days 0 2 2
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
scores (64, 84, 84)
Elapsed (with compilation) = 0h 0m 11s
(128, 84, 84)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS first LASER 0
multiple days 0 2 2
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
X (128, 113, 84) y (128,) [0. 1.]
X_test==X_train
scores (128, 84, 84)
scores (128, 84, 84)
Elapsed (with compilation) = 0h 0m 16s
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS middle LASER 0
multiple days 0 2 2
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
X (128, 113, 84) y (128,) [0. 1.]
X_test==X_train
scores (128, 84, 84)
scores (128, 84, 84)
Elapsed (with compilation) = 0h 0m 16s
(128, 84, 84)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS last LASER 0
multiple days 0 2 2
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
scores (64, 84, 84)
Elapsed (with compilation) = 0h 0m 12s
(128, 84, 84)
#+end_example

     #+begin_src ipython
print(np.array(overlaps_sample[0]).shape)
print(np.array(overlaps_sample[1]).shape)
print(np.array(overlaps_sample[2]).shape)
   #+end_src

#+RESULTS:
: (3, 128, 84, 84)
: (3, 128, 84, 84)
: (3, 128, 84, 84)

#+begin_src ipython
sample_overlaps = np.stack((overlaps_sample[0], overlaps_sample[1], overlaps_sample[2],), axis=2)
print(sample_overlaps.shape)
#+end_src

#+RESULTS:
: (3, 128, 3, 84, 84)

#+begin_src ipython
name = 'sample_overlaps'
pkl_save(sample_overlaps, '%s_%s' % (options['mouse'], name), path="../data/%s/overlaps" % options['mouse'])
#+end_src

#+RESULTS:
: saving to ../data/ACCM04/overlaps/ACCM04_sample_overlaps.pkl

*** labels
#+begin_src ipython
labels_sample = []
options['features'] = 'sample'
options['epochs'] = ['ED']
options['scoring'] = signed_overlaps_scorer

tasks = ['DPA', 'DualGo', 'DualNoGo']
for task in tasks:
    options['task'] = task
    labels_sample_task = []
    dum = 0
    for day in days:
        options['day'] = day
        labels = get_classification(model, RETURN='labels', **options)

        # if dum==1:
        #     labels = pad_with_nans(labels, labels_sample_task[-1].shape)
        if (day == 'last') and ('ACC' in options['mouse']):
            labels = pd.concat((labels, labels))
        labels_sample_task.append(labels)
        dum=1

    labels_sample.append(labels_sample_task)
   #+end_src

#+RESULTS:
#+begin_example
multiple days 0 2 2
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
multiple days 0 2 2
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
multiple days 0 2 2
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
multiple days 0 2 2
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
multiple days 0 2 2
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
multiple days 0 2 2
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
multiple days 0 2 2
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
multiple days 0 2 2
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
multiple days 0 2 2
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
#+end_example

#+begin_src ipython
df = []
for i in range(len(tasks)):
    for j in range(len(days)):
        df.append(labels_sample[i][j])
df_sample = pd.concat(df).reset_index()
print(df_sample.shape)
print(df_sample.head())
#+end_src

#+RESULTS:
#+begin_example
(1152, 9)
   index  sample_odor  test_odor      response tasks  laser  day  dist_odor  \
0      6          0.0        0.0   correct_hit   DPA    0.0  1.0        NaN
1      9          0.0        0.0   correct_hit   DPA    0.0  1.0        NaN
2     10          0.0        1.0  incorrect_fa   DPA    0.0  1.0        NaN
3     18          0.0        1.0  incorrect_fa   DPA    0.0  1.0        NaN
4     26          0.0        1.0  incorrect_fa   DPA    0.0  1.0        NaN

   choice
0     1.0
1     1.0
2     1.0
3     1.0
4     1.0
#+end_example

#+begin_src ipython
name = '%s_sample_overlaps' % options['mouse']
sample_overlaps = pkl_load(name, path="../data/%s/overlaps" % options['mouse'])
print(sample_overlaps.reshape(-1, 84, 84).shape)
#+end_src

#+RESULTS:
: (1152, 84, 84)

#+begin_src ipython
scores_diag = np.diagonal(sample_overlaps, axis1=-2, axis2=-1)
print(scores_diag.shape)
reshaped_scores = scores_diag.reshape(-1, 84).tolist()
df_diag = pd.DataFrame({'overlaps_diag': reshaped_scores})
print(df_diag.shape)
print(df_diag.head())
#+end_src

#+RESULTS:
: (3, 128, 3, 84)
: (1152, 1)
:                                        overlaps_diag
: 0  [-0.17198432981967926, 0.2414817363023758, 0.1...
: 1  [-0.21350054442882538, 0.12840549647808075, 0....
: 2  [0.07649800926446915, 0.00802299752831459, 0.0...
: 3  [0.06410852074623108, 0.17648139595985413, 0.2...
: 4  [-0.1557382196187973, -0.14372573792934418, 0....

#+begin_src ipython
scores_MD = np.swapaxes(sample_overlaps.copy(), -1, -2)
options['epochs'] = ['ED']
scores_MD = avg_epochs(scores_MD, **options)
print(scores_MD.shape)
reshaped_scores = scores_MD.reshape(-1, 84).tolist()
df_MD = pd.DataFrame({'overlaps_ED': reshaped_scores})
print(df_MD.shape)
print(df_MD.head())
#+end_src

#+RESULTS:
: (3, 128, 3, 84)
: (1152, 1)
:                                          overlaps_ED
: 0  [0.11371712386608124, 0.05915814341278747, 0.0...
: 1  [0.10189793507258098, 0.07579134259786871, 0.0...
: 2  [0.05394936205508808, 0.11763202336927255, -0....
: 3  [-0.09181576139397091, 0.04750561569299963, 0....
: 4  [0.23679555786980522, -0.000536787323653698, 0...

#+begin_src ipython
df_scores = pd.concat([df_diag, df_MD], axis=1)
print(df_scores.shape)
print(df_scores.head())
#+end_src

#+RESULTS:
#+begin_example
(1152, 2)
                                       overlaps_diag  \
0  [-0.17198432981967926, 0.2414817363023758, 0.1...
1  [-0.21350054442882538, 0.12840549647808075, 0....
2  [0.07649800926446915, 0.00802299752831459, 0.0...
3  [0.06410852074623108, 0.17648139595985413, 0.2...
4  [-0.1557382196187973, -0.14372573792934418, 0....

                                         overlaps_ED
0  [0.11371712386608124, 0.05915814341278747, 0.0...
1  [0.10189793507258098, 0.07579134259786871, 0.0...
2  [0.05394936205508808, 0.11763202336927255, -0....
3  [-0.09181576139397091, 0.04750561569299963, 0....
4  [0.23679555786980522, -0.000536787323653698, 0...
#+end_example

#+begin_src ipython
df_sample = pd.concat((df_sample, df_scores), axis=1)
print(df_sample.shape)
#+end_src

#+RESULTS:
: (1152, 11)

#+begin_src ipython
name = 'df_sample_overlaps'
pkl_save(df_sample, '%s_%s' % (options['mouse'], name), path="../data/%s/overlaps" % options['mouse'])
#+end_src

#+RESULTS:
: saving to ../data/ACCM04/overlaps/ACCM04_df_sample_overlaps.pkl

** Distractor overlap
*** overlaps
#+begin_src ipython
  overlaps_dist = []
  options['features'] = 'distractor'
  options['epochs'] = ['MD']
  options['scoring'] = overlaps_scorer

  tasks = ['DPA', 'Dual']
  for task in tasks:
    options['task'] = task

    overlaps_dist_task = []
    dum=0
    for day in days:
        options['day'] = day

        overlaps = get_classification(model, RETURN='scores', **options)

        if dum==1:
            overlaps = pad_with_nans(overlaps, overlaps_dist_task[-1].shape)

        overlaps_dist_task.append(overlaps)
        dum = 1
        options['reload'] = 0

    overlaps_dist.append(overlaps_dist_task)
    #+end_src

    #+RESULTS:
    #+begin_example
    Loading files from /home/leon/dual_task/dual_data/data/ACCM04
    DATA: FEATURES sample TASK DPA TRIALS  DAYS first LASER 0
    multiple days 0 2 2
    X_S1 (64, 113, 84) X_S2 (64, 113, 84)
    X_test (128, 113, 84) y_test (128,)
    DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
    multiple days 0 2 2
    X_S1 (128, 113, 84) X_S2 (128, 113, 84)
    X (256, 113, 84) y (256,) [0. 1. 2. 3.]
    scores (128, 84, 84)
    scores (128, 1, 84, 84)
    Elapsed (with compilation) = 0h 0m 21s
    Loading files from /home/leon/dual_task/dual_data/data/ACCM04
    DATA: FEATURES sample TASK DPA TRIALS  DAYS middle LASER 0
    multiple days 0 2 2
    X_S1 (64, 113, 84) X_S2 (64, 113, 84)
    X_test (128, 113, 84) y_test (128,)
    DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
    multiple days 0 2 2
    X_S1 (128, 113, 84) X_S2 (128, 113, 84)
    X (256, 113, 84) y (256,) [0. 1. 2. 3.]scores (128, 84, 84)
    scores (128, 1, 84, 84)
    Elapsed (with compilation) = 0h 0m 21s
    (128, 1, 84, 84)
    Loading files from /home/leon/dual_task/dual_data/data/ACCM04
    DATA: FEATURES sample TASK DPA TRIALS  DAYS last LASER 0
    multiple days 0 2 2
    X_S1 (32, 113, 84) X_S2 (32, 113, 84)
    X_test (64, 113, 84) y_test (64,)
    DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
    multiple days 0 2 2
    X_S1 (64, 113, 84) X_S2 (64, 113, 84)
    X (128, 113, 84) y (128,) [0. 1. 2. 3.]
    scores (64, 84, 84)
    scores (64, 1, 84, 84)
    Elapsed (with compilation) = 0h 0m 13s
    (128, 1, 84, 84)
    Loading files from /home/leon/dual_task/dual_data/data/ACCM04
    DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
    multiple days 0 2 2
    X_S1 (128, 113, 84) X_S2 (128, 113, 84)
    X (256, 113, 84) y (256,) [0. 1. 2. 3.]
    X_test==X_train
    scores (256, 84, 84)
    scores (128, 2, 84, 84)
    Elapsed (with compilation) = 0h 0m 28s
    Loading files from /home/leon/dual_task/dual_data/data/ACCM04
    DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
    multiple days 0 2 2
    X_S1 (128, 113, 84) X_S2 (128, 113, 84)
    X (256, 113, 84) y (256,) [0. 1. 2. 3.]
    X_test==X_train
    scores (256, 84, 84)
    scores (128, 2, 84, 84)
    Elapsed (with compilation) = 0h 0m 21s
    (128, 2, 84, 84)
    Loading files from /home/leon/dual_task/dual_data/data/ACCM04
    DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
    multiple days 0 2 2
    X_S1 (64, 113, 84) X_S2 (64, 113, 84)
    X (128, 113, 84) y (128,) [0. 1. 2. 3.]
    X_test==X_train
    scores (128, 84, 84)
    scores (64, 2, 84, 84)
    Elapsed (with compilation) = 0h 0m 16s
    (128, 2, 84, 84)
    #+end_example

    #+begin_src ipython
distractor_overlaps = np.concatenate((np.array(overlaps_dist[0]), np.array(overlaps_dist[1])), axis=2)
print(distractor_overlaps.shape)
#+end_src

#+RESULTS:
: (3, 128, 3, 84, 84)

#+begin_src ipython
name = 'distractor_overlaps'
pkl_save(distractor_overlaps, '%s_%s' % (options['mouse'], name), path="../data/%s/overlaps" % options['mouse'])
#+end_src

#+RESULTS:
: saving to ../data/ACCM04/overlaps/ACCM04_distractor_overlaps.pkl

*** labels
#+begin_src ipython
  labels_dist = []
  options['features'] = 'distractor'
  options['epochs'] = ['MD']
  options['scoring'] = overlaps_scorer

  tasks = ['DPA', 'Dual']
  for task in tasks:
    options['task'] = task

    labels_dist_task = []
    dum=0
    for day in days:
        options['day'] = day

        labels = get_classification(model, RETURN='labels', **options)
        if (day == 'last') and ('ACC' in options['mouse']):
            labels = pd.concat((labels, labels))
        # if dum==1:
        #     labels = pad_with_nans(labels, labels_dist_task[-1].shape)
        # if day=='last':
        #     labels = np.
        labels_dist_task.append(labels)

        dum = 1
        options['reload'] = 0

    labels_dist.append(labels_dist_task)
    #+end_src

    #+RESULTS:
    #+begin_example
    multiple days 0 2 2
    X_S1 (64, 113, 84) X_S2 (64, 113, 84)
    X_test (128, 113, 84) y_test (128,)
    multiple days 0 2 2
    X_S1 (128, 113, 84) X_S2 (128, 113, 84)
    multiple days 0 2 2
    X_S1 (64, 113, 84) X_S2 (64, 113, 84)
    X_test (128, 113, 84) y_test (128,)
    multiple days 0 2 2
    X_S1 (128, 113, 84) X_S2 (128, 113, 84)
    multiple days 0 2 2
    X_S1 (32, 113, 84) X_S2 (32, 113, 84)
    X_test (64, 113, 84) y_test (64,)
    multiple days 0 2 2
    X_S1 (64, 113, 84) X_S2 (64, 113, 84)
    multiple days 0 2 2X_S1 (128, 113, 84) X_S2 (128, 113, 84)
    multiple days 0 2 2
    X_S1 (128, 113, 84) X_S2 (128, 113, 84)
    multiple days 0 2 2
    X_S1 (64, 113, 84) X_S2 (64, 113, 84)
    #+end_example

#+begin_src ipython
df = []
for i in range(len(tasks)):
    for j in range(len(days)):
        # print(labels_dist[i][j].shape)
        # print(np.vstack(overlaps_dist[i][j]).shape)
        # labels_dist[i][j]['overlaps'] = overlaps_dist[i][j][:labels_dist[i][j].shape[0]]
        df.append(labels_dist[i][j])
df_distractor = pd.concat(df).reset_index()
print(df_distractor.shape)
print(df_distractor.head())
#+end_src

#+RESULTS:
#+begin_example
(1152, 9)
   index  sample_odor  test_odor      response tasks  laser  day  dist_odor  \
0      6          0.0        0.0   correct_hit   DPA    0.0  1.0        NaN
1      9          0.0        0.0   correct_hit   DPA    0.0  1.0        NaN
2     10          0.0        1.0  incorrect_fa   DPA    0.0  1.0        NaN
3     18          0.0        1.0  incorrect_fa   DPA    0.0  1.0        NaN
4     26          0.0        1.0  incorrect_fa   DPA    0.0  1.0        NaN

   choice
0     1.0
1     1.0
2     1.0
3     1.0
4     1.0
#+end_example

#+begin_src ipython
name = '%s_distractor_overlaps' % options['mouse']
distractor_overlaps = pkl_load(name, path="../data/%s/overlaps" % options['mouse'])
print(distractor_overlaps.reshape(-1, 84, 84).shape)
#+end_src

#+RESULTS:
: (1152, 84, 84)

#+begin_src ipython
scores_diag = np.diagonal(distractor_overlaps, axis1=-2, axis2=-1)
print(scores_diag.shape)
reshaped_scores = scores_diag.reshape(-1, 84).tolist()
df_diag = pd.DataFrame({'overlaps_diag': reshaped_scores})
print(df_diag.shape)
#print(df_diag.head())
#+end_src

#+RESULTS:
: (3, 128, 3, 84)
: (1152, 1)

#+begin_src ipython
scores_MD = np.swapaxes(distractor_overlaps.copy(), -1, -2)
options['epochs'] = ['MD']
scores_MD = avg_epochs(scores_MD, **options)
print(scores_MD.shape)
reshaped_scores = scores_MD.reshape(-1, 84).tolist()
df_MD = pd.DataFrame({'overlaps_MD': reshaped_scores})
print(df_MD.shape)
#print(df_MD.head())
#+end_src

#+RESULTS:
: (3, 128, 3, 84)
: (1152, 1)
:

#+begin_src ipython
df_scores = pd.concat([df_diag, df_MD], axis=1)
print(df_scores.shape)
# print(df_scores.head())
#+end_src

#+RESULTS:
: (1152, 2)

#+begin_src ipython
df_distractor = pd.concat((df_distractor, df_scores), axis=1)
print(df_distractor.shape)
#+end_src

#+RESULTS:
: (1152, 11)

#+begin_src ipython
name = 'df_distractor_overlaps'
pkl_save(df_distractor, '%s_%s' % (options['mouse'], name), path="../data/%s/overlaps" % options['mouse'])
#+end_src

#+RESULTS:
: saving to ../data/ACCM04/overlaps/ACCM04_df_distractor_overlaps.pkl


* Pickle
** Sample dfs
#+begin_src ipython
dfs = []

for mouse in options['mice']:
    name = '%s_df_sample_overlaps' % options['mouse']
    df = pkl_load(name, path="../data/%s/overlaps" % options['mouse'])
    df['mouse'] = mouse

    dfs.append(df)

dfs = pd.concat(dfs)
dfs['behavior'] = dfs['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
dfs['pair'] = dfs['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)

print(dfs.head())
#+end_src

#+RESULTS:
#+begin_example
   index  sample_odor  test_odor      response tasks  laser  day  dist_odor  \
0      6          0.0        0.0   correct_hit   DPA    0.0  1.0        NaN
1      9          0.0        0.0   correct_hit   DPA    0.0  1.0        NaN
2     10          0.0        1.0  incorrect_fa   DPA    0.0  1.0        NaN
3     18          0.0        1.0  incorrect_fa   DPA    0.0  1.0        NaN
4     26          0.0        1.0  incorrect_fa   DPA    0.0  1.0        NaN

   choice                                      overlaps_diag  \
0     1.0  [-0.17198432981967926, 0.2414817363023758, 0.1...
1     1.0  [-0.21350054442882538, 0.12840549647808075, 0....
2     1.0  [0.07649800926446915, 0.00802299752831459, 0.0...
3     1.0  [0.06410852074623108, 0.17648139595985413, 0.2...
4     1.0  [-0.1557382196187973, -0.14372573792934418, 0....

                                         overlaps_ED   mouse
0  [0.11371712386608124, 0.05915814341278747, 0.0...  ChRM04
1  [0.10189793507258098, 0.07579134259786871, 0.0...  ChRM04
2  [0.05394936205508808, 0.11763202336927255, -0....  ChRM04
3  [-0.09181576139397091, 0.04750561569299963, 0....  ChRM04
4  [0.23679555786980522, -0.000536787323653698, 0...  ChRM04
#+end_example

#+begin_src ipython
name = 'df_sample_mice'
pkl_save(dfs, name, path="../data/overlaps")
#+end_src

#+RESULTS:
: saving to ../data/overlaps/df_sample_mice.pkl

** distractor dfs
*** data

#+begin_src ipython
dfs = []

for mouse in options['mice']:
    name = '%s_df_distractor_overlaps' % options['mouse']
    df = pkl_load(name, path="../data/%s/overlaps" % options['mouse'])
    df['mouse'] = mouse

    dfs.append(df)

dfs = pd.concat(dfs)

dfs['behavior'] = dfs['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
dfs['pair'] = dfs['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)

print(dfs.head())
#+end_src

#+RESULTS:
#+begin_example
   index  sample_odor  test_odor      response tasks  laser  day  dist_odor  \
0      6          0.0        0.0   correct_hit   DPA    0.0  1.0        NaN
1      9          0.0        0.0   correct_hit   DPA    0.0  1.0        NaN
2     10          0.0        1.0  incorrect_fa   DPA    0.0  1.0        NaN
3     18          0.0        1.0  incorrect_fa   DPA    0.0  1.0        NaN
4     26          0.0        1.0  incorrect_fa   DPA    0.0  1.0        NaN

   choice                                      overlaps_diag  \
0     1.0  [0.11676032841205597, -0.03953419625759125, -0...
1     1.0  [0.12259367108345032, -0.018929380923509598, 0...
2     1.0  [-0.18104955554008484, 0.09383393079042435, 0....
3     1.0  [-0.12184631824493408, 0.1557987630367279, -0....
4     1.0  [-0.07315205782651901, 0.04572875425219536, 0....

                                         overlaps_MD   mouse  behavior  pair
0  [0.03378348393986622, 0.010957124157963941, -0...  ChRM04         1     1
1  [0.012054286897182465, 0.04256816146274408, 0....  ChRM04         1     1
2  [-0.04626151639968157, 0.06041626073420048, -0...  ChRM04         0     0
3  [-0.05099838972091675, -0.07124164483199517, -...  ChRM04         0     0
4  [0.034752229073395334, -0.06487469980493188, -...  ChRM04         0     0
#+end_example

#+begin_src ipython
name = 'df_distractor_mice'
pkl_save(dfs, name, path="../data/overlaps")
#+end_src

#+RESULTS:
: saving to ../data/overlaps/df_distractor_mice.pkl

*** GLM

#+begin_src ipython
import rpy2.robjects as robjects
from rpy2.robjects.packages import importr

# Set the .libPaths in R
custom_r_libpath = '~/R/x86_64-pc-linux-gnu-library/4.3/'
robjects.r('.libPaths("{0}")'.format(custom_r_libpath))

from pymer4.models import Lmer
#+end_src

#+RESULTS:

#+begin_src ipython
  dfs['tasks'] = dfs['tasks'].astype('category')
  dfs['day'] = dfs['day'].astype('int')

  print(dfs.behavior.unique())

  formula = 'behavior ~ day * tasks  + (1+ tasks + day | mouse)'

  results = []
  data = dfs.copy()

  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
[1 0]
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: behavior~day*tasks+(1+tasks+day|mouse)

Family: binomial	 Inference: parametric

Number of observations: 5760	 Groups: {'mouse': 5.0}

Log-likelihood: -3520.606 	 AIC: 7073.213

Random effects:

                Name  Var  Std
mouse    (Intercept)  0.0  0.0
mouse    tasksDualGo  0.0  0.0
mouse  tasksDualNoGo  0.0  0.0
mouse            day  0.0  0.0

                 IV1            IV2      Corr
mouse    (Intercept)    tasksDualGo
mouse    (Intercept)  tasksDualNoGo
mouse    (Intercept)            day
mouse    tasksDualGo  tasksDualNoGo  0.961752
mouse    tasksDualGo            day  -0.98127
mouse  tasksDualNoGo            day -0.991859

Fixed effects:
#+end_example

#+begin_src ipython
print(result.Estimate)
#+end_src

#+RESULTS:
: (Intercept)         -0.389
: day                  0.321
: tasksDualGo          0.141
: tasksDualNoGo       -0.005
: day:tasksDualGo     -0.026
: day:tasksDualNoGo    0.029
: Name: Estimate, dtype: float64

#+begin_src ipython
print(result['P-val'])
#+end_src

#+RESULTS:
: (Intercept)          0.001
: day                  0.000
: tasksDualGo          0.386
: tasksDualNoGo        0.976
: day:tasksDualGo      0.586
: day:tasksDualNoGo    0.534
: Name: P-val, dtype: float64

#+begin_src ipython
random_effects = glm.ranef
print(random_effects.keys())
#+end_src

#+RESULTS:
: Index(['X.Intercept.', 'tasksDualGo', 'tasksDualNoGo', 'day'], dtype='object')

#+begin_src ipython
# plt.figure(figsize=(15, 5))
colors = ['blue', 'green', 'red', 'purple', 'orange']
space = np.array([-0.1,-0.05, 0.0, 0.05, 0.1]) * .5

keys = ['(Intercept)', 'tasksDualGo', 'tasksDualNoGo']
# keys = result.Estimate.keys()

for i, key in enumerate(keys):
     if key == '(Intercept)':
          df = result.Estimate['(Intercept)']+ random_effects['X.Intercept.']
     else:
          df = result.Estimate['(Intercept)']+ result.Estimate[key] + random_effects[key]

     mean_value = df.mean()
     std_dev = df.std()

     if result['P-val'][key]<0.001:
          plt.text(i,   1.51, '***', ha='center', va='bottom')
     elif result['P-val'][key]<0.01:
          plt.text(i,   1.51, '**', ha='center', va='bottom')
     elif result['P-val'][key]<0.05:
          plt.text(i,   1.51, '*', ha='center', va='bottom')

     # Plot individual points
     plt.scatter(i * np.ones(df.shape[0]) + space, df, color=colors)
     # Plot mean and stddev as error bars
     plt.plot(i, mean_value, '_k', ms=20)
     plt.errorbar(i * np.ones(df.shape[0]), [mean_value]*len(df), yerr=[std_dev]*len(df), fmt='-', linestyle='None', color='k', capsize=15)

plt.axhline(y=0, color='black', linestyle='--')
plt.xticks(np.arange(len(keys)), keys)
plt.ylim([-1.5,1.5])
plt.ylabel('$\\beta$')
plt.xticks(rotation=45, ha='right', fontsize=14) # 'ha' stands for horizontal alignment
plt.show()
#+end_src

#+RESULTS:
[[./figures/landscape/figure_44.png]]

* afeafaefea
#+begin_src ipython
import pandas as pd
options['n_days'] = 6
y = []
for mouse in options['mice']:
    print(mouse)
    try:
        y_mouse = pkl_load('y_%s.pkl' % mouse)
        y_mouse['mouse'] = mouse
        y.append(y_mouse)
    except:
        pass
y = pd.concat(y)
#+end_src

#+RESULTS:
: ChRM04
: JawsM15
: JawsM18
: ACCM03
: ACCM04

#+begin_src ipython
print(y.keys())
#+end_src

#+RESULTS:
: Index(['sample_odor', 'test_odor', 'response', 'tasks', 'laser', 'day',
:        'dist_odor', 'choice', 'behavior', 'pair', 'sample', 'sample_STIM',
:        'sample_ED', 'sample_MD', 'sample_LD', 'dist', 'dist_STIM', 'dist_ED',
:        'dist_MD', 'dist_LD', 'OED_sign', 'OLD_sign', 'mouse'],
:       dtype='object')

#+begin_src ipython
sample_overlaps = pkl_load('sample_overlaps', path="../data/%s/overlaps" % options['mouse'])

#+end_src
* Data

#+begin_src ipython
if len(days) == 3:
    name = 'overlaps_tasks_days'
else:
    name = 'overlaps_tasks_'

filename = '%s_%s_%.2f_l1_ratio%s.pkl' % (options['mouse'], name, options['l1_ratio'], options['fname'])
print(filename)

try:
      overlaps = pkl_load(filename, path="../data/%s/" % options['mouse'])
      print('overlaps', overlaps.shape)
except:
      print('file not found')
#+end_src

#+RESULTS:
: JawsM15_overlaps_tasks_0.95_l1_ratio.pkl
: overlaps (2, 3, 3, 64, 84, 1)

#+begin_src ipython
overlaps_sample = overlaps[0]
overlaps_dist = overlaps[1]
# overlaps_choice = overlaps[2]
print(overlaps_sample.shape)
#+end_src

#+RESULTS:
: (3, 3, 64, 84, 1)

#+begin_src ipython
overlaps_sample = np.array(overlaps_sample)
print(overlaps_sample.shape)

overlaps_dist = np.array(overlaps_dist)
print(overlaps_dist.shape)
#+end_src

#+RESULTS:
: (3, 3, 64, 84, 1)
: (3, 3, 64, 84, 1)

#+begin_src ipython
  cmap = plt.get_cmap('Blues')
  colors = [cmap((i+1) / options['n_days'] ) for i in range(options['n_days'])]
  cmap = plt.get_cmap('Reds')
  colors2 = [cmap((i+1) / options['n_days'] ) for i in range(options['n_days'])]
  width = 6
  golden_ratio = (5**.5 - 1) / 2

  task = 1
  # mask = ~np.isnan(overlaps_dist).any(axis=2)
  # overlaps_dist = overlaps_dist[:, mask.any(axis=0)]
  options['features'] = 'choice'
  options['preprocess'] = False
  X_days, y_days = get_X_y_days(**options)

  time = np.linspace(0, 14, X_days.shape[-1])

  fig, ax = plt.subplots(3, 2, figsize= [2* width, 3*height])

  for task in range(3):
    for i in range(options['n_days']):
        overlap = overlaps_sample[task][i]
        size = overlap.shape[0] // 2

        sample = overlap[:size].mean(0)
        ax[task][0].plot(time, sample, label=i+1, color = colors[i]);

        sample = overlap[size:].mean(0)
        ax[task][0].plot(time, sample, label=i+1, color = colors[i]);

        # ax[task][0].plot(time, circcvl(overlaps_sample[task][i][:size].mean(0), windowSize=2), label=i+1, color = colors[i]);
        # ax[task][0].plot(time, circcvl(overlaps_sample[task][i][size:].mean(0), windowSize=2), label=i+1, color = colors2[i]);

        # size = overlaps_dist[task][i].shape[0] // 2
        overlap = overlaps_dist[task][i]
        size = overlap.shape[0] // 2
        dist = overlap[:size].mean(0)
        ax[task][1].plot(time, dist, label=i+1, color = colors[i]);

        dist = overlap[size:].mean(0)
        ax[task][1].plot(time, dist, label=i+1, color = colors2[i]);

        # ax[task][1].plot(overlaps_dist[task][i][:size].mean(0), label=i+1, color = colors[i]);
        # ax[task][1].plot(time, circcvl(overlaps_dist[task][i][:size].mean(0), windowSize=2), label=i+1, color = colors[i]);
        # ax[task][1].plot(time, circcvl(overlaps_dist[task][i][size:].mean(0), windowSize=2), label=i+1, color = colors2[i]);

        options['day'] = i+1
        # X, y = get_X_y_S1_S2(X_days, y_days, **options)
        # size = np.sum(y==-1)

        # ax[task][2].plot(time, circcvl(overlaps_choice[task][i][size:].mean(0), windowSize=2), label=i+1, color = colors2[i]);
        # ax[task][2].plot(time, circcvl(overlaps_choice[task][i][:size].mean(0), windowSize=2), label=i+1, color = colors[i]);

    # ax[task][1].legend(fontsize=10)
    ax[task][0].set_xlabel('Time (s)')
    ax[task][1].set_xlabel('Time (s)')
    ax[task][0].set_ylabel('Sample Overlap')
    ax[task][1].set_ylabel('Distractor Overlap')

    for i in range(2):
        ax[task][i].set_xticks(np.arange(0, 16, 2))
        ax[task][i].set_xlim([0, 14])
        add_vlines(ax[task][i])
        # ax[task][i].set_ylim([-20, 20])

  # plt.savefig('%s_overlaps.svg' % options['mouse'], dpi=300)
  # plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: Loading files from /home/leon/dual_task/dual_data/data/JawsM15
[[./figures/landscape/figure_28.png]]
:END:

#+begin_src ipython
import pandas as pd
options['trials'] = ''
options['verbose'] = 0
options['features'] = 'sample'
df = []

X_days, y_days = get_X_y_days(**options)

for task in tasks:
    options['task'] = task
    df2 = []
    for day in days:
        options['day'] = day
        X, y = get_X_y_S1_S2(X_days, y_days, **options)

        df2.append(y)
    df.append(pd.concat(df2))
y = pd.concat(df)
#+end_src

#+RESULTS:
#+begin_example
multiple days 0 2 2
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
multiple days 0 2 2
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
multiple days 0 2 2
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
multiple days 0 2 2
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
multiple days 0 2 2
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
multiple days 0 2 2
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
multiple days 0 2 2
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
multiple days 0 2 2
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
multiple days 0 2 2
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
#+end_example

#+begin_src ipython
# y['choice'] = ~y['choice'].astype('int')
y['behavior'] = y['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
y['pair'] = y['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
#+end_src

#+RESULTS:

#+begin_src ipython
# print(np.vstack(overlaps_dist).shape)
# print(np.vstack(np.vstack(np.swapaxes(overlaps_dist, 0, -3))).shape)
# overlaps  = np.vstack(np.hstack(overlaps_sample)[..., 0])
sample  = overlaps_sample[..., 0].reshape(-1, 84)
dist  = overlaps_dist[..., 0].reshape(-1, 84)
# overlaps = np.vstack(np.vstack(np.swapaxes(overlaps_dist, 0, -3)))[..., 0]
#+end_src

#+RESULTS:

#+begin_src ipython
y['sample'] = sample.tolist()
y['sample'] = y['sample'].apply(np.array)
# y['sample'] = (2*y.sample_odor-1) * y['sample']

options['epochs'] = ['STIM']
y['sample_STIM'] = y['sample'].apply(lambda x: avg_epochs(np.array(x), **options))

options['epochs'] = ['ED']
y['sample_ED'] = y['sample'].apply(lambda x: avg_epochs(np.array(x), **options))

options['epochs'] = ['MD']
y['sample_MD'] = y['sample'].apply(lambda x: avg_epochs(np.array(x), **options))

options['epochs'] = ['LD']
y['sample_LD'] = y['sample'].apply(lambda x: avg_epochs(np.array(x), **options))

print(sample.shape)
#+end_src

#+RESULTS:
: (960, 84)

#+begin_src ipython
y['dist'] = dist.tolist()
y['dist'] = y['dist'].apply(np.array)
# y['dist'] = (2*y.dist_odor-1) * y['dist']

options['epochs'] = ['STIM']
y['dist_STIM'] = y['dist'].apply(lambda x: avg_epochs(np.array(x), **options))

options['epochs'] = ['ED']
y['dist_ED'] = y['dist'].apply(lambda x: avg_epochs(np.array(x), **options))

options['epochs'] = ['MD']
y['dist_MD'] = y['dist'].apply(lambda x: avg_epochs(np.array(x), **options))

options['epochs'] = ['LD']
y['dist_LD'] = y['dist'].apply(lambda x: avg_epochs(np.array(x), **options))

print(dist.shape)
#+end_src

#+RESULTS:
: (960, 84)
:

#+begin_src ipython
y['OED_sign'] = y['dist_ED'].apply(lambda x: 0 if x<=0 else 1)
y['OLD_sign'] = (-(2 * y.sample_odor -1 ) * y['sample_LD']).apply(lambda x: 1 if x<=0 else 0)
#+end_src

#+RESULTS:

#+begin_src ipython
k=23
print(y.sample_odor.iloc[k], y.sample_ED.iloc[k], y.OLD_sign.iloc[k])
#+end_src

#+RESULTS:
: 1.0 -0.9962940578650235 0

#+begin_src ipython
df = y[y.tasks=='DualGo'].copy()
# df['overlaps'] = df['overlaps'].apply(np.array)

# Group by 'day' and compute the mean overlaps for each day
mean_overlaps_by_day = df.groupby('day')['sample'].apply(lambda x: np.mean(np.stack(x)**2, axis=0))

# Prepare data for plotting
mean_overlaps_df = pd.DataFrame(mean_overlaps_by_day.tolist(), index=mean_overlaps_by_day.index)

# Plotting
for idx, row in mean_overlaps_df.iterrows():
    plt.plot(np.linspace(0, 14, 84), row, label=f"Day {idx}")

plt.xlabel('Time (s)')
plt.ylabel('Overlap')
plt.legend(fontsize=10)
add_vlines()
plt.show()
#+end_src

#+RESULTS:
[[./figures/landscape/figure_33.png]]

* Overlaps
** Sample OLD
*** Tasks

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['mouse'] = y['mouse'].astype('category')
  print(y.sample_odor.unique())
  formula = 'sample_LD ~ tasks -1 '

  results = []
  beta = []
  pval = []

  for day in y.day.unique():
      # data = y[(y['day'] == day) & (y.pair==0)]
      data = y[(y['day'] == day) & (y.mouse == 'JawsM15')]
      data['sample_LD'] = -(2*data.sample_odor-1) * data['sample_LD']
      glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

      result = glm.fit()
      results.append(result)
      beta.append(result.params)
      pval.append(result.pvalues)

print(result.summary())
    #+end_src

#+RESULTS:
#+begin_example
[0. 1.]
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:              sample_LD   No. Observations:                   96
Model:                            GLM   Df Residuals:                       93
Model Family:                Gaussian   Df Model:                            2
Link Function:               Identity   Scale:                         0.38268
Method:                          IRLS   Log-Likelihood:                -88.587
Date:                Wed, 28 Aug 2024   Deviance:                       35.589
Time:                        17:22:39   Pearson chi2:                     35.6
No. Iterations:                     3   Pseudo R-squ. (CS):             0.2218
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------
tasks[DPA]          1.1661      0.109     10.664      0.000       0.952       1.380
tasks[DualGo]       0.4110      0.109      3.758      0.000       0.197       0.625
tasks[DualNoGo]     0.8452      0.109      7.729      0.000       0.631       1.060
===================================================================================
#+end_example

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
for i in range(3):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta).T[i], '-o', color=cols[i])
  print(np.round(np.array(pval).T[i], 3))

  for j, p in enumerate(np.array(pval).T[i]):
    if p < 0.05:
      plt.text(j+1,  np.max(beta) + .01 + i * .05, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('Sample OLD $\\beta_{Task}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.006 0.    0.    0.    0.    0.   ]
: [0.    0.    0.005 0.    0.    0.   ]
: [0.    0.003 0.    0.    0.    0.   ]
[[./figures/landscape/figure_36.png]]
:END:

*** Choice

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'sample_LD ~ choice'

  results = []
  beta = []
  pval = []

  for task in tasks:
    for day in y.day.unique():
        data = y[(y['day'] == day) & (y.tasks==task) & (y.mouse=='JawsM15')]
        data['sample_LD'] = -(2*data.sample_odor-1) * data['sample_LD']
        # data = y[(y['day'] == day)]
        glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

        result = glm.fit()
        results.append(result)
        beta.append(result.params)
        pval.append(result.pvalues)

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:              sample_LD   No. Observations:                   32
Model:                            GLM   Df Residuals:                       30
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.23209
Method:                          IRLS   Log-Likelihood:                -21.004
Date:                Wed, 28 Aug 2024   Deviance:                       6.9628
Time:                        17:33:35   Pearson chi2:                     6.96
No. Iterations:                     3   Pseudo R-squ. (CS):            0.02567
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.7669      0.124      6.165      0.000       0.523       1.011
choice        -0.1495      0.171     -0.876      0.381      -0.484       0.185
==============================================================================
#+end_example

#+begin_src ipython
beta = np.array(beta).reshape((3, options['n_days'], -1))
print(beta.shape)

pval = np.array(pval).reshape((3, options['n_days'], -1))
print(pval.shape)
#+end_src

#+RESULTS:
: (3, 6, 2)
: (3, 6, 2)

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
k=1
for i in range(3):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta)[i, :, k], '-o', color=cols[i])
  print(np.round(pval[i, :, k], 3))
  for j in range(pval.shape[1]):
    if pval[i, j, k] < 0.05:
      plt.text(j+1, np.max(beta[..., k]) + .01 + i * .05, '*', ha='center', va='bottom', color=cols[i])
      # plt.text(j+1, .01, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('SOLD $\\beta_{choice}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.086 0.973 0.381 0.692 0.458 0.186]
: [0.125 0.375 0.296 0.448 0.066 0.767]
: [0.699 0.634 0.679 0.338 0.348 0.419]
[[./figures/landscape/figure_39.png]]
:END:

*** Behavior

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')
  # y['behavior'] = 2*y.behavior -1
  formula = 'sample_LD ~ behavior'

  results = []
  beta = []
  pval = []

  for task in tasks:
    for day in y.day.unique():
        data = y[(y['day'] == day) & (y.tasks==task)]
        data['sample_LD'] = -(2*data.sample_odor-1) * data['sample_LD']
        # data = y[(y['day'] == day)]
        glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

        result = glm.fit()
        results.append(result)
        beta.append(result.params)
        pval.append(result.pvalues)

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:              sample_LD   No. Observations:                  224
Model:                            GLM   Df Residuals:                      222
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.40234
Method:                          IRLS   Log-Likelihood:                -214.87
Date:                Wed, 28 Aug 2024   Deviance:                       89.320
Time:                        17:44:33   Pearson chi2:                     89.3
No. Iterations:                     3   Pseudo R-squ. (CS):            0.01653
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.9551      0.188      5.078      0.000       0.586       1.324
behavior       0.1048      0.054      1.930      0.054      -0.002       0.211
==============================================================================
#+end_example

#+begin_src ipython
beta = np.array(beta).reshape((3, options['n_days'], -1))
print(beta.shape)

pval = np.array(pval).reshape((3, options['n_days'], -1))
print(pval.shape)
#+end_src

#+RESULTS:
: (3, 6, 2)
: (3, 6, 2)

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
k=1
for i in range(3):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta)[i, :, k], '-o', color=cols[i])
  print(pval[i, :, k])
  for j in range(pval.shape[1]):
    if pval[i, j, k] < 0.05:
      plt.text(j+1, .51+i*0.05, '*', ha='center', va='bottom', color=cols[i])
      # plt.text(j+1, .01, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('SOLD $\\beta_{behavior}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.86037155 0.21418035 0.05364159 0.02929007 0.06089178 0.00199354]
: [0.70087702 0.44260844 0.28563124 0.21726989 0.34405583 0.1625283 ]
: [0.43464444 0.3659488  0.05960316 0.32394952 0.58576318 0.64897676]
[[./figures/landscape/figure_42.png]]
:END:

*** Pair

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'sample_LD ~ pair'

  results = []
  beta = []
  pval = []

  for task in tasks:
    for day in y.day.unique():
        data = y[(y['day'] == day) & (y.tasks==task)]
        # data = y[(y['day'] == day)]
        glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

        result = glm.fit()
        results.append(result)
        beta.append(result.params)
        pval.append(result.pvalues)

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:              sample_LD   No. Observations:                  224
Model:                            GLM   Df Residuals:                      222
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.77313
Method:                          IRLS   Log-Likelihood:                -288.02
Date:                Wed, 28 Aug 2024   Deviance:                       171.64
Time:                        16:17:24   Pearson chi2:                     172.
No. Iterations:                     3   Pseudo R-squ. (CS):          0.0003932
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     -0.0105      0.083     -0.127      0.899      -0.173       0.152
pair          -0.0330      0.117     -0.281      0.779      -0.263       0.197
==============================================================================
#+end_example

#+begin_src ipython
beta = np.array(beta).reshape((3, options['n_days'], -1))
print(beta.shape)

pval = np.array(pval).reshape((3, options['n_days'], -1))
print(pval.shape)
#+end_src

#+RESULTS:
: (3, 6, 2)
: (3, 6, 2)

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
k=1
for i in range(3):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta)[i, :, k], '-o', color=cols[i])
  print(np.round(pval[i, :, k], 3))
  for j in range(pval.shape[1]):
    if pval[i, j, k] < 0.05:
      plt.text(j+1, np.max(beta[..., k])+.01+.05*i, '*', ha='center', va='bottom', color=cols[i])
      # plt.text(j+1, .01, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('SOLD $\\beta_{pair}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.759 0.888 0.779 0.815 0.728 0.759]
: [0.316 0.64  0.824 0.43  0.944 0.694]
: [0.875 0.33  0.668 0.458 0.564 0.94 ]
[[./figures/landscape/figure_44.png]]
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

** Sample sign OLD
*** Tasks

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  # y['choice'] = y['choice'].astype('category')

  formula = 'OLD_sign ~ tasks'

  results = []
  beta = []
  pval = []

  for day in y.day.unique():
      # data = y[(y['day'] == day) & (y.pair==0)]
      data = y[(y['day'] == day)]
      glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

      result = glm.fit()
      results.append(result)
      beta.append(result.params)
      pval.append(result.pvalues)

print(result.summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:               OLD_sign   No. Observations:                  288
Model:                            GLM   Df Residuals:                      285
Model Family:                Gaussian   Df Model:                            2
Link Function:               Identity   Scale:                         0.16177
Method:                          IRLS   Log-Likelihood:                -144.84
Date:                Wed, 28 Aug 2024   Deviance:                       46.104
Time:                        16:17:54   Pearson chi2:                     46.1
No. Iterations:                     3   Pseudo R-squ. (CS):           0.004664
Covariance Type:            nonrobust
=====================================================================================
                        coef    std err          z      P>|z|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.1771      0.041      4.314      0.000       0.097       0.258
tasks[T.DualGo]       0.0104      0.058      0.179      0.858      -0.103       0.124
tasks[T.DualNoGo]     0.0625      0.058      1.077      0.282      -0.051       0.176
=====================================================================================
#+end_example

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
for i in range(3):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta).T[i], '-o', color=cols[i])
  print(np.round(np.array(pval).T[i], 3))
  for j, p in enumerate(np.array(pval).T[i]):
    if p < 0.05:
      plt.text(j+1,  np.max(beta) + .01 + i* .05, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('sign(SOLD) $\\beta_{Task}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0. 0. 0. 0. 0. 0.]
: [0.393 0.472 0.    0.18  0.26  0.858]
: [0.625 0.023 0.738 0.003 0.055 0.282]
[[./figures/landscape/figure_47.png]]
:END:

*** Choice

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'OLD_sign ~ choice'

  results = []
  beta = []
  pval = []

  for task in tasks:
    for day in y.day.unique():
        data = y[(y['day'] == day) & (y.tasks==task)]
        # data = y[(y['day'] == day)]
        glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

        result = glm.fit()
        results.append(result)
        beta.append(result.params)
        pval.append(result.pvalues)

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:               OLD_sign   No. Observations:                  224
Model:                            GLM   Df Residuals:                      222
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.14396
Method:                          IRLS   Log-Likelihood:                -99.759
Date:                Wed, 28 Aug 2024   Deviance:                       31.960
Time:                        16:18:41   Pearson chi2:                     32.0
No. Iterations:                     3   Pseudo R-squ. (CS):           0.007766
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.1333      0.040      3.334      0.001       0.055       0.212
choice         0.0682      0.052      1.318      0.187      -0.033       0.170
==============================================================================
#+end_example

#+begin_src ipython
beta = np.array(beta).reshape((3, options['n_days'], -1))
print(beta.shape)

pval = np.array(pval).reshape((3, options['n_days'], -1))
print(pval.shape)
#+end_src

#+RESULTS:
: (3, 6, 2)
: (3, 6, 2)

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
k=1
for i in range(3):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta)[i, :, k], '-o', color=cols[i])
  print(np.round(pval[i, :, k], 3))
  for j in range(pval.shape[1]):
    if pval[i, j, k] < 0.05:
      plt.text(j+1, np.max(beta[..., k]) + .01 + i * .05, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('sign(SOLD) $\\beta_{choice}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.33  0.094 0.187 0.762 0.113 0.16 ]
: [0.374 0.763 0.913 0.235 0.112 0.475]
: [0.563 0.696 0.556 0.539 0.793 0.711]
[[./figures/landscape/figure_50.png]]
:END:

*** Behavior

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'OLD_sign ~ behavior'

  results = []
  beta = []
  pval = []

  for task in tasks:
    for day in y.day.unique():
        data = y[(y['day'] == day) & (y.tasks==task)]
        # data = y[(y['day'] == day)]
        glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

        try:
            result = glm.fit()
            results.append(result)
            beta.append(result.params)
            pval.append(result.pvalues)
        except:
            beta.append(np.zeros(2))
            pval.append(np.ones(2))
            pass

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:               OLD_sign   No. Observations:                  224
Model:                            GLM   Df Residuals:                      222
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.14329
Method:                          IRLS   Log-Likelihood:                -99.238
Date:                Wed, 28 Aug 2024   Deviance:                       31.811
Time:                        16:20:30   Pearson chi2:                     31.8
No. Iterations:                     3   Pseudo R-squ. (CS):            0.01238
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.1538      0.028      5.483      0.000       0.099       0.209
behavior       0.1081      0.065      1.668      0.095      -0.019       0.235
==============================================================================
#+end_example

#+begin_src ipython
beta = np.array(beta).reshape((3, options['n_days'], -1))
print(beta.shape)

pval = np.array(pval).reshape((3, options['n_days'], -1))
print(pval.shape)
#+end_src

#+RESULTS:
: (3, 6, 2)
: (3, 6, 2)

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
k=1
for i in range(3):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta)[i, :, k], '-o', color=cols[i])
  print(pval[i, :, k])
  for j in range(pval.shape[1]):
    if pval[i, j, k] < 0.05:
      plt.text(j+1, np.max(beta[..., k])+.01+i*.05, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('sign(SOLD) $\\beta_{behavior}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.7304999  0.37880538 0.09540339 0.45984996 0.78289986 0.00912811]
: [0.84462168 0.55503664 0.5356652  0.66135849 0.71381496 0.15582459]
: [0.1195424  0.2127877  0.03086698 0.81245162 0.49723088 0.53695203]
[[./figures/landscape/figure_53.png]]
:END:

*** Pair

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'OLD_sign ~ pair'

  results = []
  beta = []
  pval = []

  for task in tasks:
    for day in y.day.unique():
        data = y[(y['day'] == day) & (y.tasks==task)]
        # data = y[(y['day'] == day)]
        glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

        result = glm.fit()
        results.append(result)
        beta.append(result.params)
        pval.append(result.pvalues)

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:               OLD_sign   No. Observations:                  224
Model:                            GLM   Df Residuals:                      222
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.14459
Method:                          IRLS   Log-Likelihood:                -100.24
Date:                Wed, 28 Aug 2024   Deviance:                       32.098
Time:                        16:20:50   Pearson chi2:                     32.1
No. Iterations:                     3   Pseudo R-squ. (CS):           0.003480
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.1518      0.036      4.225      0.000       0.081       0.222
pair           0.0446      0.051      0.879      0.380      -0.055       0.144
==============================================================================
#+end_example

#+begin_src ipython
beta = np.array(beta).reshape((3, options['n_days'], -1))
print(beta.shape)

pval = np.array(pval).reshape((3, options['n_days'], -1))
print(pval.shape)
#+end_src

#+RESULTS:
: (3, 6, 2)
: (3, 6, 2)

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
k=1
for i in range(3):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta)[i, :, k], '-o', color=cols[i])
  print(np.round(pval[i, :, k], 3))
  for j in range(pval.shape[1]):
    if pval[i, j, k] < 0.05:
      plt.text(j+1, np.max(beta[..., k])+.01 + i*.05, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('sign(SOLD) $\\beta_{pair}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.305 0.855 0.38  0.434 0.171 0.791]
: [0.855 0.606 0.275 0.227 0.206 0.604]
: [0.322 0.35  0.305 0.35  0.45  0.813]
[[./figures/landscape/figure_56.png]]
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

** Distractor OED
*** Tasks

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  # y['choice'] = y['choice'].astype('category')

  formula = 'dist_ED ~ tasks'

  results = []
  beta = []
  pval = []

  for day in y.day.unique():
      # data = y[(y['day'] == day) & (y.pair==0)]
      data = y[(y['day'] == day) & (y.mouse=='JawsM15')]
      glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

      result = glm.fit()
      results.append(result)
      beta.append(result.params)
      pval.append(result.pvalues)

print(result.summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:                dist_ED   No. Observations:                   96
Model:                            GLM   Df Residuals:                       93
Model Family:                Gaussian   Df Model:                            2
Link Function:               Identity   Scale:                         0.29278
Method:                          IRLS   Log-Likelihood:                -75.734
Date:                Wed, 28 Aug 2024   Deviance:                       27.229
Time:                        18:41:30   Pearson chi2:                     27.2
No. Iterations:                     3   Pseudo R-squ. (CS):            0.09962
Covariance Type:            nonrobust
=====================================================================================
                        coef    std err          z      P>|z|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept            -0.8730      0.096     -9.127      0.000      -1.061      -0.686
tasks[T.DualGo]       0.2024      0.135      1.496      0.135      -0.063       0.467
tasks[T.DualNoGo]    -0.2258      0.135     -1.669      0.095      -0.491       0.039
=====================================================================================
#+end_example

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
for i in range(3):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta).T[i], '-o', color=cols[i])
  print(np.round(np.array(pval).T[i], 3))
  for j, p in enumerate(np.array(pval).T[i]):
    if p < 0.05:
      plt.text(j+1, np.max(beta)+.01 + i*.05, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('DOED $\\beta_{Task}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.    0.029 0.    0.    0.743 0.   ]
: [0.    0.014 0.    0.001 0.    0.135]
: [0.002 0.001 0.    0.004 0.    0.095]
[[./figures/landscape/figure_60.png]]
:END:

*** Choice

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'dist_ED ~ choice'

  results = []
  beta = []
  pval = []

  for task in tasks:
    for day in y.day.unique():
        data = y[(y['day'] == day) & (y.tasks==task) ]
        glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())
        try:
            result = glm.fit()
            results.append(result)
            beta.append(result.params)
            pval.append(result.pvalues)
        except:
            beta.append(np.zeros(2))
            pval.append(np.ones(2))
            pass

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:                dist_ED   No. Observations:                  224
Model:                            GLM   Df Residuals:                      222
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.16259
Method:                          IRLS   Log-Likelihood:                -113.38
Date:                Wed, 28 Aug 2024   Deviance:                       36.094
Time:                        16:21:56   Pearson chi2:                     36.1
No. Iterations:                     3   Pseudo R-squ. (CS):           0.005115
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.0463      0.043      1.089      0.276      -0.037       0.130
choice        -0.0587      0.055     -1.068      0.286      -0.166       0.049
==============================================================================
#+end_example


#+begin_src ipython
beta = np.array(beta).reshape((3, options['n_days'], -1))
print(beta.shape)

pval = np.array(pval).reshape((3, options['n_days'], -1))
print(pval.shape)
#+end_src

#+RESULTS:
: (3, 6, 2)
: (3, 6, 2)

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
k=1
for i in range(3):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta)[i, :, k], '-o', color=cols[i])
  print(np.round(pval[i, :, k], 3))
  for j in range(pval.shape[1]):
    if pval[i, j, k] < 0.05:
      plt.text(j+1, np.max(beta[..., k])+.01 + i*.05, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('DOED $\\beta_{choice}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.067 0.67  0.286 0.128 0.996 0.516]
: [0.001 0.013 0.485 0.539 0.251 0.986]
: [0.257 0.484 0.768 0.783 0.276 0.95 ]
[[./figures/landscape/figure_62.png]]
:END:

*** Behavior

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'dist_ED ~ behavior'
  # formula = 'OED_sign ~ behavior'

  results = []
  beta = []
  pval = []

  for task in tasks:
    for day in y.day.unique():
        data = y[(y['day'] == day) & (y.tasks==task)]
        glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())
        try:
            result = glm.fit()
            results.append(result)
            beta.append(result.params)
            pval.append(result.pvalues)
        except:
            beta.append(np.zeros(2))
            pval.append(np.ones(2))
            pass

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:                dist_ED   No. Observations:                  224
Model:                            GLM   Df Residuals:                      222
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.16336
Method:                          IRLS   Log-Likelihood:                -113.92
Date:                Wed, 28 Aug 2024   Deviance:                       36.266
Time:                        16:23:10   Pearson chi2:                     36.3
No. Iterations:                     3   Pseudo R-squ. (CS):          0.0004085
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.0149      0.030      0.498      0.619      -0.044       0.074
behavior      -0.0199      0.069     -0.287      0.774      -0.155       0.116
==============================================================================
#+end_example

#+begin_src ipython
beta = np.array(beta).reshape((3, options['n_days'], -1))
print(beta.shape)

pval = np.array(pval).reshape((3, options['n_days'], -1))
print(pval.shape)
#+end_src

#+RESULTS:
: (3, 6, 2)
: (3, 6, 2)

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
k=1
for i in range(3):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta)[i, :, k], '-o', color=cols[i])
  print(np.round(pval[i, :, k], 3))
  for j in range(pval.shape[1]):
    if pval[i, j, k] < 0.05:
      plt.text(j+1, np.max(beta[..., k])+.01 + i*.05, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('DOED $\\beta_{behavior}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.26  0.066 0.774 0.548 0.065 0.066]
: [0.781 0.    0.004 0.108 0.295 0.003]
: [0.919 0.407 0.185 0.043 0.951 0.409]
[[./figures/landscape/figure_65.png]]
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

*** Pair

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'dist_ED ~ pair'
  # formula = 'OED_sign ~ behavior'

  results = []
  beta = []
  pval = []

  for task in tasks:
    for day in y.day.unique():
        data = y[(y['day'] == day) & (y.tasks==task)]
        glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())
        try:
            result = glm.fit()
            results.append(result)
            beta.append(result.params)
            pval.append(result.pvalues)
        except:
            beta.append(np.zeros(2))
            pval.append(np.ones(2))
            pass

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:                dist_ED   No. Observations:                  224
Model:                            GLM   Df Residuals:                      222
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.16332
Method:                          IRLS   Log-Likelihood:                -113.89
Date:                Wed, 28 Aug 2024   Deviance:                       36.256
Time:                        16:23:29   Pearson chi2:                     36.3
No. Iterations:                     3   Pseudo R-squ. (CS):          0.0006663
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.0213      0.038      0.558      0.577      -0.054       0.096
pair          -0.0202      0.054     -0.375      0.708      -0.126       0.086
==============================================================================
#+end_example

#+begin_src ipython
beta = np.array(beta).reshape((3, options['n_days'], -1))
print(beta.shape)

pval = np.array(pval).reshape((3, options['n_days'], -1))
print(pval.shape)
#+end_src

#+RESULTS:
: (3, 6, 2)
: (3, 6, 2)

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
k=1
for i in range(3):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta)[i, :, k], '-o', color=cols[i])
  print(np.round(pval[i, :, k], 3))
  for j in range(pval.shape[1]):
    if pval[i, j, k] < 0.05:
      plt.text(j+1, np.max(beta[..., k])+.01 + i*.05, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('DOED $\\beta_{pair}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.906 0.723 0.708 0.283 0.775 0.875]
: [0.348 0.565 0.568 0.566 0.823 0.881]
: [0.857 0.31  0.789 0.113 0.601 0.353]
[[./figures/landscape/figure_69.png]]
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

** Distractor sign OED
*** Tasks

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  # y['choice'] = y['choice'].astype('category')

  formula = 'OED_sign ~ tasks'

  results = []
  beta = []
  pval = []

  for day in y.day.unique():
      # data = y[(y['day'] == day) & (y.pair==0)]
      data = y[(y['day'] == day)]
      glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

      result = glm.fit()
      results.append(result)
      beta.append(result.params)
      pval.append(result.pvalues)

print(result.summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:               OED_sign   No. Observations:                  288
Model:                            GLM   Df Residuals:                      285
Model Family:                Gaussian   Df Model:                            2
Link Function:               Identity   Scale:                         0.24784
Method:                          IRLS   Log-Likelihood:                -206.27
Date:                Wed, 28 Aug 2024   Deviance:                       70.635
Time:                        16:23:43   Pearson chi2:                     70.6
No. Iterations:                     3   Pseudo R-squ. (CS):           0.008193
Covariance Type:            nonrobust
=====================================================================================
                        coef    std err          z      P>|z|      [0.025      0.975]
-------------------------------------------------------------------------------------
Intercept             0.4062      0.051      7.995      0.000       0.307       0.506
tasks[T.DualGo]       0.1042      0.072      1.450      0.147      -0.037       0.245
tasks[T.DualNoGo]     0.0208      0.072      0.290      0.772      -0.120       0.162
=====================================================================================
#+end_example

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
for i in range(3):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta).T[i], '-o', color=cols[i])
  print(np.round(np.array(pval).T[i], 3))
  for j, p in enumerate(np.array(pval).T[i]):
    if p < 0.05:
      plt.text(j+1, np.max(beta)+.01 + i*.05, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('sign(DOED) $\\beta_{Task}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0. 0. 0. 0. 0. 0.]
: [0.02  0.003 0.08  0.637 0.    0.147]
: [0.042 0.001 0.001 0.22  0.021 0.772]
[[./figures/landscape/figure_72.png]]
:END:

*** Choice

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'OED_sign ~ choice'

  results = []
  beta = []
  pval = []

  for task in tasks:
    for day in y.day.unique():
        data = y[(y['day'] == day) & (y.tasks==task) ]
        glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())
        try:
            result = glm.fit()
            results.append(result)
            beta.append(result.params)
            pval.append(result.pvalues)
        except:
            beta.append(np.zeros(2))
            pval.append(np.ones(2))
            pass

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:               OED_sign   No. Observations:                  224
Model:                            GLM   Df Residuals:                      222
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.24043
Method:                          IRLS   Log-Likelihood:                -157.20
Date:                Wed, 28 Aug 2024   Deviance:                       53.376
Time:                        16:24:46   Pearson chi2:                     53.4
No. Iterations:                     3   Pseudo R-squ. (CS):           0.004901
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.6444      0.052     12.468      0.000       0.543       0.746
choice        -0.0698      0.067     -1.045      0.296      -0.201       0.061
==============================================================================
#+end_example


#+begin_src ipython
beta = np.array(beta).reshape((3, options['n_days'], -1))
print(beta.shape)

pval = np.array(pval).reshape((3, options['n_days'], -1))
print(pval.shape)
#+end_src

#+RESULTS:
: (3, 6, 2)
: (3, 6, 2)

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
k=1
for i in range(3):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta)[i, :, k], '-o', color=cols[i])
  print(np.round(pval[i, :, k], 3))
  for j in range(pval.shape[1]):
    if pval[i, j, k] < 0.05:
      plt.text(j+1, np.max(beta[..., k])+.01 + i*.05, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('sign(DOED) $\\beta_{choice}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.432 0.065 0.296 0.026 0.726 0.305]
: [0.001 0.986 0.597 0.157 0.627 0.538]
: [0.603 0.286 0.392 0.678 0.384 0.465]
[[./figures/landscape/figure_75.png]]
:END:

*** Behavior

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'OED_sign ~ behavior'

  results = []
  beta = []
  pval = []

  for task in tasks:
    for day in y.day.unique():
        data = y[(y['day'] == day) & (y.tasks==task)]
        glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())
        try:
            result = glm.fit()
            results.append(result)
            beta.append(result.params)
            pval.append(result.pvalues)
        except:
            beta.append(np.zeros(2))
            pval.append(np.ones(2))
            pass

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:               OED_sign   No. Observations:                  224
Model:                            GLM   Df Residuals:                      222
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.24155
Method:                          IRLS   Log-Likelihood:                -157.72
Date:                Wed, 28 Aug 2024   Deviance:                       53.625
Time:                        16:24:54   Pearson chi2:                     53.6
No. Iterations:                     3   Pseudo R-squ. (CS):          0.0002960
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.5989      0.036     16.439      0.000       0.527       0.670
behavior       0.0201      0.084      0.239      0.811      -0.145       0.185
==============================================================================
#+end_example

#+begin_src ipython
beta = np.array(beta).reshape((3, options['n_days'], -1))
print(beta.shape)

pval = np.array(pval).reshape((3, options['n_days'], -1))
print(pval.shape)
#+end_src

#+RESULTS:
: (3, 6, 2)
: (3, 6, 2)

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
k=1
for i in range(3):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta)[i, :, k], '-o', color=cols[i])
  print(np.round(pval[i, :, k], 3))
  for j in range(pval.shape[1]):
    if pval[i, j, k] < 0.05:
      plt.text(j+1, np.max(beta[..., k])+.01 + i*.05, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('sign(DOED) $\\beta_{behavior}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.025 0.002 0.811 0.225 0.149 0.064]
: [0.601 0.008 0.004 0.007 0.567 0.123]
: [0.849 0.64  0.836 0.043 0.293 0.426]
[[./figures/landscape/figure_78.png]]
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

*** Pair

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'OED_sign ~ behavior'

  results = []
  beta = []
  pval = []

  for task in tasks:
    for day in y.day.unique():
        data = y[(y['day'] == day) & (y.tasks==task)]
        glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())
        try:
            result = glm.fit()
            results.append(result)
            beta.append(result.params)
            pval.append(result.pvalues)
        except:
            beta.append(np.zeros(2))
            pval.append(np.ones(2))
            pass

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:               OED_sign   No. Observations:                  224
Model:                            GLM   Df Residuals:                      222
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.24155
Method:                          IRLS   Log-Likelihood:                -157.72
Date:                Wed, 28 Aug 2024   Deviance:                       53.625
Time:                        16:25:27   Pearson chi2:                     53.6
No. Iterations:                     3   Pseudo R-squ. (CS):          0.0002960
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.5989      0.036     16.439      0.000       0.527       0.670
behavior       0.0201      0.084      0.239      0.811      -0.145       0.185
==============================================================================
#+end_example

#+begin_src ipython
beta = np.array(beta).reshape((3, options['n_days'], -1))
print(beta.shape)

pval = np.array(pval).reshape((3, options['n_days'], -1))
print(pval.shape)
#+end_src

#+RESULTS:
: (3, 6, 2)
: (3, 6, 2)

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
k=1
for i in range(3):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta)[i, :, k], '-o', color=cols[i])
  print(np.round(pval[i, :, k], 3))
  for j in range(pval.shape[1]):
    if pval[i, j, k] < 0.05:
      plt.text(j+1, np.max(beta[..., k])+.01 + i*.05, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('sign(DOED) $\\beta_{pair}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.025 0.002 0.811 0.225 0.149 0.064]
: [0.601 0.008 0.004 0.007 0.567 0.123]
: [0.849 0.64  0.836 0.043 0.293 0.426]
[[./figures/landscape/figure_82.png]]
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

** All tasks
*** sample OLD
**** Choice

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'sample_LD ~  choice'

  results = []
  beta = []
  pval = []

  for day in y.day.unique():
      data = y[(y['day'] == day)]
      data['sample_LD'] = -(2*data.sample_odor-1) * data['sample_LD']
      glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

      result = glm.fit()
      results.append(result)
      beta.append(result.params)
      pval.append(result.pvalues)

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:              sample_LD   No. Observations:                  672
Model:                            GLM   Df Residuals:                      670
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.50343
Method:                          IRLS   Log-Likelihood:                -721.92
Date:                Wed, 28 Aug 2024   Deviance:                       337.30
Time:                        17:49:28   Pearson chi2:                     337.
No. Iterations:                     3   Pseudo R-squ. (CS):           0.005184
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.5413      0.046     11.843      0.000       0.452       0.631
choice        -0.1066      0.057     -1.868      0.062      -0.218       0.005
==============================================================================
#+end_example

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
for i in range(1, 2):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta).T[i], '-o', color=cols[i])
  print(np.round(np.array(pval).T[i]))
  # for j, p in enumerate(np.array(pval).T[i]):
  #   if p < 0.05:
  #     plt.text(j+1, max(np.array(beta).T[i]) + .01 + i * 0.05, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('SOLD $\\beta_{choice}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0. 0. 0. 0. 0. 0.]
[[./figures/landscape/figure_86.png]]
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

**** Behavior

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'sample_LD ~  behavior'

  results = []
  beta = []
  pval = []

  for day in y.day.unique():
      data = y[(y['day'] == day)]
      data['sample_LD'] = -(2*data.sample_odor-1) * data['sample_LD']
      # data = y[(y['day'] == day)]
      glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

      result = glm.fit()
      results.append(result)
      beta.append(result.params)
      pval.append(result.pvalues)

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:              sample_LD   No. Observations:                  672
Model:                            GLM   Df Residuals:                      670
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.50112
Method:                          IRLS   Log-Likelihood:                -720.38
Date:                Wed, 28 Aug 2024   Deviance:                       335.75
Time:                        17:46:18   Pearson chi2:                     336.
No. Iterations:                     3   Pseudo R-squ. (CS):           0.009761
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.7626      0.116      6.568      0.000       0.535       0.990
behavior       0.0840      0.033      2.567      0.010       0.020       0.148
==============================================================================
#+end_example

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
for i in range(1, 2):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta).T[i], '-o', color=cols[i])
  print(np.round(np.array(pval).T[i], 3))
  # for j, p in enumerate(np.array(pval).T[i]):
  #   if p < 0.05:
  #     plt.text(j+1, .11 + i * 0.05, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('SOLD $\\beta_{behavior}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.466 0.096 0.01  0.008 0.036 0.171]
[[./figures/landscape/figure_89.png]]
:END:

*** sample sign OLD
**** Choice

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'OLD_sign ~  choice'

  results = []
  beta = []
  pval = []

  for day in y.day.unique():
      data = y[(y['day'] == day)]
      # data = y[(y['day'] == day)]
      glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

      result = glm.fit()
      results.append(result)
      beta.append(result.params)
      pval.append(result.pvalues)

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:               OLD_sign   No. Observations:                  672
Model:                            GLM   Df Residuals:                      670
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.18791
Method:                          IRLS   Log-Likelihood:                -390.81
Date:                Wed, 28 Aug 2024   Deviance:                       125.90
Time:                        16:28:30   Pearson chi2:                     126.
No. Iterations:                     3   Pseudo R-squ. (CS):           0.004723
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.2116      0.028      7.579      0.000       0.157       0.266
choice         0.0622      0.035      1.783      0.075      -0.006       0.131
==============================================================================
#+end_example

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
for i in range(1, 2):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta).T[i], '-o', color=cols[i])
  print(np.round(np.array(pval).T[i],3))
  for j, p in enumerate(np.array(pval).T[i]):
    if p < 0.05:
      plt.text(j+1, max(np.array(beta).T[i]) + .01 + i * 0.001, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('sign(SOLD) $\\beta_{choice}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.664 0.419 0.075 0.406 0.046 0.56 ]
[[./figures/landscape/figure_90.png]]
:END:

**** Behavior

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'OLD_sign ~  behavior'

  results = []
  beta = []
  pval = []

  for day in y.day.unique():
      data = y[(y['day'] == day)]
      # data = y[(y['day'] == day)]
      glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

      result = glm.fit()
      results.append(result)
      beta.append(result.params)
      pval.append(result.pvalues)

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:               OLD_sign   No. Observations:                  672
Model:                            GLM   Df Residuals:                      670
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.18630
Method:                          IRLS   Log-Likelihood:                -387.90
Date:                Wed, 28 Aug 2024   Deviance:                       124.82
Time:                        16:29:21   Pearson chi2:                     125.
No. Iterations:                     3   Pseudo R-squ. (CS):            0.01334
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.2246      0.019     11.876      0.000       0.188       0.262
behavior       0.1198      0.040      3.003      0.003       0.042       0.198
==============================================================================
#+end_example

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
for i in range(1, 2):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta).T[i], '-o', color=cols[i])
  print(np.round(np.array(pval).T[i], 3))
  for j, p in enumerate(np.array(pval).T[i]):
    if p < 0.05:
      plt.text(j+1, max(np.array(beta).T[i]) + .01, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('sign(SOLD) $\\beta_{behavior}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.4   0.428 0.003 0.788 0.382 0.987]
[[./figures/landscape/figure_92.png]]
:END:

*** Dist OED
**** Choice

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'dist_ED ~  choice'

  results = []
  beta = []
  pval = []

  for day in y.day.unique():
      # data = y[(y['day'] == day) & (y['pair']==0)]
      data = y[(y['day'] == day)]
      glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

      result = glm.fit()
      results.append(result)
      beta.append(result.params)
      pval.append(result.pvalues)

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:                dist_ED   No. Observations:                  672
Model:                            GLM   Df Residuals:                      670
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.17625
Method:                          IRLS   Log-Likelihood:                -369.27
Date:                Wed, 28 Aug 2024   Deviance:                       118.08
Time:                        16:29:37   Pearson chi2:                     118.
No. Iterations:                     3   Pseudo R-squ. (CS):          0.0004536
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.0022      0.027      0.083      0.934      -0.051       0.055
choice        -0.0186      0.034     -0.549      0.583      -0.085       0.048
==============================================================================
#+end_example

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
for i in range(1,2):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta).T[i], '-o', color=cols[i])
  print(np.round(np.array(pval).T[i], 3))
  for j, p in enumerate(np.array(pval).T[i]):
    if p < 0.05:
      plt.text(j+1, max(np.array(beta).T[i]) + .01, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('DOED $\\beta_{choice}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.    0.178 0.583 0.244 0.951 0.738]
[[./figures/landscape/figure_94.png]]
:END:

**** Behavior

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'dist_ED ~  behavior'

  results = []
  beta = []
  pval = []

  for day in y.day.unique():
      # data = y[(y['day'] == day) & (y['pair']==0)]
      data = y[(y['day'] == day)]
      glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

      result = glm.fit()
      results.append(result)
      beta.append(result.params)
      pval.append(result.pvalues)

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:                dist_ED   No. Observations:                  672
Model:                            GLM   Df Residuals:                      670
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.17423
Method:                          IRLS   Log-Likelihood:                -365.40
Date:                Wed, 28 Aug 2024   Deviance:                       116.73
Time:                        16:29:39   Pearson chi2:                     117.
No. Iterations:                     3   Pseudo R-squ. (CS):            0.01195
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     -0.0343      0.018     -1.875      0.061      -0.070       0.002
behavior       0.1096      0.039      2.841      0.004       0.034       0.185
==============================================================================
#+end_example

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
for i in range(1, 2):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta).T[i], '-o', color=cols[i])
  print(np.round(np.array(pval).T[i], 3))
  for j, p in enumerate(np.array(pval).T[i]):
    if p < 0.05:
      plt.text(j+1, max(np.array(beta).T[i]) + .01, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('$\\beta_{behavior}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.715 0.    0.004 0.016 0.136 0.889]
[[./figures/landscape/figure_96.png]]
:END:

*** Dist sign OED
**** Choice

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'OED_sign ~  choice'

  results = []
  beta = []
  pval = []

  for day in y.day.unique():
      # data = y[(y['day'] == day) & (y['pair']==0)]
      data = y[(y['day'] == day)]
      glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

      result = glm.fit()
      results.append(result)
      beta.append(result.params)
      pval.append(result.pvalues)

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:               OED_sign   No. Observations:                  672
Model:                            GLM   Df Residuals:                      670
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.24450
Method:                          IRLS   Log-Likelihood:                -479.26
Date:                Wed, 28 Aug 2024   Deviance:                       163.82
Time:                        16:29:40   Pearson chi2:                     164.
No. Iterations:                     3   Pseudo R-squ. (CS):          1.458e-05
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.5768      0.032     18.108      0.000       0.514       0.639
choice         0.0033      0.040      0.083      0.934      -0.075       0.081
==============================================================================
#+end_example

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
for i in range(1,2):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta).T[i], '-o', color=cols[i])
  print(np.round(np.array(pval).T[i], 3))
  for j, p in enumerate(np.array(pval).T[i]):
    if p < 0.05:
      plt.text(j+1, max(np.array(beta).T[i]) + .01, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('sign(DOED) $\\beta_{choice}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.012 0.482 0.934 0.061 0.607 0.817]
[[./figures/landscape/figure_98.png]]
:END:

**** Behavior

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('int')

  formula = 'OED_sign ~  behavior'

  results = []
  beta = []
  pval = []

  for day in y.day.unique():
      # data = y[(y['day'] == day) & (y['pair']==0)]
      data = y[(y['day'] == day)]
      glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())

      result = glm.fit()
      results.append(result)
      beta.append(result.params)
      pval.append(result.pvalues)

print(results[2].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:               OED_sign   No. Observations:                  672
Model:                            GLM   Df Residuals:                      670
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.24249
Method:                          IRLS   Log-Likelihood:                -476.48
Date:                Wed, 28 Aug 2024   Deviance:                       162.47
Time:                        16:29:42   Pearson chi2:                     162.
No. Iterations:                     3   Pseudo R-squ. (CS):           0.008280
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.5547      0.022     25.712      0.000       0.512       0.597
behavior       0.1075      0.046      2.363      0.018       0.018       0.197
==============================================================================
#+end_example

#+begin_src ipython
cols = ['r', 'b', 'g', 'r', 'b', 'g']
for i in range(1, 2):
  plt.plot(np.arange(1, options['n_days']+1), np.array(beta).T[i], '-o', color=cols[i])
  print(np.round(np.array(pval).T[i], 3))
  for j, p in enumerate(np.array(pval).T[i]):
    if p < 0.05:
      plt.text(j+1, max(np.array(beta).T[i]) + .01, '*', ha='center', va='bottom', color=cols[i])

plt.xlabel('Day')
plt.ylabel('sign(DOED) $\\beta_{behavior}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.092 0.    0.018 0.001 0.576 0.628]
[[./figures/landscape/figure_100.png]]
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

** overlaps day

*** Sample LD

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf
  import os
  os.environ['R_LIBS_USER'] = '~/R/x86_64-pc-linux-gnu-library/4.3/'

  from rpy2.robjects.packages import importr
  lmer = importr("~/R/x86_64-pc-linux-gnu-library/4.3/lme4/R/lme4")
  # from pymer4.models import Lmer

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('int')

  print(y.behavior.unique())

  formula = 'behavior ~ day * tasks * sample_LD + (1|mouse)'

  results = []
  data = y.copy()
  data['sample_LD'] = -(2*data.sample_odor-1) * data['sample_LD']

  glm = lmer(formula=formula, data=data, family='binomial')
  # glm = smf.glm(formula=formula, data=data, family=sm.families.Binomial())
  # glm = smf.mixedlm(formula, data, groups=data['mouse'], re_formula='1')
  result = glm.fit()
  pval = result.pvalues

  print(result.summary())
    #+end_src


#+begin_src ipython
import rpy2.robjects as robjects
from rpy2.robjects.packages import importr

# Set the .libPaths in R
custom_r_libpath = '~/R/x86_64-pc-linux-gnu-library/4.3/'
robjects.r('.libPaths("{0}")'.format(custom_r_libpath))

from pymer4.models import Lmer
#+end_src

#+RESULTS:

#+begin_src ipython
  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('int')

  print(y.behavior.unique())

  formula = 'behavior ~ day * tasks * sample_LD + (1|mouse)'

  results = []
  data = y.copy()
  data['sample_LD'] = -(2*data.sample_odor-1) * data['sample_LD']

  formula = 'behavior ~ day * tasks * sample_LD + (1|mouse)'
  glm = Lmer(formula=formula, data=data, family='binomial')
  # glm = smf.glm(formula=formula, data=data, family=sm.families.Binomial())
  # glm = smf.mixedlm(formula, data, groups=data['mouse'], re_formula='1')
  result = glm.fit()
  pval = result.pvalues

  print(result.summary())

#+end_src

#+RESULTS:

#+begin_src ipython
  print(glm.summary())
#+end_src


#+begin_src ipython
random_effects = glm.ranef
print(random_effects)
#+end_src

#+RESULTS:
:          X.Intercept.
: ACCM03       0.202566
: ACCM04       0.726651
: ChRM04      -0.436518
: JawsM15      0.273253
: JawsM18     -0.751546

#+begin_src ipython
print(result['P-val'])
#+end_src

#+RESULTS:
#+begin_example
(Intercept)                    0.311
day                            0.000
tasksDualGo                    0.243
tasksDualNoGo                  0.952
sample_LD                      0.027
day:tasksDualGo                0.594
day:tasksDualNoGo              0.821
day:sample_LD                  0.001
tasksDualGo:sample_LD          0.202
tasksDualNoGo:sample_LD        0.525
day:tasksDualGo:sample_LD      0.023
day:tasksDualNoGo:sample_LD    0.145
Name: P-val, dtype: float64
#+end_example

#+begin_src ipython
plt.figure(figsize=(15, 5))
colors = ['blue', 'green', 'red', 'purple', 'orange']
space = np.array([-0.1,-0.05, 0.0, 0.05, 0.1]) * .1

keys = ['(Intercept)', 'day', 'tasksDualGo', 'tasksDualNoGo', 'sample_LD']
# keys = result.Estimate.keys()
for i, key in enumerate(keys):
     df = result.Estimate[key] + random_effects

     mean_value = df['X.Intercept.'].mean()
     std_dev = df['X.Intercept.'].std()

     if result['P-val'][key]<0.001:
          plt.text(i,   1.01, '***', ha='center', va='bottom')

     elif result['P-val'][key]<0.01:
          plt.text(i,   1.01, '**', ha='center', va='bottom')

     elif result['P-val'][key]<0.05:
          plt.text(i,   1.01, '*', ha='center', va='bottom')

     # Plot individual points
     plt.scatter(i * np.ones(df.shape[0]) + space, df['X.Intercept.'], color=colors)
     # Plot mean and stddev as error bars
     plt.plot(i, mean_value, '_k', ms=20)
     plt.errorbar(i * np.ones(df.shape[0]), [mean_value]*len(df), yerr=[std_dev]*len(df), fmt='-', linestyle='None', color='k', capsize=15)

plt.axhline(y=0, color='black', linestyle='--')
plt.xticks(np.arange(len(keys)), keys)
plt.ylabel('$\\beta$')
plt.show()
#+end_src

#+RESULTS:
[[./figures/landscape/figure_109.png]]
#+RESULTS:

#+begin_src ipython
plt.figure(figsize=(15, 5))
colors = ['blue', 'green', 'red', 'purple', 'orange']
space = np.array([-0.1,-0.05, 0.0, 0.05, 0.1]) * .1

keys = ['day:tasksDualGo', 'day:tasksDualNoGo', 'day:sample_LD']
# keys = result.Estimate.keys()
for i, key in enumerate(keys):
     df = result.Estimate[key] + random_effects

     mean_value = df['X.Intercept.'].mean()
     std_dev = df['X.Intercept.'].std()

     # Plot individual points
     plt.scatter(i * np.ones(df.shape[0]) + space, df['X.Intercept.'], color=colors)
     # Plot mean and stddev as error bars
     plt.plot(i, mean_value, '_k', ms=20)
     plt.errorbar(i * np.ones(df.shape[0]), [mean_value]*len(df), yerr=[std_dev]*len(df), fmt='-', linestyle='None', color='k', capsize=15)

plt.axhline(y=0, color='black', linestyle='--')
plt.xticks(np.arange(len(keys)), keys)
plt.ylabel('$\\beta$')
plt.show()
#+end_src

#+RESULTS:
[[./figures/landscape/figure_110.png]]



#+begin_src ipython
df = intercepts
# Step 3: Calculate mean and standard deviation
mean_value = df['X.Intercept.'].mean()
std_dev = df['X.Intercept.'].std()

# Step 4: Plotting the data
plt.figure(figsize=(10, 5))

colors = ['blue', 'green', 'red', 'purple', 'orange']
space = np.array([-0.1,-0.05, 0.0, 0.05, 0.1]) * .1
# Plot individual points
plt.scatter(np.ones(df.shape[0]) + space, df['X.Intercept.'], label='Intercepts', color=colors)
# Plot mean and stddev as error bars
plt.plot(1, mean_value, 'ok')
plt.errorbar(np.ones(df.shape[0]), [mean_value]*len(df), yerr=[std_dev]*len(df), fmt='-', linestyle='None', color='k', capsize=15, label='Mean ± Std. Dev')

# Adding labels and title
plt.xlim([.85, 1.15])
plt.xticks([1], ['Intercept'])
plt.ylabel('$\\beta$')
plt.legend(fontsize=10)

#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.legend.Legend at 0x7fe4f3b79010>
[[./figures/landscape/figure_110.png]]
:END:

#+begin_src ipython
pval_DPA = [result.pvalues[j] for i, j in enumerate(result.params.keys()) if i<options['n_days']]
pval_Go = [result.pvalues[i] for i in result.params.keys() if 'DualGo' in i]
pval_NoGo = [result.pvalues[i] for i in result.params.keys() if 'DualNoGo' in i]
#+end_src

#+RESULTS:

#+begin_src ipython
coefs_DPA = [result.params[j] for i, j in enumerate(result.params.keys()) if i<options['n_days']]
coefs_Go = [result.params[i] for i in result.params.keys() if 'DualGo' in i]
coefs_NoGo = [result.params[i] for i in result.params.keys() if 'DualNoGo' in i]
#+end_src

#+RESULTS:

#+begin_src ipython
plt.plot(np.arange(1, options['n_days']+1), coefs_DPA, '-o', color='r')
plt.plot(np.arange(1, options['n_days']+1), coefs_Go, '-o', color='b')
plt.plot(np.arange(1, options['n_days']+1), coefs_NoGo, '-o', color='g')

print(np.round(pval_DPA, 3))
print(np.round(pval_Go, 3))
print(np.round(pval_NoGo, 3))

for i in range(len(coefs_DPA)):
    if pval_DPA[i] < 0.05:
        plt.text(i+1, .01, '*', ha='center', va='bottom', color='r')
    if pval_Go[i] < 0.05:
        plt.text(i+1, .05, '*', ha='center', va='bottom', color='b')
    if pval_NoGo[i] < 0.05:
        plt.text(i+1, .1, '*', ha='center', va='bottom', color='g')

plt.xlabel('Day')
plt.ylabel('SOLD $\\beta_{day}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.041 0.198 0.288 0.    0.014 0.002]
: [0.024 0.774 0.218 0.003 0.245 0.007]
: [0.099 0.701 0.794 0.567 0.237 0.535]
[[./figures/landscape/figure_105.png]]
:END:


#+RESULTS:
#+begin_src ipython

#+end_src

#+RESULTS:

*** sign Sample LD

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')

  formula = 'OLD_sign ~ day * tasks'

  results = []
  glm = smf.glm(formula=formula, data=y, family=sm.families.Gaussian())
  # glm = smf.mixedlm(formula, y, groups=y['day'], re_formula='1')
  result = glm.fit()
  pval = result.pvalues

  print(result.summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:               OLD_sign   No. Observations:                 3648
Model:                            GLM   Df Residuals:                     3630
Model Family:                Gaussian   Df Model:                           17
Link Function:               Identity   Scale:                         0.16200
Method:                          IRLS   Log-Likelihood:                -1847.3
Date:                Wed, 28 Aug 2024   Deviance:                       588.06
Time:                        16:34:20   Pearson chi2:                     588.
No. Iterations:                     3   Pseudo R-squ. (CS):            0.02084
Covariance Type:            nonrobust
================================================================================================
                                   coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------------------
Intercept                        0.1875      0.027      6.972      0.000       0.135       0.240
day[T.2.0]                      -0.0312      0.038     -0.822      0.411      -0.106       0.043
day[T.3.0]                      -0.0134      0.038     -0.352      0.725      -0.088       0.061
day[T.4.0]                      -0.0536      0.038     -1.409      0.159      -0.128       0.021
day[T.5.0]                     1.01e-15      0.038   2.65e-14      1.000      -0.075       0.075
day[T.6.0]                      -0.0104      0.049     -0.212      0.832      -0.107       0.086
tasks[T.DualGo]                 -0.0313      0.038     -0.822      0.411      -0.106       0.043
tasks[T.DualNoGo]                0.0179      0.038      0.470      0.639      -0.057       0.092
day[T.2.0]:tasks[T.DualGo]       0.0580      0.054      1.079      0.281      -0.047       0.163
day[T.3.0]:tasks[T.DualGo]       0.2500      0.054      4.648      0.000       0.145       0.355
day[T.4.0]:tasks[T.DualGo]       0.0804      0.054      1.494      0.135      -0.025       0.186
day[T.5.0]:tasks[T.DualGo]       0.0759      0.054      1.411      0.158      -0.030       0.181
day[T.6.0]:tasks[T.DualGo]       0.0417      0.069      0.600      0.548      -0.094       0.178
day[T.2.0]:tasks[T.DualNoGo]     0.0670      0.054      1.245      0.213      -0.038       0.172
day[T.3.0]:tasks[T.DualNoGo]    -0.0045      0.054     -0.083      0.934      -0.110       0.101
day[T.4.0]:tasks[T.DualNoGo]     0.0893      0.054      1.660      0.097      -0.016       0.195
day[T.5.0]:tasks[T.DualNoGo]     0.0580      0.054      1.079      0.281      -0.047       0.163
day[T.6.0]:tasks[T.DualNoGo]     0.0446      0.069      0.643      0.520      -0.091       0.181
================================================================================================
#+end_example

#+begin_src ipython
pval_DPA = [result.pvalues[j] for i, j in enumerate(result.params.keys()) if i<options['n_days']]
pval_Go = [result.pvalues[i] for i in result.params.keys() if 'DualGo' in i]
pval_NoGo = [result.pvalues[i] for i in result.params.keys() if 'DualNoGo' in i]
#+end_src

#+RESULTS:

#+begin_src ipython
coefs_DPA = [result.params[j] for i, j in enumerate(result.params.keys()) if i<options['n_days']]
coefs_Go = [result.params[i] for i in result.params.keys() if 'DualGo' in i]
coefs_NoGo = [result.params[i] for i in result.params.keys() if 'DualNoGo' in i]
#+end_src

#+RESULTS:

#+begin_src ipython
plt.plot(np.arange(1, options['n_days']+1), coefs_DPA, '-o', color='r')
plt.plot(np.arange(1, options['n_days']+1), coefs_Go, '-o', color='b')
plt.plot(np.arange(1, options['n_days']+1), coefs_NoGo, '-o', color='g')

print(np.round(pval_DPA, 3))
print(np.round(pval_Go, 3))
print(np.round(pval_NoGo, 3))

for i in range(len(coefs_DPA)):
    if pval_DPA[i] < 0.05:
        plt.text(i+1, .01, '*', ha='center', va='bottom', color='r')
    if pval_Go[i] < 0.05:
        plt.text(i+1, .05, '*', ha='center', va='bottom', color='b')
    if pval_NoGo[i] < 0.05:
        plt.text(i+1, .1, '*', ha='center', va='bottom', color='g')

plt.xlabel('Day')
plt.ylabel('sign(SOLD) $\\beta_{day}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.    0.411 0.725 0.159 1.    0.832]
: [0.411 0.281 0.    0.135 0.158 0.548]
: [0.639 0.213 0.934 0.097 0.281 0.52 ]
[[./figures/landscape/figure_110.png]]
:END:


#+RESULTS:
#+begin_src ipython

#+end_src

#+RESULTS:


*** dist ED

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')

  formula = 'dist_ED ~ day * tasks'

  results = []
  glm = smf.glm(formula=formula, data=y, family=sm.families.Gaussian())
  # glm = smf.mixedlm(formula, y, groups=y['day'], re_formula='1')
  result = glm.fit()
  pval = result.pvalues

  print(result.summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:                dist_ED   No. Observations:                 3648
Model:                            GLM   Df Residuals:                     3630
Model Family:                Gaussian   Df Model:                           17
Link Function:               Identity   Scale:                         0.22039
Method:                          IRLS   Log-Likelihood:                -2408.7
Date:                Wed, 28 Aug 2024   Deviance:                       800.02
Time:                        16:34:46   Pearson chi2:                     800.
No. Iterations:                     3   Pseudo R-squ. (CS):            0.08119
Covariance Type:            nonrobust
================================================================================================
                                   coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------------------
Intercept                        0.1062      0.031      3.384      0.001       0.045       0.168
day[T.2.0]                      -0.1781      0.044     -4.014      0.000      -0.265      -0.091
day[T.3.0]                      -0.0950      0.044     -2.141      0.032      -0.182      -0.008
day[T.4.0]                      -0.1120      0.044     -2.526      0.012      -0.199      -0.025
day[T.5.0]                      -0.2633      0.044     -5.936      0.000      -0.350      -0.176
day[T.6.0]                      -0.3259      0.057     -5.691      0.000      -0.438      -0.214
tasks[T.DualGo]                  0.1092      0.044      2.461      0.014       0.022       0.196
tasks[T.DualNoGo]               -0.1060      0.044     -2.389      0.017      -0.193      -0.019
day[T.2.0]:tasks[T.DualGo]      -0.0153      0.063     -0.243      0.808      -0.138       0.108
day[T.3.0]:tasks[T.DualGo]      -0.0646      0.063     -1.030      0.303      -0.188       0.058
day[T.4.0]:tasks[T.DualGo]      -0.1031      0.063     -1.643      0.100      -0.226       0.020
day[T.5.0]:tasks[T.DualGo]       0.1380      0.063      2.200      0.028       0.015       0.261
day[T.6.0]:tasks[T.DualGo]      -0.0212      0.081     -0.262      0.793      -0.180       0.138
day[T.2.0]:tasks[T.DualNoGo]    -0.0168      0.063     -0.267      0.789      -0.140       0.106
day[T.3.0]:tasks[T.DualNoGo]    -0.0012      0.063     -0.019      0.985      -0.124       0.122
day[T.4.0]:tasks[T.DualNoGo]    -0.0025      0.063     -0.040      0.968      -0.125       0.120
day[T.5.0]:tasks[T.DualNoGo]    -0.0667      0.063     -1.063      0.288      -0.190       0.056
day[T.6.0]:tasks[T.DualNoGo]     0.0113      0.081      0.140      0.889      -0.147       0.170
================================================================================================
#+end_example

#+begin_src ipython
pval_DPA = [result.pvalues[j] for i, j in enumerate(result.params.keys()) if i<options['n_days']]
pval_Go = [result.pvalues[i] for i in result.params.keys() if 'DualGo' in i]
pval_NoGo = [result.pvalues[i] for i in result.params.keys() if 'DualNoGo' in i]
#+end_src

#+RESULTS:

#+begin_src ipython
coefs_DPA = [result.params[j] for i, j in enumerate(result.params.keys()) if i<options['n_days']]
coefs_Go = [result.params[i] for i in result.params.keys() if 'DualGo' in i]
coefs_NoGo = [result.params[i] for i in result.params.keys() if 'DualNoGo' in i]
#+end_src

#+RESULTS:

#+begin_src ipython
plt.plot(np.arange(1, options['n_days']+1), coefs_DPA, '-o', color='r')
plt.plot(np.arange(1, options['n_days']+1), coefs_Go, '-o', color='b')
plt.plot(np.arange(1, options['n_days']+1), coefs_NoGo, '-o', color='g')

print(np.round(pval_DPA, 3))
print(np.round(pval_Go, 3))
print(np.round(pval_NoGo, 3))

for i in range(len(coefs_DPA)):
    if pval_DPA[i] < 0.05:
        plt.text(i+1, .01, '*', ha='center', va='bottom', color='r')
    if pval_Go[i] < 0.05:
        plt.text(i+1, .05, '*', ha='center', va='bottom', color='b')
    if pval_NoGo[i] < 0.05:
        plt.text(i+1, .1, '*', ha='center', va='bottom', color='g')

plt.xlabel('Day')
plt.ylabel('DOED $\\beta_{day}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.001 0.    0.032 0.012 0.    0.   ]
: [0.014 0.808 0.303 0.1   0.028 0.793]
: [0.017 0.789 0.985 0.968 0.288 0.889]
[[./figures/landscape/figure_115.png]]
:END:


#+RESULTS:
#+begin_src ipython

#+end_src

#+RESULTS:

*** sign dist ED

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')

  formula = 'OED_sign ~ day * tasks'

  results = []
  glm = smf.glm(formula=formula, data=y, family=sm.families.Gaussian())
  # glm = smf.mixedlm(formula, y, groups=y['day'], re_formula='1')
  result = glm.fit()
  pval = result.pvalues

  print(result.summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:               OED_sign   No. Observations:                 3648
Model:                            GLM   Df Residuals:                     3630
Model Family:                Gaussian   Df Model:                           17
Link Function:               Identity   Scale:                         0.23677
Method:                          IRLS   Log-Likelihood:                -2539.5
Date:                Wed, 28 Aug 2024   Deviance:                       859.47
Time:                        16:35:26   Pearson chi2:                     859.
No. Iterations:                     3   Pseudo R-squ. (CS):            0.05890
Covariance Type:            nonrobust
================================================================================================
                                   coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------------------
Intercept                        0.5714      0.033     17.576      0.000       0.508       0.635
day[T.2.0]                      -0.1473      0.046     -3.204      0.001      -0.237      -0.057
day[T.3.0]                       0.0313      0.046      0.680      0.497      -0.059       0.121
day[T.4.0]                      -0.0357      0.046     -0.777      0.437      -0.126       0.054
day[T.5.0]                      -0.2054      0.046     -4.466      0.000      -0.295      -0.115
day[T.6.0]                      -0.1652      0.059     -2.783      0.005      -0.282      -0.049
tasks[T.DualGo]                  0.1071      0.046      2.330      0.020       0.017       0.197
tasks[T.DualNoGo]               -0.0938      0.046     -2.039      0.041      -0.184      -0.004
day[T.2.0]:tasks[T.DualGo]       0.0268      0.065      0.412      0.680      -0.101       0.154
day[T.3.0]:tasks[T.DualGo]      -0.0268      0.065     -0.412      0.680      -0.154       0.101
day[T.4.0]:tasks[T.DualGo]      -0.1295      0.065     -1.991      0.046      -0.257      -0.002
day[T.5.0]:tasks[T.DualGo]       0.1250      0.065      1.922      0.055      -0.002       0.252
day[T.6.0]:tasks[T.DualGo]      -0.0030      0.084     -0.035      0.972      -0.168       0.162
day[T.2.0]:tasks[T.DualNoGo]    -0.0536      0.065     -0.824      0.410      -0.181       0.074
day[T.3.0]:tasks[T.DualNoGo]    -0.0580      0.065     -0.893      0.372      -0.185       0.069
day[T.4.0]:tasks[T.DualNoGo]     0.0357      0.065      0.549      0.583      -0.092       0.163
day[T.5.0]:tasks[T.DualNoGo]    -0.0089      0.065     -0.137      0.891      -0.136       0.119
day[T.6.0]:tasks[T.DualNoGo]     0.1146      0.084      1.365      0.172      -0.050       0.279
================================================================================================
#+end_example

#+begin_src ipython
pval_DPA = [result.pvalues[j] for i, j in enumerate(result.params.keys()) if i<options['n_days']]
pval_Go = [result.pvalues[i] for i in result.params.keys() if 'DualGo' in i]
pval_NoGo = [result.pvalues[i] for i in result.params.keys() if 'DualNoGo' in i]
#+end_src

#+RESULTS:

#+begin_src ipython
coefs_DPA = [result.params[j] for i, j in enumerate(result.params.keys()) if i<options['n_days']]
coefs_Go = [result.params[i] for i in result.params.keys() if 'DualGo' in i]
coefs_NoGo = [result.params[i] for i in result.params.keys() if 'DualNoGo' in i]
#+end_src

#+RESULTS:

#+begin_src ipython
plt.plot(np.arange(1, options['n_days']+1), coefs_DPA, '-o', color='r')
plt.plot(np.arange(1, options['n_days']+1), coefs_Go, '-o', color='b')
plt.plot(np.arange(1, options['n_days']+1), coefs_NoGo, '-o', color='g')

print(np.round(pval_DPA, 3))
print(np.round(pval_Go, 3))
print(np.round(pval_NoGo, 3))

for i in range(len(coefs_DPA)):
    if pval_DPA[i] < 0.05:
        plt.text(i+1, .01, '*', ha='center', va='bottom', color='r')
    if pval_Go[i] < 0.05:
        plt.text(i+1, .05, '*', ha='center', va='bottom', color='b')
    if pval_NoGo[i] < 0.05:
        plt.text(i+1, .1, '*', ha='center', va='bottom', color='g')

plt.xlabel('Day')
plt.ylabel('sign(DOED) $\\beta_{day}$')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: [0.    0.001 0.497 0.437 0.    0.005]
: [0.02  0.68  0.68  0.046 0.055 0.972]
: [0.041 0.41  0.372 0.583 0.891 0.172]
[[./figures/landscape/figure_120.png]]
:END:

#+RESULTS:
#+begin_src ipython

#+end_src

#+RESULTS:
