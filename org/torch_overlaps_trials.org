#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session decoder :kernel dual_data :exports results :output-dir ./figures/landscape :file (lc/org-babel-tangle-figure-filename)

Look at incorrect trials vs correct trials, trial by trial

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python

* Imports

#+begin_src ipython
  from sklearn.exceptions import ConvergenceWarning
  warnings.filterwarnings("ignore")

  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import os
  if not sys.warnoptions:
    warnings.simplefilter("ignore")
    os.environ["PYTHONWARNINGS"] = "ignore"

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  from time import perf_counter

  import torch
  import torch.nn as nn
  import torch.optim as optim
  from skorch import NeuralNetClassifier

  from sklearn.base import clone
  from sklearn.metrics import make_scorer, roc_auc_score
  from sklearn.ensemble import BaggingClassifier
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.pipeline import Pipeline
  from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, LeaveOneOut
  from sklearn.decomposition import PCA

  from mne.decoding import SlidingEstimator, cross_val_multiscore, GeneralizingEstimator, get_coef

  from src.common.plot_utils import add_vlines, add_vdashed
  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.decode.bump import decode_bump, circcvl
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.decode.classifiers import safeSelector
  from src.preprocess.helpers import avg_epochs
#+end_src

#+RESULTS:

* Helpers
** Perceptron

#+begin_src ipython :tangle ../src/torch/perceptron.py
  import torch
  import torch.nn as nn

  class CustomBCEWithLogitsLoss(nn.BCEWithLogitsLoss):
      def __init__(self, pos_weight=None, weight=None, reduction='mean'):
          super(CustomBCEWithLogitsLoss, self).__init__(weight=weight, reduction=reduction, pos_weight=pos_weight)

      def forward(self, input, target):
          target = target.view(-1, 1)  # Make sure target shape is (n_samples, 1)
          return super().forward(input.to(torch.float32), target.to(torch.float32))
#+end_src

#+RESULTS:

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/perceptron.py
  class Perceptron(nn.Module):
      def __init__(self, num_features, dropout_rate=0.0):
          super(Perceptron, self).__init__()
          self.linear = nn.Linear(num_features, 1)
          self.dropout = nn.Dropout(dropout_rate)

      def forward(self, x):
          x = self.dropout(x)
          hidden = self.linear(x)
          return hidden
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/perceptron.py
  class MLP(nn.Module):
      def __init__(self, num_features, hidden_units=64, dropout_rate=0.5):
          super(MLP, self).__init__()
          self.linear = nn.Linear(num_features, hidden_units)
          self.dropout = nn.Dropout(dropout_rate)
          self.relu = nn.ReLU()
          self.linear2 = nn.Linear(hidden_units, 1)

      def forward(self, x):
          x = self.dropout(x)
          x = self.relu(self.linear(x))
          x = self.dropout(x)
          hidden = self.linear2(x)
          return hidden
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/skorch.py
  import torch
  from skorch import NeuralNetClassifier
  from skorch.callbacks import Callback
  from skorch.callbacks import EarlyStopping

  early_stopping = EarlyStopping(
      monitor='train_loss',    # Metric to monitor
      patience=10,              # Number of epochs to wait for improvement
      threshold=0.001,       # Minimum change to qualify as an improvement
      threshold_mode='rel',    # 'rel' for relative change, 'abs' for absolute change
      lower_is_better=True     # Set to True if lower metric values are better
  )

  class RegularizedNet(NeuralNetClassifier):
      def __init__(self, module, alpha=0.001, l1_ratio=0.95, **kwargs):
          self.alpha = alpha  # Regularization strength
          self.l1_ratio = l1_ratio # Balance between L1 and L2 regularization

          super().__init__(module, **kwargs)

      def get_loss(self, y_pred, y_true, X=None, training=False):
          # Call super method to compute primary loss
          if y_pred.shape != y_true.shape:
              y_true = y_true.unsqueeze(-1)

          loss = super().get_loss(y_pred, y_true, X=X, training=training)

          if self.alpha>0:
              elastic_net_reg = 0
              for param in self.module_.parameters():
                  elastic_net_reg += self.alpha * self.l1_ratio * torch.sum(torch.abs(param))
                  elastic_net_reg += self.alpha * (1 - self.l1_ratio) * torch.sum(param ** 2)

          # Add the elastic net regularization term to the primary loss
          return loss + elastic_net_reg
#+end_src

#+RESULTS:

** Model
#+begin_src ipython
  def get_bagged_coefs(clf, n_estimators):
      coefs_list = []
      bias_list = []
      for i in range(n_estimators):
          model = clf.estimators_[i]
          try:
              coefs = model.named_steps['net'].module_.linear.weight.data.cpu().detach().numpy()[0]
              bias = model.named_steps['net'].module_.linear.bias.data.cpu().detach().numpy()[0]
          except:
              coefs = model.named_steps['net'].coef_.T
              bias = model.named_steps['net'].intercept_.T

          # coefs, bias = rescale_coefs(model, coefs, bias)

          coefs_list.append(coefs)
          bias_list.append(bias)

      return np.array(coefs_list).mean(0), np.array(bias_list).mean(0)
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/classificationCV.py
  from time import perf_counter
  from sklearn.ensemble import BaggingClassifier
  from sklearn.preprocessing import StandardScaler
  from sklearn.pipeline import Pipeline
  from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, LeaveOneOut
  from sklearn.decomposition import PCA

  from mne.decoding import SlidingEstimator, cross_val_multiscore

  class ClassificationCV():
      def __init__(self, net, params, **kwargs):

          pipe = []
          self.scaler = kwargs['scaler']
          if self.scaler is not None and self.scaler !=0 :
              pipe.append(("scaler", StandardScaler()))

          self.n_comp = kwargs['n_comp']
          if kwargs['n_comp'] is not None:
              self.n_comp = kwargs['n_comp']
              pipe.append(("pca", PCA(n_components=self.n_comp)))

          self.prescreen = kwargs['prescreen']
          self.alpha = kwargs['pval']
          if kwargs["prescreen"] is not None:
              pipe.append(("filter", safeSelector(method=kwargs['prescreen'] , alpha=kwargs["pval"])))

          pipe.append(("net", net))
          self.model = Pipeline(pipe)

          self.num_features = kwargs['num_features']
          self.scoring =  kwargs['scoring']

          if  kwargs['n_splits']==-1:
              self.cv = LeaveOneOut()
          else:
              self.cv = RepeatedStratifiedKFold(n_splits=kwargs['n_splits'], n_repeats=kwargs['n_repeats'])

          self.params = params
          self.verbose =  kwargs['verbose']
          self.n_jobs =  kwargs['n_jobs']

      def fit(self, X, y):
          start = perf_counter()
          if self.verbose:
              print('Fitting hyperparameters ...')

          try:
              self.model['net'].module__num_features = self.num_features
          except:
              pass

          grid = GridSearchCV(self.model, self.params, refit=True, cv=self.cv, scoring=self.scoring, n_jobs=self.n_jobs)
          grid.fit(X.astype('float32'), y.astype('float32'))
          end = perf_counter()
          if self.verbose:
              print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

          self.best_model = grid.best_estimator_
          self.best_params = grid.best_params_

          if self.verbose:
              print(self.best_params)

          try:
              self.coefs = self.best_model.named_steps['net'].module_.linear.weight.data.cpu().detach().numpy()[0]
              self.bias = self.best_model.named_steps['net'].module_.linear.bias.data.cpu().detach().numpy()[0]
          except:
              self.coefs = self.best_model.named_steps['net'].coef_.T
              self.bias = self.best_model.named_steps['net'].intercept_.T

      def get_bootstrap_coefs(self, X, y, n_boots=10):
          start = perf_counter()
          if self.verbose:
              print('Bootstrapping coefficients ...')

          self.bagging_clf = BaggingClassifier(base_estimator=self.best_model, n_estimators=n_boots)
          self.bagging_clf.fit(X.astype('float32'), y.astype('float32'))
          end = perf_counter()

          if self.verbose:
              print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

          self.coefs, self.bias = get_bagged_coefs(self.bagging_clf, n_estimators=n_boots)

          return self.coefs, self.bias


      def get_overlap(self, model, X):
          try:
              coefs = model.named_steps['net'].module_.linear.weight.data.cpu().detach().numpy()[0]
              bias = model.named_steps['net'].module_.linear.bias.data.cpu().detach().numpy()[0]
          except:
              coefs = model.named_steps['net'].coef_.T
              bias = model.named_steps['net'].intercept_.T

          if self.scaler is not None and self.scaler!=0:
              scaler = model.named_steps['scaler']
              for i in range(X.shape[-1]):
                  X[..., i] = scaler.transform(X[..., i])

          if (self.prescreen is not None) and (self.prescreen != 0):
              filter = model.named_steps['filter']
              idx = filter.selector.get_support(indices=True)
              self.overlaps = (np.swapaxes(X[:, idx], 1, -1) @ coefs) / np.linalg.norm(coefs, axis=0)

          elif (self.n_comp is not None) and (self.n_comp != 0):
              pca = model.named_steps['pca']
              X_pca = np.zeros((X.shape[0], self.n_comp, X.shape[-1]))

              for i in range(X.shape[-1]):
                  X_pca[..., i] = pca.transform(X[..., i])

              self.overlaps = (np.swapaxes(X_pca, 1, -1) @ coefs + bias) # / np.linalg.norm(coefs, axis=0)
          else:
              self.overlaps = -(np.swapaxes(X, 1, -1) @ coefs) / np.linalg.norm(coefs, axis=0)
              # self.overlaps = -(np.swapaxes(X, 1, -1) @ coefs + bias) / np.linalg.norm(coefs, axis=0)

          return self.overlaps

      def get_bootstrap_overlaps(self, X):
          start = perf_counter()
          if self.verbose:
              print('Getting bootstrapped overlaps ...')

          X_copy = np.copy(X)
          overlaps_list = []
          n_boots = len(self.bagging_clf.estimators_)

          for i in range(n_boots):
              model = self.bagging_clf.estimators_[i]
              overlaps = self.get_overlap(model, X_copy)
              overlaps_list.append(overlaps)

          end = perf_counter()
          if self.verbose:
              print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

          return np.array(overlaps_list).mean(0)

      def get_cv_scores(self, X, y, scoring):
          start = perf_counter()
          if self.verbose:
              print('Computing cv scores ...')

          estimator = SlidingEstimator(clone(self.best_model), n_jobs=1,
                                       scoring=scoring, verbose=False)

          self.scores = cross_val_multiscore(estimator, X.astype('float32'), y.astype('float32'),
                                             cv=self.cv, n_jobs=-1, verbose=False)
          end = perf_counter()
          if self.verbose:
              print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

          return self.scores
#+end_src

#+RESULTS:

  #+begin_src ipython :tangle ../src/torch/main.py
    from src.common.get_data import get_X_y_days, get_X_y_S1_S2
    from src.preprocess.helpers import avg_epochs

    def get_classification(model, RETURN='overlaps', **options):
            start = perf_counter()

            dum = 0
            if options['features'] == 'distractor':
                    if options['task'] != 'Dual':
                            task = options['task']
                            options['task'] = 'Dual'
                            dum = 1

            X_days, y_days = get_X_y_days(**options)
            X, y = get_X_y_S1_S2(X_days, y_days, **options)

            y_labels = y.copy()

            if options['features'] == 'sample':
                y = y.sample_odor.dropna().to_numpy()
            elif options['features'] == 'distractor':
                y = y.dist_odor.dropna().to_numpy()
            elif options['features'] == 'choice':
                y = y.choice.to_numpy()

            y[y==-1] = 0

            if options['verbose']:
                print('X', X.shape, 'y', y.shape)

            X_avg = avg_epochs(X, **options).astype('float32')
            y_avg = y

            if options['trials'] == 'correct':
                options['trials'] = ''
                X, _ = get_X_y_S1_S2(X_days, y_days, **options)

            if dum:
                    options['features'] = 'sample'
                    options['task'] = task
                    X, _ = get_X_y_S1_S2(X_days, y_days, **options)

            # if options['class_weight']:
            #         pos_weight = torch.tensor(np.sum(y==0) / np.sum(y==1), device=DEVICE).to(torch.float32)
            #         print('imbalance', pos_weight)
            #         model.criterion__pos_weight = pos_weight

            if RETURN is None:
                return None
            else:
                model.fit(X_avg, y_avg)

            if 'scores' in RETURN:
                scores = model.get_cv_scores(X, y, options['scoring'])
                end = perf_counter()
                print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
                return scores
            elif 'overlaps' in RETURN:
                coefs, bias = model.get_bootstrap_coefs(X_avg, y_avg, n_boots=options['n_boots'])
                overlaps = model.get_bootstrap_overlaps(X)
                end = perf_counter()
                print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
                return overlaps, y_labels
            elif 'coefs' in RETURN:
                coefs, bias = model.get_bootstrap_coefs(X_avg, y_avg, n_boots=options['n_boots'])
                end = perf_counter()
                print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
                return coefs, bias
            else:
                return None
#+end_src

#+RESULTS:

** Other

#+begin_src ipython :tangle ../src/torch/utils.py
  import numpy as np

  def safe_roc_auc_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return np.nan  # return np.nan where the score cannot be calculated
      return roc_auc_score(y_true, y_score)
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def rescale_coefs(model, coefs, bias):

          try:
                  means = model.named_steps["scaler"].mean_
                  scales = model.named_steps["scaler"].scale_

                  # Rescale the coefficients
                  rescaled_coefs = np.true_divide(coefs, scales)

                  # Adjust the intercept
                  rescaled_bias = bias - np.sum(rescaled_coefs * means)

                  return rescaled_coefs, rescaled_bias
          except:
                  return coefs, bias

#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  from scipy.stats import bootstrap

  def get_bootstrap_ci(data, statistic=np.mean, confidence_level=0.95, n_resamples=1000, random_state=None):
      result = bootstrap((data,), statistic)
      ci_lower, ci_upper = result.confidence_interval
      return np.array([ci_lower, ci_upper])
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      pkl.dump(obj, open(path + "/" + name + ".pkl", "wb"))


  def pkl_load(name, path="."):
      return pkl.load(open(path + "/" + name, "rb"))

#+end_src

#+RESULTS:

* Parameters

#+begin_src ipython
  DEVICE = 'cuda:0'
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  N_NEURONS = [668, 693, 444, 361, 113]

  tasks = ['DPA', 'DualGo', 'DualNoGo']
  params = { 'net__alpha': np.logspace(-4, 4, 10),
             # 'net__l1_ratio': np.linspace(0, 1, 10),
             # 'net__module__dropout_rate': np.linspace(0, 1, 10),
            }

  # ['AP02', 'AP12', 'PP09', 'PP17', 'RP17']

  kwargs = {
      'mouse': 'JawsM15', 'laser': 0,
      'trials': '', 'reload': 0, 'data_type': 'dF',
      'prescreen': None, 'pval': 96,
      'preprocess': False, 'scaler_BL': 'robust',
      'avg_noise':True, 'unit_var_BL': True,
      'random_state': None, 'T_WINDOW': 0.0,
      'l1_ratio': 0.95,
      'n_comp': None, 'scaler': None,
      'bootstrap': 1, 'n_boots': 128,
      'n_splits': 3, 'n_repeats': 32,
      'class_weight': 0,
      'multilabel':0,
  }

  # kwargs['days'] = ['first', 'middle', 'last']
  options = set_options(**kwargs)
  days = np.arange(1, options['n_days']+1)
  # days = ['first', 'middle', 'last']

  safe_roc_auc = make_scorer(safe_roc_auc_score, needs_proba=True)
  options['scoring'] = safe_roc_auc
  options['n_jobs'] = 30
#+end_src

#+RESULTS:

* Decoding vs days
** RNN

#+begin_src ipython
net = RegularizedNet(
    module=Perceptron,
    module__num_features=693,
    module__dropout_rate=0.0,
    alpha=0.01,
    l1_ratio=options['l1_ratio'],
    criterion=CustomBCEWithLogitsLoss,
    criterion__pos_weight=torch.tensor(1.0, device=DEVICE).to(torch.float32),
    optimizer=optim.Adam,
    optimizer__lr=0.1,
    max_epochs=1000,
    callbacks=[early_stopping],
    train_split=None,
    iterator_train__shuffle=False,  # Ensure the data is shuffled each epoch
    verbose=0,
    device= DEVICE if torch.cuda.is_available() else 'cpu',  # Assuming you might want to use CUDA
    compile=True,
    warm_start=True,
)

options['verbose'] = 0
model = ClassificationCV(net, params, **options)
options['verbose'] = 1
#+end_src

#+RESULTS:

** sklearn

#+begin_src ipython
from sklearn.linear_model import LogisticRegression
# net = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', n_jobs=None)
net = LogisticRegression(penalty='elasticnet', solver='saga', class_weight='balanced', n_jobs=None, l1_ratio=0.95, max_iter=100, tol=.001)
# net = LogisticRegression(penalty='elasticnet', solver='saga', class_weight='balanced', n_jobs=None, l1_ratio=0.95, max_iter=100, tol=.001, multi_class='multinomial')

params = {'net__C': np.logspace(-4, 4, 10)}

options['n_jobs'] = -1
options['verbose'] = 0
model = ClassificationCV(net, params, **options)
options['verbose'] = 1
#+end_src

#+RESULTS:

** fit

#+begin_src ipython
  overlaps_sample = []
  overlaps_dist = []
  overlaps_choice = []

  for task in tasks:
    options['task'] = task

    overlaps_sample_task = []
    overlaps_dist_task = []
    overlaps_choice_task = []

    for day in days:
        options['day'] = day

        options['features'] = 'sample'
        options['epochs'] = ['ED']
        overlaps = get_classification(model, RETURN='overlaps', **options)
        overlaps_sample_task.append(overlaps)

        options['features'] = 'distractor'
        options['epochs'] = ['MD']
        overlaps = get_classification(model, RETURN='overlaps', **options)
        overlaps_dist_task.append(overlaps)

        # options['features'] = 'choice'
        # options['epochs'] = ['CHOICE']
        # overlaps = get_classification(model, RETURN='overlaps', **options)
        # overlaps_choice_task.append(overlaps)

    overlaps_sample.append(overlaps_sample_task)
    overlaps_dist.append(overlaps_dist_task)
    # overlaps_choice.append(overlaps_choice_task)
    #+end_src

#+RESULTS:
#+begin_example
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 1 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 33s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 1 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DPA TRIALS  DAYS 1 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 9s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 2 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 6s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 2 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DPA TRIALS  DAYS 2 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 3 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 6s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 3 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DPA TRIALS  DAYS 3 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 4 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 6s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 4 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DPA TRIALS  DAYS 4 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 5 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 6s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 5 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DPA TRIALS  DAYS 5 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 6 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 6s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 6 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DPA TRIALS  DAYS 6 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 1 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 6s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 1 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 1 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 2 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 6s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 2 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 2 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 3 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 6s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 3 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 3 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 4 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 6s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 4 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 4 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 5 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 6s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 5 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 5 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 6 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 6s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 6 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 6 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 1 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 6s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 1 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 1 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 2 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 6s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 2 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 2 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 3 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 6s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 3 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 3 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 4 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 5s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 4 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 4 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 5 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 5s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 5 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 5 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 6 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X (32, 693, 84) y (32,)
Elapsed (with compilation) = 0h 0m 6s
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 6 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
X (64, 693, 84) y (64,)
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 6 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Elapsed (with compilation) = 0h 0m 10s
#+end_example

#+begin_src ipython
print(overlaps_sample[2][2].shape)
#+end_src

#+RESULTS:
: (32, 84, 1)

#+begin_src ipython
overlaps_save = np.stack((overlaps_sample, overlaps_dist))
# overlaps_save = np.stack((overlaps_sample, overlaps_dist, overlaps_choice))
print(overlaps_save.shape)
pkl_save(overlaps_save, '%s_overlaps_tasks_%.2f_l1_ratio%s' % (options['mouse'], options['l1_ratio'], options['fname']), path="../data/%s/" % options['mouse'])
#+end_src

#+RESULTS:
: (2, 3, 6, 32, 84, 1)

* Overlaps

#+begin_src ipython
filename = '%s_overlaps_tasks_%.2f_l1_ratio%s.pkl' % (options['mouse'], options['l1_ratio'], options['fname'])
print(filename)
try:
      overlaps = pkl_load(filename, path="../data/%s/" % options['mouse'])
      print('overlaps', overlaps.shape)
except:
      print('file not found')
#+end_src

#+RESULTS:
: JawsM15_overlaps_tasks_0.95_l1_ratio.pkl
: overlaps (2, 3, 6, 32, 84, 1)

#+begin_src ipython
overlaps_sample = overlaps[0]
overlaps_dist = overlaps[1]
# overlaps_choice = overlaps[2]
print(overlaps_sample.shape)
#+end_src

#+RESULTS:
: (3, 6, 32, 84, 1)

#+begin_src ipython
options['n_days'] = 6

overlaps_sample = np.array(overlaps_sample)
print(overlaps_sample.shape)

overlaps_dist = np.array(overlaps_dist)
print(overlaps_dist.shape)
#+end_src

#+RESULTS:
: (3, 6, 32, 84, 1)
: (3, 6, 32, 84, 1)

#+begin_src ipython
  options['n_days'] = 6
  cmap = plt.get_cmap('Blues')
  colors = [cmap((i+1) / options['n_days'] ) for i in range(options['n_days'])]
  cmap = plt.get_cmap('Reds')
  colors2 = [cmap((i+1) / options['n_days'] ) for i in range(options['n_days'])]
  width = 6
  golden_ratio = (5**.5 - 1) / 2

  task = 1
  # mask = ~np.isnan(overlaps_dist).any(axis=2)
  # overlaps_dist = overlaps_dist[:, mask.any(axis=0)]
  options['features'] = 'choice'
  options['preprocess'] = False
  X_days, y_days = get_X_y_days(**options)

  time = np.linspace(0, 14, X_days.shape[-1])

  fig, ax = plt.subplots(3, 2, figsize= [2* width, 3*height])

  for task in range(3):
    for i in range(options['n_days']):
        overlap = overlaps_sample[task][i]
        size = overlap.shape[0] // 2

        sample = overlap[:size].mean(0)
        ax[task][0].plot(time, sample, label=i+1, color = colors[i]);

        sample = overlap[size:].mean(0)
        ax[task][0].plot(time, sample, label=i+1, color = colors[i]);

        # ax[task][0].plot(time, circcvl(overlaps_sample[task][i][:size].mean(0), windowSize=2), label=i+1, color = colors[i]);
        # ax[task][0].plot(time, circcvl(overlaps_sample[task][i][size:].mean(0), windowSize=2), label=i+1, color = colors2[i]);

        # size = overlaps_dist[task][i].shape[0] // 2
        overlap = overlaps_dist[task][i]
        size = overlap.shape[0] // 2
        dist = overlap[:size].mean(0)
        ax[task][1].plot(time, dist, label=i+1, color = colors[i]);

        dist = overlap[size:].mean(0)
        ax[task][1].plot(time, dist, label=i+1, color = colors2[i]);

        # ax[task][1].plot(overlaps_dist[task][i][:size].mean(0), label=i+1, color = colors[i]);
        # ax[task][1].plot(time, circcvl(overlaps_dist[task][i][:size].mean(0), windowSize=2), label=i+1, color = colors[i]);
        # ax[task][1].plot(time, circcvl(overlaps_dist[task][i][size:].mean(0), windowSize=2), label=i+1, color = colors2[i]);

        options['day'] = i+1
        # X, y = get_X_y_S1_S2(X_days, y_days, **options)
        # size = np.sum(y==-1)

        # ax[task][2].plot(time, circcvl(overlaps_choice[task][i][size:].mean(0), windowSize=2), label=i+1, color = colors2[i]);
        # ax[task][2].plot(time, circcvl(overlaps_choice[task][i][:size].mean(0), windowSize=2), label=i+1, color = colors[i]);

    # ax[task][1].legend(fontsize=10)
    ax[task][0].set_xlabel('Time (s)')
    ax[task][1].set_xlabel('Time (s)')
    ax[task][0].set_ylabel('Sample Overlap')
    ax[task][1].set_ylabel('Distractor Overlap')

    for i in range(2):
        ax[task][i].set_xticks(np.arange(0, 16, 2))
        ax[task][i].set_xlim([0, 14])
        add_vlines(ax[task][i])
        # ax[task][i].set_ylim([-20, 20])

  # plt.savefig('%s_overlaps.svg' % options['mouse'], dpi=300)
  # plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: Loading files from /home/leon/dual_task/dual_data/data/JawsM15
[[./figures/landscape/figure_23.png]]
:END:

#+begin_src ipython
df = []
for task in tasks:
    options['task'] = task
    df2 = []
    for day in days:
        options['day'] = day
        X_days, y_days = get_X_y_days(**options)
        X, y = get_X_y_S1_S2(X_days, y_days, **options)

        df2.append(y)
    df.append(pd.concat(df2))
y = pd.concat(df)
#+end_src

#+RESULTS:
#+begin_example
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DPA TRIALS  DAYS 1 LASER 0
X_S1 (19, 693, 84) X_S2 (13, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DPA TRIALS  DAYS 2 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DPA TRIALS  DAYS 3 LASER 0
X_S1 (17, 693, 84) X_S2 (15, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DPA TRIALS  DAYS 4 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DPA TRIALS  DAYS 5 LASER 0
X_S1 (9, 693, 84) X_S2 (23, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DPA TRIALS  DAYS 6 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DualGo TRIALS  DAYS 1 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DualGo TRIALS  DAYS 2 LASER 0
X_S1 (9, 693, 84) X_S2 (23, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DualGo TRIALS  DAYS 3 LASER 0
X_S1 (14, 693, 84) X_S2 (18, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DualGo TRIALS  DAYS 4 LASER 0
X_S1 (17, 693, 84) X_S2 (15, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DualGo TRIALS  DAYS 5 LASER 0
X_S1 (8, 693, 84) X_S2 (24, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DualGo TRIALS  DAYS 6 LASER 0
X_S1 (15, 693, 84) X_S2 (17, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DualNoGo TRIALS  DAYS 1 LASER 0
X_S1 (22, 693, 84) X_S2 (10, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DualNoGo TRIALS  DAYS 2 LASER 0
X_S1 (18, 693, 84) X_S2 (14, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DualNoGo TRIALS  DAYS 3 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DualNoGo TRIALS  DAYS 4 LASER 0
X_S1 (14, 693, 84) X_S2 (18, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DualNoGo TRIALS  DAYS 5 LASER 0
X_S1 (7, 693, 84) X_S2 (25, 693, 84)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES choice TASK DualNoGo TRIALS  DAYS 6 LASER 0
X_S1 (15, 693, 84) X_S2 (17, 693, 84)
#+end_example

#+begin_src ipython
print(y.response.unique())
#+end_src

#+RESULTS:
: ['correct_hit' 'incorrect_fa' 'correct_rej' 'incorrect_miss']

#+begin_src ipython
y['behavior'] = y['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
y['pair'] = y['response'].apply(lambda x: 0 if ('rej' in x) or ('fa' in x) else 1)
#+end_src

#+RESULTS:

#+begin_src ipython
# print(np.vstack(overlaps_dist).shape)
# print(np.vstack(np.vstack(np.swapaxes(overlaps_dist, 0, -3))).shape)
# overlaps  = np.vstack(np.hstack(overlaps_sample)[..., 0])
overlaps  = overlaps_sample[..., 0].reshape(-1, 84)
# overlaps = np.vstack(np.vstack(np.swapaxes(overlaps_dist, 0, -3)))[..., 0]
print(overlaps.shape)
#+end_src

#+RESULTS:
: (576, 84)

#+begin_src ipython
y['overlaps'] = overlaps.tolist()
y['overlaps'] = y['overlaps'].apply(np.array)

options['epochs'] = ['ED']
y['overlaps_ED'] = y['overlaps'].apply(lambda x: avg_epochs(np.array(x), **options))

options['epochs'] = ['MD']
y['overlaps_MD'] = y['overlaps'].apply(lambda x: avg_epochs(np.array(x), **options))

options['epochs'] = ['LD']
y['overlaps_LD'] = y['overlaps'].apply(lambda x: avg_epochs(np.array(x), **options))

print(overlaps.shape)
#+end_src

#+RESULTS:
: (576, 84)

#+begin_src ipython
y['OED_sign'] = y['overlaps_ED'].apply(lambda x: 0 if x<=0 else 1)
y['OLD_sign'] = y['overlaps_LD'].apply(lambda x: 0 if x<=0 else 1)
print(y.overlaps_ED.head())
#+end_src

#+RESULTS:
: 14    0.670362
: 21    1.601941
: 25    0.438161
: 26    0.689194
: 32    1.255044
: Name: overlaps_ED, dtype: float64

#+begin_src ipython
print(y.keys())
#+end_src

#+RESULTS:
: Index(['sample_odor', 'test_odor', 'response', 'tasks', 'laser', 'day',
:        'dist_odor', 'choice', 'overlaps', 'overlaps_ED', 'overlaps_MD',
:        'overlaps_LD', 'behavior', 'pair', 'OED_sign', 'OLD_sign'],
:       dtype='object')

#+begin_src ipython
print(y.choice.shape)
#+end_src

#+RESULTS:
: (576,)

#+begin_src ipython
print(y.response.unique())
#+end_src

#+RESULTS:
: ['correct_hit' 'incorrect_fa' 'correct_rej' 'incorrect_miss']

#+begin_src ipython
df = y[y.tasks=='DPA'].copy()
# df['overlaps'] = df['overlaps'].apply(np.array)

# Group by 'day' and compute the mean overlaps for each day
mean_overlaps_by_day = df.groupby('day')['overlaps'].apply(lambda x: np.mean(np.stack(x), axis=0))

# Prepare data for plotting
mean_overlaps_df = pd.DataFrame(mean_overlaps_by_day.tolist(), index=mean_overlaps_by_day.index)

# Plotting
for idx, row in mean_overlaps_df.iterrows():
    plt.plot(np.linspace(0, 14, 84), row, label=f"Day {idx}")

plt.xlabel('Time (s)')
plt.ylabel('Overlap')
plt.legend(fontsize=10)
add_vlines()
plt.show()
#+end_src

#+RESULTS:
[[./figures/landscape/figure_33.png]]

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')
  y['choice'] = y['choice'].astype('category')

  formula = 'OLD_sign ~ choice'
  results = []

  for day in y.day.unique():
      data = y[(y['day'] == day)]
      glm = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())
      result = glm.fit()
      results.append(result)

  print(results[0].summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:               OLD_sign   No. Observations:                   96
Model:                            GLM   Df Residuals:                       94
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.16189
Method:                          IRLS   Log-Likelihood:                -47.806
Date:                Mon, 26 Aug 2024   Deviance:                       15.217
Time:                        18:52:40   Pearson chi2:                     15.2
No. Iterations:                     3   Pseudo R-squ. (CS):             0.4257
Covariance Type:            nonrobust
=================================================================================
                    coef    std err          z      P>|z|      [0.025      0.975]
---------------------------------------------------------------------------------
Intercept         0.7895      0.053     14.814      0.000       0.685       0.894
choice[T.1.0]    -0.6100      0.084     -7.295      0.000      -0.774      -0.446
=================================================================================
#+end_example

#+begin_src ipython
  print(results[0].summary())
#+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:            overlaps_ED   No. Observations:                   96
Model:                            GLM   Df Residuals:                       94
Model Family:                Gaussian   Df Model:                            1
Link Function:               Identity   Scale:                         0.22748
Method:                          IRLS   Log-Likelihood:                -64.135
Date:                Mon, 26 Aug 2024   Deviance:                       21.383
Time:                        18:05:51   Pearson chi2:                     21.4
No. Iterations:                     3   Pseudo R-squ. (CS):            0.06226
Covariance Type:            nonrobust
=================================================================================
                    coef    std err          z      P>|z|      [0.025      0.975]
---------------------------------------------------------------------------------
Intercept         0.3005      0.063      4.756      0.000       0.177       0.424
choice[T.1.0]     0.2458      0.099      2.480      0.013       0.052       0.440
=================================================================================
#+end_example

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf

  y['tasks'] = y['tasks'].astype('category')
  y['day'] = y['day'].astype('category')

  formula = 'overlaps_LD ~ day'
  formula = 'OLD_sign ~ day'
  results = []

  glm = smf.glm(formula=formula, data=y, family=sm.families.Gaussian())
  # glm = smf.mixedlm(formula, y, groups=y['day'], re_formula='1')
  result = glm.fit()

  print(result.summary())
    #+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:               OLD_sign   No. Observations:                  576
Model:                            GLM   Df Residuals:                      570
Model Family:                Gaussian   Df Model:                            5
Link Function:               Identity   Scale:                         0.24543
Method:                          IRLS   Log-Likelihood:                -409.73
Date:                Mon, 26 Aug 2024   Deviance:                       139.90
Time:                        18:53:12   Pearson chi2:                     140.
No. Iterations:                     3   Pseudo R-squ. (CS):            0.02633
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.5417      0.051     10.713      0.000       0.443       0.641
day[T.2.0]     0.0208      0.072      0.291      0.771      -0.119       0.161
day[T.3.0]    -0.1875      0.072     -2.622      0.009      -0.328      -0.047
day[T.4.0]     0.0729      0.072      1.020      0.308      -0.067       0.213
day[T.5.0]  1.058e-15      0.072   1.48e-14      1.000      -0.140       0.140
day[T.6.0]    -0.0104      0.072     -0.146      0.884      -0.151       0.130
==============================================================================
#+end_example

#+begin_src ipython
print(result.params.keys())
#+end_src

#+RESULTS:
: Index(['Intercept', 'day[T.2.0]', 'day[T.3.0]', 'day[T.4.0]', 'day[T.5.0]',
:        'day[T.6.0]'],
:       dtype='object')

#+begin_src ipython
coefs = []
for i in result.params.keys():
    coefs.append(result.params[i])

plt.plot(np.arange(1, 7), coefs[:6])
plt.xlabel('Day')
plt.ylabel('$\\beta_{overlap}$')
plt.show()
    #+end_src

#+RESULTS:
[[./figures/landscape/figure_38.png]]

#+begin_src ipython
print(result.summary())
#+end_src

#+RESULTS:
#+begin_example
                 Generalized Linear Model Regression Results
==============================================================================
Dep. Variable:            overlaps_ED   No. Observations:                  576
Model:                            GLM   Df Residuals:                      570
Model Family:                Gaussian   Df Model:                            5
Link Function:               Identity   Scale:                         0.34608
Method:                          IRLS   Log-Likelihood:                -508.70
Date:                Mon, 26 Aug 2024   Deviance:                       197.27
Time:                        17:54:52   Pearson chi2:                     197.
No. Iterations:                     3   Pseudo R-squ. (CS):             0.5316
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.4003      0.060      6.667      0.000       0.283       0.518
day[T.2.0]    -0.2510      0.085     -2.956      0.003      -0.417      -0.085
day[T.3.0]     0.2413      0.085      2.842      0.004       0.075       0.408
day[T.4.0]    -0.8347      0.085     -9.830      0.000      -1.001      -0.668
day[T.5.0]    -0.4128      0.085     -4.862      0.000      -0.579      -0.246
day[T.6.0]    -1.2922      0.085    -15.218      0.000      -1.459      -1.126
==============================================================================
#+end_example
