#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session decoder :kernel dual_data :exports results :output-dir ./figures/overlaps :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python

* Imports
#+begin_src ipython
  from sklearn.exceptions import ConvergenceWarning
  warnings.filterwarnings("ignore")
  import traceback

  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import os
  if not sys.warnoptions:
    warnings.simplefilter("ignore")
    os.environ["PYTHONWARNINGS"] = "ignore"

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  import pandas as pd

  from time import perf_counter

  from sklearn.base import clone
  from sklearn.metrics import make_scorer, roc_auc_score
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.model_selection import RepeatedStratifiedKFold, LeaveOneOut, StratifiedKFold

  from src.common.plot_utils import add_vlines, add_vdashed
  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.preprocess.helpers import avg_epochs

  from src.torch.classificationCV import ClassificationCV
  from src.torch.main import get_classification
#+end_src

#+RESULTS:

* Helpers

#+begin_src ipython
def pad_with_nans(array, target_shape):
    result = np.full(target_shape, np.nan)  # Create an array filled with NaNs
    print(result.shape)
    slices = tuple(slice(0, min(dim, target)) for dim, target in zip(array.shape, target_shape))
    result[slices] = array[slices]
    return result
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import numpy as np

  def safe_roc_auc_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return np.nan  # return np.nan where the score cannot be calculated
      return roc_auc_score(y_true, y_score)
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def rescale_coefs(model, coefs, bias):

          try:
                  means = model.named_steps["scaler"].mean_
                  scales = model.named_steps["scaler"].scale_

                  # Rescale the coefficients
                  rescaled_coefs = np.true_divide(coefs, scales)

                  # Adjust the intercept
                  rescaled_bias = bias - np.sum(rescaled_coefs * means)

                  return rescaled_coefs, rescaled_bias
          except:
                  return coefs, bias

#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  from scipy.stats import bootstrap

  def get_bootstrap_ci(data, statistic=np.mean, confidence_level=0.95, n_resamples=1000, random_state=None):
      result = bootstrap((data,), statistic)
      ci_lower, ci_upper = result.confidence_interval
      return np.array([ci_lower, ci_upper])
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

* Parameters

#+begin_src ipython
  DEVICE = 'cuda:0'
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  N_NEURONS = [668, 693, 444, 361, 113]

  tasks = ['DPA', 'DualGo', 'DualNoGo']
  # mice = ['AP02', 'AP12', 'PP09', 'PP17', 'RP17']
  mice = ['PP09']

  kwargs = {
      'mouse': 'PP09', 'laser': 0,
      'trials': '', 'reload': 0, 'data_type': 'dF',
      'prescreen': None, 'pval': 0.05,
      'preprocess': False, 'scaler_BL': 'robust',
      'avg_noise':True, 'unit_var_BL': True,
      'random_state': None, 'T_WINDOW': 0.0,
      'l1_ratio': 0.95,
      'n_comp': None, 'scaler': None,
      'bootstrap': 1, 'n_boots': 128,
      'n_splits': 3, 'n_repeats': 32,
      'class_weight': 0,
      'multilabel':0,
  }

  # kwargs['days'] = ['first', 'middle', 'last']
  kwargs['days'] = np.arange(1, options['n_days']+1)
  options = set_options(**kwargs)
  safe_roc_auc = make_scorer(safe_roc_auc_score, needs_proba=True)
  options['hp_scoring'] = safe_roc_auc
  options['n_jobs'] = 30
#+end_src

#+RESULTS:

#+begin_src ipython
def overlaps_scorer(estimator, X_test, y_test, IF_SIGN=0):
    coef = estimator.named_steps["net"].coef_.flatten()
    if IF_SIGN:
        dot_product = (2*y_test -1) * np.dot(X_test, coef) / np.linalg.norm(coef)
    else:
        dot_product = -np.dot(X_test, coef) / np.linalg.norm(coef)

    return dot_product.mean()


options['scoring'] = overlaps_scorer
# options['hp_scoring'] = 'overlaps_scorer'
#+end_src

#+RESULTS:

#+begin_src ipython
def signed_overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1):
    coef = estimator.named_steps["net"].coef_.flatten()
    if IF_SIGN:
        dot_product = (2*y_test -1) * np.dot(X_test, coef) / np.linalg.norm(coef)
    else:
        dot_product = -np.dot(X_test, coef) / np.linalg.norm(coef)

    return dot_product.mean()


options['scoring'] = overlaps_scorer
# options['hp_scoring'] = 'overlaps_scorer'
#+end_src

#+RESULTS:

* Decoding vs days
** Model

#+begin_src ipython
from sklearn.linear_model import LogisticRegression
# net = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', n_jobs=None)
net = LogisticRegression(penalty='elasticnet', solver='saga', class_weight='balanced', n_jobs=None, l1_ratio=0.95, max_iter=100, tol=.001)
# net = LogisticRegression(penalty='elasticnet', solver='saga', class_weight='balanced', n_jobs=None, l1_ratio=0.95, max_iter=100, tol=.001, multi_class='multinomial')

params = {'net__C': np.logspace(-4, 4, 20)}

options['n_jobs'] = -1
options['verbose'] = 0
model = ClassificationCV(net, params, **options)
options['cv'] = LeaveOneOut()
#+end_src

#+RESULTS:

** Sample Overlap

#+begin_src ipython
options['verbose'] = 1
options['features'] = 'sample'
options['epochs'] = ['ED']
options['scoring'] = signed_overlaps_scorer
options['reload'] = 0

tasks = ['DPA', 'DualGo', 'DualNoGo']

dfs = []
for mouse in mice:
    df_mouse = []
    options['mouse'] = mouse
    options = set_options(**options)
    days = options['days']

    for task in tasks:
        options['task'] = task

        for day in days:
            options['day'] = day
            overlaps = get_classification(model, RETURN='df_scores', **options)
            options['reload'] = 0
            df_mouse.append(overlaps)

    df_mouse = pd.concat(df_mouse)
    df_mouse['mouse'] = mouse
    dfs.append(df_mouse)

df_mice = pd.concat(dfs)
print(df_mice.shape)
    #+end_src

#+RESULTS:
#+begin_example
Reading data from source file
DATA: FEATURES sample TASK DPA TRIALS  DAYS first LASER 0
multiple days, discard 4 first 2 middle 2
X_S1 (16, 702, 84) X_S2 (16, 702, 84)
y_labels ['DPA']
X (32, 702, 84) y (32,) [0. 1.]
scores (32, 84, 84)
(32, 1) (32, 7)
y_labels ['DPA']
df (32, 8)
Loading files from /home/leon/dual_task/dual_data/data/AP02
DATA: FEATURES sample TASK DPA TRIALS  DAYS middle LASER 0
multiple days, discard 4 first 2 middle 2
X_S1 (16, 702, 84) X_S2 (16, 702, 84)
y_labels ['DPA']
X (32, 702, 84) y (32,) [0. 1.]
scores (32, 84, 84)
(32, 1) (32, 7)
y_labels ['DPA']
df (32, 8)
Loading files from /home/leon/dual_task/dual_data/data/AP02
DATA: FEATURES sample TASK DPA TRIALS  DAYS last LASER 0
multiple days, discard 4 first 2 middle 2
X_S1 (16, 702, 84) X_S2 (16, 702, 84)
y_labels ['DPA']
X (32, 702, 84) y (32,) [0. 1.]
scores (32, 84, 84)
(32, 1) (32, 7)
y_labels ['DPA']
df (32, 8)
Loading files from /home/leon/dual_task/dual_data/data/AP02
DATA: FEATURES sample TASK DualGo TRIALS  DAYS first LASER 0
multiple days, discard 4 first 2 middle 2
X_S1 (32, 702, 84) X_S2 (32, 702, 84)
y_labels ['DualGo']
X (64, 702, 84) y (64,) [0. 1.]
scores (64, 84, 84)
(64, 1) (64, 7)
y_labels ['DualGo']
df (64, 8)
Loading files from /home/leon/dual_task/dual_data/data/AP02
DATA: FEATURES sample TASK DualGo TRIALS  DAYS middle LASER 0
multiple days, discard 4 first 2 middle 2
X_S1 (32, 702, 84) X_S2 (32, 702, 84)
y_labels ['DualGo']
X (64, 702, 84) y (64,) [0. 1.]
scores (64, 84, 84)
(64, 1) (64, 7)
y_labels ['DualGo']
df (64, 8)
Loading files from /home/leon/dual_task/dual_data/data/AP02
DATA: FEATURES sample TASK DualGo TRIALS  DAYS last LASER 0
multiple days, discard 4 first 2 middle 2
X_S1 (32, 702, 84) X_S2 (32, 702, 84)
y_labels ['DualGo']
X (64, 702, 84) y (64,) [0. 1.]
scores (64, 84, 84)
(64, 1) (64, 7)
y_labels ['DualGo']
df (64, 8)
Loading files from /home/leon/dual_task/dual_data/data/AP02
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS first LASER 0
multiple days, discard 4 first 2 middle 2
X_S1 (32, 702, 84) X_S2 (32, 702, 84)
y_labels ['DualNoGo']
X (64, 702, 84) y (64,) [0. 1.]
scores (64, 84, 84)
(64, 1) (64, 7)
y_labels ['DualNoGo']
df (64, 8)
Loading files from /home/leon/dual_task/dual_data/data/AP02
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS middle LASER 0
multiple days, discard 4 first 2 middle 2
X_S1 (32, 702, 84) X_S2 (32, 702, 84)
y_labels ['DualNoGo']
X (64, 702, 84) y (64,) [0. 1.]
scores (64, 84, 84)
(64, 1) (64, 7)
y_labels ['DualNoGo']
df (64, 8)
Loading files from /home/leon/dual_task/dual_data/data/AP02
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS last LASER 0
multiple days, discard 4 first 2 middle 2
X_S1 (32, 702, 84) X_S2 (32, 702, 84)
y_labels ['DualNoGo']
X (64, 702, 84) y (64,) [0. 1.]
scores (64, 84, 84)
(64, 1) (64, 7)
y_labels ['DualNoGo']
df (64, 8)
(480, 9)
#+end_example

#+begin_src ipython
df_mice['performance'] = df_mice['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_mice['pair'] = df_mice['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
#+end_src

#+RESULTS:

#+begin_src ipython
if len(days)>3:
    name = 'df_sample_overlaps_days'
else:
    name = 'df_sample_overlaps'

pkl_save(df_mice, '%s' % name, path="../data/mice/overlaps")
#+end_src

#+RESULTS:
: saving to ../data/mice/overlaps/df_sample_overlaps_days.pkl

** Distractor overlap
*** overlaps

#+begin_src ipython
options['verbose'] = 1
options['features'] = 'distractor'
options['epochs'] = ['MD']
options['scoring'] = overlaps_scorer
options['reload'] = 1
tasks = ['DPA', 'Dual']
dfs = []
# mice = ['JawsM15']
options['cv'] = LeaveOneOut()
for mouse in mice:
    df_mouse = []
    options['mouse'] = mouse

    options = set_options(**options)
    days = options['days']

    for task in tasks:
        options['task'] = task
        for day in days:

            options['day'] = day

            try:
                overlaps = get_classification(model, RETURN='df_scores', **options)
            except Exception as exc:
                print(traceback.format_exc())
                break

            options['reload'] = 0
            df_mouse.append(overlaps)

    df_mouse = pd.concat(df_mouse)
    df_mouse['mouse'] = mouse
    dfs.append(df_mouse)

df_mice = pd.concat(dfs)
print(df_mice.shape)
    #+end_src

#+RESULTS:
#+begin_example
Reading data from source file
mouse PP09 n_days 10 day 1 type dF all data: X (176, 894, 84) y (176, 7)
mouse PP09 n_days 10 day 2 type dF all data: X (264, 894, 84) y (264, 7)
mouse PP09 n_days 10 day 3 type dF all data: X (176, 894, 84) y (176, 7)
mouse PP09 n_days 10 day 4 type dF all data: X (176, 894, 84) y (176, 7)
mouse PP09 n_days 10 day 5 type dF all data: X (176, 894, 84) y (176, 7)
mouse PP09 n_days 10 day 6 type dF all data: X (176, 894, 84) y (176, 7)
mouse PP09 n_days 10 day 7 type dF all data: X (176, 894, 84) y (176, 7)
mouse PP09 n_days 10 day 8 type dF all data: X (176, 894, 84) y (176, 7)
mouse PP09 n_days 10 day 9 type dF all data: X (176, 894, 84) y (176, 7)
mouse PP09 n_days 10 day 10 type dF all data: X (176, 894, 84) y (176, 7)
DATA: FEATURES sample TASK DPA TRIALS  DAYS 1 LASER 0
X_S1 (12, 894, 84) X_S2 (4, 894, 84)
X_test (16, 894, 84) y_test (16,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 1 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DPA']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (16, 84, 84)
(16, 1) (16, 7)
y_labels ['DPA']
df (16, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES sample TASK DPA TRIALS  DAYS 2 LASER 0
X_S1 (18, 894, 84) X_S2 (6, 894, 84)
X_test (24, 894, 84) y_test (24,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 2 LASER 0
X_S1 (48, 894, 84) X_S2 (48, 894, 84)
y_labels ['DPA']
X (96, 894, 84) y (96,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (24, 84, 84)
(24, 1) (24, 7)
y_labels ['DPA']
df (24, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES sample TASK DPA TRIALS  DAYS 3 LASER 0
X_S1 (12, 894, 84) X_S2 (4, 894, 84)
X_test (16, 894, 84) y_test (16,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 3 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DPA']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (16, 84, 84)
(16, 1) (16, 7)
y_labels ['DPA']
df (16, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES sample TASK DPA TRIALS  DAYS 4 LASER 0
X_S1 (12, 894, 84) X_S2 (4, 894, 84)
X_test (16, 894, 84) y_test (16,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 4 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DPA']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (16, 84, 84)
(16, 1) (16, 7)
y_labels ['DPA']
df (16, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES sample TASK DPA TRIALS  DAYS 5 LASER 0
X_S1 (12, 894, 84) X_S2 (4, 894, 84)
X_test (16, 894, 84) y_test (16,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 5 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DPA']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (16, 84, 84)
(16, 1) (16, 7)
y_labels ['DPA']
df (16, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES sample TASK DPA TRIALS  DAYS 6 LASER 0
X_S1 (12, 894, 84) X_S2 (4, 894, 84)
X_test (16, 894, 84) y_test (16,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 6 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DPA']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (16, 84, 84)
(16, 1) (16, 7)
y_labels ['DPA']
df (16, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES sample TASK DPA TRIALS  DAYS 7 LASER 0
X_S1 (12, 894, 84) X_S2 (4, 894, 84)
X_test (16, 894, 84) y_test (16,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 7 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DPA']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (16, 84, 84)
(16, 1) (16, 7)
y_labels ['DPA']
df (16, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES sample TASK DPA TRIALS  DAYS 8 LASER 0
X_S1 (12, 894, 84) X_S2 (4, 894, 84)
X_test (16, 894, 84) y_test (16,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 8 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DPA']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (16, 84, 84)
(16, 1) (16, 7)
y_labels ['DPA']
df (16, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES sample TASK DPA TRIALS  DAYS 9 LASER 0
X_S1 (12, 894, 84) X_S2 (4, 894, 84)
X_test (16, 894, 84) y_test (16,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 9 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DPA']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (16, 84, 84)
(16, 1) (16, 7)
y_labels ['DPA']
df (16, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES sample TASK DPA TRIALS  DAYS 10 LASER 0
X_S1 (12, 894, 84) X_S2 (4, 894, 84)
X_test (16, 894, 84) y_test (16,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 10 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DPA']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (16, 84, 84)
(16, 1) (16, 7)
y_labels ['DPA']
df (16, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 1 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (64, 84, 84)
(64, 1) (64, 7)
y_labels ['DualGo' 'DualNoGo']
df (64, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 2 LASER 0
X_S1 (48, 894, 84) X_S2 (48, 894, 84)
y_labels ['DualGo' 'DualNoGo']
X (96, 894, 84) y (96,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (96, 84, 84)
(96, 1) (96, 7)
y_labels ['DualGo' 'DualNoGo']
df (96, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 3 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (64, 84, 84)
(64, 1) (64, 7)
y_labels ['DualGo' 'DualNoGo']
df (64, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 4 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (64, 84, 84)
(64, 1) (64, 7)
y_labels ['DualGo' 'DualNoGo']
df (64, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 5 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (64, 84, 84)
(64, 1) (64, 7)
y_labels ['DualGo' 'DualNoGo']
df (64, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 6 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (64, 84, 84)
(64, 1) (64, 7)
y_labels ['DualGo' 'DualNoGo']
df (64, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 7 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (64, 84, 84)
(64, 1) (64, 7)
y_labels ['DualGo' 'DualNoGo']
df (64, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 8 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (64, 84, 84)
(64, 1) (64, 7)
y_labels ['DualGo' 'DualNoGo']
df (64, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 9 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (64, 84, 84)
(64, 1) (64, 7)
y_labels ['DualGo' 'DualNoGo']
df (64, 8)
Loading files from /home/leon/dual_task/dual_data/data/PP09
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 10 LASER 0
X_S1 (32, 894, 84) X_S2 (32, 894, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 894, 84) y (64,) [1. 2. 3. 4. 5. 6. 7. 8.]
scores (64, 84, 84)
(64, 1) (64, 7)
y_labels ['DualGo' 'DualNoGo']
df (64, 8)
(840, 9)
#+end_example

#+begin_src ipython
df_mice['performance'] = df_mice['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_mice['pair'] = df_mice['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
#+end_src

#+RESULTS:

#+begin_src ipython
print(df_mice.head())
#+end_src

#+RESULTS:
#+begin_example
   sample_odor  dist_odor  test_odor tasks      response  laser  day  \
0          0.0        0.0        0.0   DPA   correct_hit    0.0    1
1          0.0        0.0        1.0   DPA  incorrect_fa    0.0    1
2          0.0        0.0        0.0   DPA   correct_hit    0.0    1
3          0.0        0.0        1.0   DPA   correct_rej    0.0    1
4          0.0        0.0        0.0   DPA   correct_hit    0.0    1

                                            overlaps mouse  performance  pair
0  [-0.3442525863647461, -0.04141944274306297, -0...  PP09            1     1
1  [-0.322248250246048, 0.08833469450473785, -0.1...  PP09            0     0
2  [-0.04603399708867073, 0.01701030693948269, -0...  PP09            1     1
3  [-0.16955529153347015, -0.20525024831295013, -...  PP09            1     0
4  [0.3878960907459259, 0.09251184016466141, -0.1...  PP09            1     1
#+end_example

#+begin_src ipython
if len(days)>3:
    name = 'df_distractor_overlaps_days'
else:
    name = 'df_distractor_overlaps'
pkl_save(df_mice, '%s' % name, path="../data/mice/overlaps")
#+end_src

#+RESULTS:
: saving to ../data/mice/overlaps/df_distractor_overlaps_days.pkl

* Plots

#+begin_src ipython
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p <.1:
        return '.'
    else:
        return ''
#+end_src

#+RESULTS:

#+begin_src ipython
import rpy2.robjects as robjects
from rpy2.robjects.packages import importr

# Set the .libPaths in R
custom_r_libpath = '~/R/x86_64-pc-linux-gnu-library/4.3/'
robjects.r('.libPaths("{0}")'.format(custom_r_libpath))

from pymer4.models import Lmer
#+end_src

#+RESULTS:
: Warning message:
: package ‘methods’ was built under R version 4.3.3
: During startup - Warning messages:
: 1: package ‘datasets’ was built under R version 4.3.3
: 2: package ‘utils’ was built under R version 4.3.3
: 3: package ‘grDevices’ was built under R version 4.3.3
: 4: package ‘graphics’ was built under R version 4.3.3
: 5: package ‘stats’ was built under R version 4.3.3

#+begin_src ipython
def plot_overlaps(df, day, epoch, ax):
    df_ = df[df.day == day].copy()
    colors = ['r', 'b', 'g']
    time_points = np.linspace(0, 14, 84)

    mean_overlaps = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.mean(np.stack(x), axis=0))
    lower_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
    upper_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    for i, task in enumerate(mean_overlaps.index):
        ax.plot(time_points, mean_overlaps[task], label=f"Day {task}", color=colors[i])
        ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)

    ax.set_xlabel('Time (s)')
    ax.set_ylabel('Overlap')
    add_vlines(ax)

def bootstrap_ci_per_task(x, n_bootstrap, ci_idx):
    stacked = np.stack(x)
    return np.array([bootstrap_ci(stacked[:, i], n_bootstrap)[ci_idx] for i in range(stacked.shape[1])])
#+end_src

#+RESULTS:

#+begin_src ipython
def bootstrap_ci(data, n_bootstrap=1000, ci=95):
    bootstrapped_means = np.array([np.mean(np.random.choice(data, size=len(data))) for _ in range(n_bootstrap)])
    lower_bound = np.percentile(bootstrapped_means, (100-ci)/2)
    upper_bound = np.percentile(bootstrapped_means, 100 - (100-ci)/2)
    return lower_bound, upper_bound
#+end_src

#+RESULTS:

* Sample dfs
*** Data
#+begin_src ipython
name = 'df_sample_overlaps_days'
df_sample = pkl_load(name, path="../data/mice/overlaps")
#+end_src

#+RESULTS:
: loading from ../data/mice/overlaps/df_sample_overlaps_days.pkl

#+begin_src ipython
df_sample = df_mice.copy()
#+end_src

#+RESULTS:

 #+begin_src ipython
df_sample['overlaps_diag'] = df_sample['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
#+end_src

#+RESULTS:

 #+begin_src ipython
options['epochs'] = ['ED']
df_sample['overlaps_ED'] = df_sample['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src
#+RESULTS:

 #+begin_src ipython
options['epochs'] = ['MD']
df_sample['overlaps_MD'] = df_sample['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['LD']
df_sample['overlaps_ED_LD'] = df_sample['overlaps_ED'].apply(lambda x: avg_epochs(np.array(x), **options))
df_sample['overlaps_diag_LD'] = df_sample['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_sample['overlaps_MD_LD'] = df_sample['overlaps_MD'].apply(lambda x: avg_epochs(np.array(x), **options))
# print(df_sample.head())
#+end_src

#+RESULTS:

#+begin_src ipython
import seaborn as sns
sns.lineplot(data=df_sample, x='day', y='performance', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])

# Set plot labels and title
plt.xlabel('Day')
plt.ylabel('Behavior')
plt.title('Behavior vs Day per Task')
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_29.png]]

#+begin_src ipython
import seaborn as sns
sns.lineplot(data=df_sample, x='day', y='overlaps_ED_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])

# Set plot labels and title
plt.xlabel('Day')
plt.ylabel('Sample Overlap')
plt.title('Behavior vs Day per Task')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[95], line 2
      1 import seaborn as sns
----> 2 sns.lineplot(data=df_sample, x='day', y='overlaps_ED_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])
      4 # Set plot labels and title
      5 plt.xlabel('Day')

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/seaborn/relational.py:645, in lineplot(data, x, y, hue, size, style, units, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, estimator, errorbar, n_boot, seed, orient, sort, err_style, err_kws, legend, ci, ax, **kwargs)
    642 color = kwargs.pop("color", kwargs.pop("c", None))
    643 kwargs["color"] = _default_color(ax.plot, hue, color, kwargs)
--> 645 p.plot(ax, kwargs)
    646 return ax

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/seaborn/relational.py:423, in _LinePlotter.plot(self, ax, kws)
    415 # TODO How to handle NA? We don't want NA to propagate through to the
    416 # estimate/CI when some values are present, but we would also like
    417 # matplotlib to show "gaps" in the line when all values are missing.
   (...)
    420
    421 # Loop over the semantic subsets and add to the plot
    422 grouping_vars = "hue", "size", "style"
--> 423 for sub_vars, sub_data in self.iter_data(grouping_vars, from_comp_data=True):
    425     if self.sort:
    426         sort_vars = ["units", orient, other]

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/seaborn/_oldcore.py:1028, in VectorPlotter.iter_data(self, grouping_vars, reverse, from_comp_data, by_facet, allow_empty, dropna)
   1023 grouping_vars = [
   1024     var for var in grouping_vars if var in self.variables
   1025 ]
   1027 if from_comp_data:
-> 1028     data = self.comp_data
   1029 else:
   1030     data = self.plot_data

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/seaborn/_oldcore.py:1134, in VectorPlotter.comp_data(self)
   1132         else:
   1133             comp_col = pd.Series(dtype=float, name=var)
-> 1134         comp_data.insert(0, var, comp_col)
   1136     self._comp_data = comp_data
   1138 return self._comp_data

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/frame.py:4944, in DataFrame.insert(self, loc, column, value, allow_duplicates)
   4941 elif isinstance(value, DataFrame):
   4942     value = value.iloc[:, 0]
-> 4944 value, refs = self._sanitize_column(value)
   4945 self._mgr.insert(loc, column, value, refs=refs)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/frame.py:5036, in DataFrame._sanitize_column(self, value)
   5034     if not isinstance(value, Series):
   5035         value = Series(value)
-> 5036     return _reindex_for_setitem(value, self.index)
   5038 if is_list_like(value):
   5039     com.require_length_match(value, self.index)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/frame.py:12309, in _reindex_for_setitem(value, index)
  12305 except ValueError as err:
  12306     # raised in MultiIndex.from_tuples, see test_insert_error_msmgs
  12307     if not value.index.is_unique:
  12308         # duplicate axis
> 12309         raise err
  12311     raise TypeError(
  12312         "incompatible index of inserted column with frame index"
  12313     ) from err
  12314 return reindexed_value, None

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/frame.py:12304, in _reindex_for_setitem(value, index)
  12302 # GH#4107
  12303 try:
> 12304     reindexed_value = value.reindex(index)._values
  12305 except ValueError as err:
  12306     # raised in MultiIndex.from_tuples, see test_insert_error_msmgs
  12307     if not value.index.is_unique:
  12308         # duplicate axis

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/series.py:4977, in Series.reindex(self, index, axis, method, copy, level, fill_value, limit, tolerance)
   4960 @doc(
   4961     NDFrame.reindex,  # type: ignore[has-type]
   4962     klass=_shared_doc_kwargs["klass"],
   (...)
   4975     tolerance=None,
   4976 ) -> Series:
-> 4977     return super().reindex(
   4978         index=index,
   4979         method=method,
   4980         copy=copy,
   4981         level=level,
   4982         fill_value=fill_value,
   4983         limit=limit,
   4984         tolerance=tolerance,
   4985     )

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/generic.py:5521, in NDFrame.reindex(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)
   5518     return self._reindex_multi(axes, copy, fill_value)
   5520 # perform the reindex on the axes
-> 5521 return self._reindex_axes(
   5522     axes, level, limit, tolerance, method, fill_value, copy
   5523 ).__finalize__(self, method="reindex")

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/generic.py:5544, in NDFrame._reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy)
   5541     continue
   5543 ax = self._get_axis(a)
-> 5544 new_index, indexer = ax.reindex(
   5545     labels, level=level, limit=limit, tolerance=tolerance, method=method
   5546 )
   5548 axis = self._get_axis_number(a)
   5549 obj = obj._reindex_with_indexers(
   5550     {axis: [new_index, indexer]},
   5551     fill_value=fill_value,
   5552     copy=copy,
   5553     allow_dups=False,
   5554 )

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/indexes/base.py:4433, in Index.reindex(self, target, method, level, limit, tolerance)
   4430     raise ValueError("cannot handle a non-unique multi-index!")
   4431 elif not self.is_unique:
   4432     # GH#42568
-> 4433     raise ValueError("cannot reindex on an axis with duplicate labels")
   4434 else:
   4435     indexer, _ = self.get_indexer_non_unique(target)

ValueError: cannot reindex on an axis with duplicate labels
#+end_example
[[./figures/overlaps/figure_30.png]]
:END:


#+RESULTS:

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height), sharex=True, sharey=True)

df = df_sample[df_sample.mouse!='JawsM18']
# df = df_dist.copy()

# plot_overlaps(df, 'first', 'ED', ax[0])
# plot_overlaps(df, 'middle', 'ED', ax[1])
# plot_overlaps(df, 'last', 'ED', ax[2])

plot_overlaps(df, 'first', 'diag', ax[0])
plot_overlaps(df, 'middle', 'diag', ax[1])
plot_overlaps(df, 'last', 'diag', ax[2])

ax[2].legend(fontsize=10)

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_31.png]]

*** Performance
**** Performance ~ day * tasks

#+begin_src ipython
  df_sample['tasks'] = df_sample['tasks'].astype('category')
  # df_sample['day'] = df_sample['day'].astype('int')

  formula = 'performance ~ tasks * day + (1 + tasks + day | mouse)'
  data = df_sample.copy()
  # data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']

  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*day+(1+tasks+day|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1754.357 	 AIC: 3540.714

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.189  0.434
mouse    tasksDualGo  0.100  0.317
mouse  tasksDualNoGo  0.020  0.141
mouse            day  0.035  0.187

                 IV1            IV2   Corr
mouse    (Intercept)    tasksDualGo  0.098
mouse    (Intercept)  tasksDualNoGo -0.648
mouse    (Intercept)            day -0.047
mouse    tasksDualGo  tasksDualNoGo  0.530
mouse    tasksDualGo            day -0.571
mouse  tasksDualNoGo            day -0.697

Fixed effects:

                   Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
(Intercept)          -0.035  -0.538    0.468  0.257  0.966      0.584
tasksDualGo          -0.088  -0.608    0.432  0.265  0.916      0.544
tasksDualNoGo         0.085  -0.374    0.544  0.234  1.089      0.688
day                   0.564   0.363    0.764  0.102  1.757      1.438
tasksDualGo:day      -0.104  -0.249    0.040  0.074  0.901      0.780
tasksDualNoGo:day    -0.089  -0.236    0.059  0.075  0.915      0.789

                   OR_97.5_ci   Prob  Prob_2.5_ci  Prob_97.5_ci  Z-stat  \
(Intercept)             1.597  0.491        0.369         0.615  -0.135
tasksDualGo             1.540  0.478        0.352         0.606  -0.333
tasksDualNoGo           1.723  0.521        0.408         0.633   0.363
day                     2.147  0.637        0.590         0.682   5.507
tasksDualGo:day         1.041  0.474        0.438         0.510  -1.414
tasksDualNoGo:day       1.061  0.478        0.441         0.515  -1.177

                   P-val  Sig
(Intercept)        0.892
tasksDualGo        0.739
tasksDualNoGo      0.716
day                0.000  ***
tasksDualGo:day    0.157
tasksDualNoGo:day  0.239
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)


df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_32.png]]

**** Performance ~ overlaps

#+begin_src ipython
  df_sample['tasks'] = df_sample['tasks'].astype('category')
  # df_sample['day'] = df_sample['day'].astype('int')

  formula = 'performance ~ overlaps_ED_LD + (1 + tasks | mouse)'

  data = df_sample.copy()
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~overlaps_ED_LD+(1+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3072	 Groups: {'mouse': 4.0}

Log-likelihood: -1705.129 	 AIC: 3426.257

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.278  0.527
mouse    tasksDualGo  0.199  0.446
mouse  tasksDualNoGo  0.014  0.119

               IV1            IV2   Corr
mouse  (Intercept)    tasksDualGo -0.491
mouse  (Intercept)  tasksDualNoGo -0.911
mouse  tasksDualGo  tasksDualNoGo  0.806

Fixed effects:

                Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
(Intercept)        1.134   0.533    1.735  0.307  3.108      1.703
overlaps_ED_LD     0.055  -0.091    0.202  0.075  1.057      0.913

                OR_97.5_ci   Prob  Prob_2.5_ci  Prob_97.5_ci  Z-stat  P-val  \
(Intercept)          5.671  0.757        0.630          0.85   3.695  0.000
overlaps_ED_LD       1.223  0.514        0.477          0.55   0.742  0.458

                Sig
(Intercept)     ***
overlaps_ED_LD
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)


df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_34.png]]

**** Performance ~ overlaps * days

#+begin_src ipython
  df_sample['tasks'] = df_sample['tasks'].astype('category')
  formula = 'performance ~ day * overlaps_ED_LD  + (1 + day | mouse)'

  data = df_sample.copy()
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~day*overlaps_ED_LD+(1+day|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3072	 Groups: {'mouse': 4.0}

Log-likelihood: -1606.931 	 AIC: 3227.862

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.233  0.482
mouse          day  0.015  0.123

               IV1  IV2   Corr
mouse  (Intercept)  day -0.557

Fixed effects:

                    Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
(Intercept)           -0.025  -0.543    0.494  0.265  0.976      0.581
day                    0.403   0.265    0.541  0.070  1.496      1.304
overlaps_ED_LD        -0.046  -0.378    0.287  0.170  0.955      0.685
day:overlaps_ED_LD     0.042  -0.066    0.149  0.055  1.042      0.936

                    OR_97.5_ci   Prob  Prob_2.5_ci  Prob_97.5_ci  Z-stat  \
(Intercept)              1.639  0.494        0.367         0.621  -0.093
day                      1.718  0.599        0.566         0.632   5.726
overlaps_ED_LD           1.332  0.489        0.407         0.571  -0.269
day:overlaps_ED_LD       1.161  0.510        0.483         0.537   0.756

                    P-val  Sig
(Intercept)         0.926
day                 0.000  ***
overlaps_ED_LD      0.788
day:overlaps_ED_LD  0.450
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)


df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_36.png]]

**** Performance ~ overlaps * days * tasks

#+begin_src ipython
  df_sample['tasks'] = df_sample['tasks'].astype('category')
  formula = 'performance ~ day * tasks * overlaps_ED_LD  + (1 + day | mouse)'

  data = df_sample.copy()
  # data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
,**NOTE**: Column for 'residuals' not created in model.data, but saved in model.resid only. This is because you have rows with NaNs in your data.

,**NOTE** Column for 'fits' not created in model.data, but saved in model.fits only. This is because you have rows with NaNs in your data.

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~day*tasks*overlaps_ED_LD+(1+day|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1767.491 	 AIC: 3582.981

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.174  0.418
mouse      daylast  0.560  0.749
mouse    daymiddle  0.224  0.473

               IV1        IV2   Corr
mouse  (Intercept)    daylast  0.004
mouse  (Intercept)  daymiddle  0.808
mouse      daylast  daymiddle  0.593

Fixed effects:

                                        Estimate  2.5_ci  97.5_ci     SE  \
(Intercept)                                0.736   0.316    1.155  0.214
daylast                                    1.830   1.023    2.638  0.412
daymiddle                                  1.385   0.835    1.935  0.281
tasksDualGo                               -0.184  -0.460    0.092  0.141
tasksDualNoGo                              0.015  -0.264    0.295  0.143
overlaps_ED_LD                             0.311  -0.095    0.717  0.207
daylast:tasksDualGo                       -0.161  -0.747    0.426  0.299
daymiddle:tasksDualGo                     -0.347  -0.792    0.099  0.227
daylast:tasksDualNoGo                     -0.381  -0.970    0.207  0.300
daymiddle:tasksDualNoGo                   -0.084  -0.546    0.379  0.236
daylast:overlaps_ED_LD                    -0.152  -0.960    0.656  0.412
daymiddle:overlaps_ED_LD                  -0.190  -0.871    0.490  0.347
tasksDualGo:overlaps_ED_LD                -0.382  -0.913    0.148  0.271
tasksDualNoGo:overlaps_ED_LD              -0.174  -0.672    0.323  0.254
daylast:tasksDualGo:overlaps_ED_LD         0.158  -0.937    1.252  0.558
daymiddle:tasksDualGo:overlaps_ED_LD       0.293  -0.536    1.121  0.423
daylast:tasksDualNoGo:overlaps_ED_LD       0.048  -1.013    1.110  0.542
daymiddle:tasksDualNoGo:overlaps_ED_LD     0.196  -0.698    1.090  0.456

                                           OR  OR_2.5_ci  OR_97.5_ci   Prob  \
(Intercept)                             2.087      1.371       3.175  0.676
daylast                                 6.235      2.781      13.980  0.862
daymiddle                               3.994      2.304       6.926  0.800
tasksDualGo                             0.832      0.631       1.097  0.454
tasksDualNoGo                           1.016      0.768       1.343  0.504
overlaps_ED_LD                          1.365      0.909       2.048  0.577
daylast:tasksDualGo                     0.852      0.474       1.531  0.460
daymiddle:tasksDualGo                   0.707      0.453       1.104  0.414
daylast:tasksDualNoGo                   0.683      0.379       1.230  0.406
daymiddle:tasksDualNoGo                 0.920      0.579       1.461  0.479
daylast:overlaps_ED_LD                  0.859      0.383       1.926  0.462
daymiddle:overlaps_ED_LD                0.827      0.418       1.633  0.453
tasksDualGo:overlaps_ED_LD              0.682      0.402       1.160  0.406
tasksDualNoGo:overlaps_ED_LD            0.840      0.511       1.382  0.457
daylast:tasksDualGo:overlaps_ED_LD      1.171      0.392       3.498  0.539
daymiddle:tasksDualGo:overlaps_ED_LD    1.340      0.585       3.068  0.573
daylast:tasksDualNoGo:overlaps_ED_LD    1.049      0.363       3.034  0.512
daymiddle:tasksDualNoGo:overlaps_ED_LD  1.216      0.498       2.973  0.549

                                        Prob_2.5_ci  Prob_97.5_ci  Z-stat  \
(Intercept)                                   0.578         0.760   3.435
daylast                                       0.736         0.933   4.443
daymiddle                                     0.697         0.874   4.932
tasksDualGo                                   0.387         0.523  -1.305
tasksDualNoGo                                 0.434         0.573   0.109
overlaps_ED_LD                                0.476         0.672   1.502
daylast:tasksDualGo                           0.321         0.605  -0.537
daymiddle:tasksDualGo                         0.312         0.525  -1.525
daylast:tasksDualNoGo                         0.275         0.551  -1.271
daymiddle:tasksDualNoGo                       0.367         0.594  -0.355
daylast:overlaps_ED_LD                        0.277         0.658  -0.369
daymiddle:overlaps_ED_LD                      0.295         0.620  -0.548
tasksDualGo:overlaps_ED_LD                    0.286         0.537  -1.413
tasksDualNoGo:overlaps_ED_LD                  0.338         0.580  -0.686
daylast:tasksDualGo:overlaps_ED_LD            0.282         0.778   0.282
daymiddle:tasksDualGo:overlaps_ED_LD          0.369         0.754   0.693
daylast:tasksDualNoGo:overlaps_ED_LD          0.266         0.752   0.089
daymiddle:tasksDualNoGo:overlaps_ED_LD        0.332         0.748   0.430

                                        P-val  Sig
(Intercept)                             0.001  ***
daylast                                 0.000  ***
daymiddle                               0.000  ***
tasksDualGo                             0.192
tasksDualNoGo                           0.914
overlaps_ED_LD                          0.133
daylast:tasksDualGo                     0.591
daymiddle:tasksDualGo                   0.127
daylast:tasksDualNoGo                   0.204
daymiddle:tasksDualNoGo                 0.723
daylast:overlaps_ED_LD                  0.712
daymiddle:overlaps_ED_LD                0.583
tasksDualGo:overlaps_ED_LD              0.158
tasksDualNoGo:overlaps_ED_LD            0.493
daylast:tasksDualGo:overlaps_ED_LD      0.778
daymiddle:tasksDualGo:overlaps_ED_LD    0.488
daylast:tasksDualNoGo:overlaps_ED_LD    0.929
daymiddle:tasksDualNoGo:overlaps_ED_LD  0.667
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_36.png]]

**** Performance per day

#+begin_src ipython
results = []
formula = 'performance ~ tasks * overlaps_ED_LD  + (1 + tasks | mouse)'
for day in df_sample.day.unique():
  data = df_sample.copy()
  data = data[data.day==day]
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  glm.fit();
  results.append(glm)
#+end_src

#+RESULTS:
#+begin_example
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_ED_LD+(1+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 842	 Groups: {'mouse': 4.0}

Log-likelihood: -759.007 	 AIC: 1542.015

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.186  0.432
mouse    tasksDualGo  0.004  0.066
mouse  tasksDualNoGo  0.007  0.083

               IV1            IV2  Corr
mouse  (Intercept)    tasksDualGo  -1.0
mouse  (Intercept)  tasksDualNoGo  -1.0
mouse  tasksDualGo  tasksDualNoGo   1.0

Fixed effects:
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_ED_LD+(1+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 842	 Groups: {'mouse': 4.0}

Log-likelihood: -546.648 	 AIC: 1117.296

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.923  0.961
mouse    tasksDualGo  0.390  0.625
mouse  tasksDualNoGo  0.063  0.251

               IV1            IV2   Corr
mouse  (Intercept)    tasksDualGo -0.901
mouse  (Intercept)  tasksDualNoGo -0.986
mouse  tasksDualGo  tasksDualNoGo  0.814

Fixed effects:
Model failed to converge with max|grad| = 0.00690125 (tol = 0.002, component 1)

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_ED_LD+(1+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 768	 Groups: {'mouse': 4.0}

Log-likelihood: -288.533 	 AIC: 601.066

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.321  0.567
mouse    tasksDualGo  0.007  0.082
mouse  tasksDualNoGo  0.070  0.265

               IV1            IV2  Corr
mouse  (Intercept)    tasksDualGo   1.0
mouse  (Intercept)  tasksDualNoGo  -1.0
mouse  tasksDualGo  tasksDualNoGo  -1.0

Fixed effects:
#+end_example

#+begin_src ipython
import pandas as pd

# Assuming you have the list of results from all sessions
combined_results = []

for i, result in enumerate(results):
    coefficients = {
        'coef': result.coefs['Estimate'],
        'lower_ci': result.coefs['2.5_ci'],
        'upper_ci': result.coefs['97.5_ci'],
        'p_value': result.coefs['P-val'],
        'Sig': result.coefs['Sig'],
        'day': df_sample.day.unique()[i]  # Add a session identifier
    }
    df_result = pd.DataFrame(coefficients)
    combined_results.append(df_result)

df_combined = pd.concat(combined_results)
#+end_src

#+RESULTS:

#+begin_src ipython
print(df_combined)
#+end_src

#+RESULTS:
#+begin_example
                                  coef  lower_ci  upper_ci       p_value  Sig  \
(Intercept)                   0.590960  0.095447  1.086472  1.941326e-02    *
tasksDualGo                  -0.219893 -0.571313  0.131526  2.200456e-01
tasksDualNoGo                 0.065029 -0.292921  0.422979  7.217907e-01
overlaps_ED_LD                0.148187 -0.235214  0.531589  4.487264e-01
tasksDualGo:overlaps_ED_LD   -0.058438 -0.557718  0.440843  8.185568e-01
tasksDualNoGo:overlaps_ED_LD -0.252372 -0.808545  0.303800  3.738065e-01
(Intercept)                   2.111160  1.060521  3.161800  8.203970e-05  ***
tasksDualGo                  -0.888414 -1.711319 -0.065508  3.434580e-02    *
tasksDualNoGo                -0.304023 -0.933322  0.325276  3.436974e-01
overlaps_ED_LD               -0.184518 -0.848397  0.479361  5.859250e-01
tasksDualGo:overlaps_ED_LD    0.078341 -0.735617  0.892300  8.503743e-01
tasksDualNoGo:overlaps_ED_LD  0.176529 -0.712100  1.065159  6.970145e-01
(Intercept)                   1.860035  1.126384  2.593686  6.725706e-07  ***
tasksDualGo                   0.150633 -0.506137  0.807403  6.530530e-01
tasksDualNoGo                -0.096611 -0.753401  0.560178  7.731141e-01
overlaps_ED_LD                1.940209  0.903424  2.976994  2.446276e-04  ***
tasksDualGo:overlaps_ED_LD   -2.381316 -3.638778 -1.123854  2.058891e-04  ***
tasksDualNoGo:overlaps_ED_LD -1.850660 -3.042371 -0.658950  2.336759e-03   **

                                 day
(Intercept)                    first
tasksDualGo                    first
tasksDualNoGo                  first
overlaps_ED_LD                 first
tasksDualGo:overlaps_ED_LD     first
tasksDualNoGo:overlaps_ED_LD   first
(Intercept)                   middle
tasksDualGo                   middle
tasksDualNoGo                 middle
overlaps_ED_LD                middle
tasksDualGo:overlaps_ED_LD    middle
tasksDualNoGo:overlaps_ED_LD  middle
(Intercept)                     last
tasksDualGo                     last
tasksDualNoGo                   last
overlaps_ED_LD                  last
tasksDualGo:overlaps_ED_LD      last
tasksDualNoGo:overlaps_ED_LD    last
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import seaborn as sns

# Thresholds for significance markers
p_value_annotations = [(0.001, '***'), (0.01, '**'), (0.05, '*'), (0.1, '.')]

# Set up the subplots
unique_coefs = df_combined.index.unique()
fig, axes = plt.subplots(nrows=len(unique_coefs) // 3, ncols=3, figsize=(3*width, len(unique_coefs) // 3
                                                                    ,* height), sharex=True)

for coef, ax in zip(unique_coefs, axes.flatten()):
    sub_df = df_combined.loc[coef].reset_index()  # Select data for the current coefficient

    sns.lineplot(x='day', y='coef', data=sub_df, ax=ax, marker='o')

    # Plotting the confidence intervals
    ax.fill_between(x=sub_df['day'], y1=sub_df['lower_ci'], y2=sub_df['upper_ci'], alpha=0.3)

    for idx in range(len(sub_df)):
        for threshold, marker in p_value_annotations:
            if sub_df.loc[idx, 'p_value'] <= threshold:
                ax.text(sub_df.loc[idx, 'day'], sub_df.loc[idx, 'coef'] + 1 , marker, ha='center', fontsize=20, color='red')
                break

    ax.set_title(f'Evolution of {coef} over Time', fontsize=10)
    # ax.legend()
    ax.set_xlabel('Day')
    ax.set_ylabel('Coefficient Value')

fig.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_41.png]]

*** Overlaps
**** Overlaps ~ day * tasks
#+begin_src ipython
df_sample_day = df_sample.day.astype('category')
#+end_src

#+RESULTS:
: [1 2 3 4 5 6]

#+begin_src ipython
  formula = 'overlaps_ED_LD ~ day + (1 + day | mouse)'

  data = df_sample.copy()
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse!='ACCM04']
  glm = Lmer(formula=formula, data=data, family='gaussian')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by REML [’lmerMod’]
Formula: overlaps_ED_LD~day+(1+day|mouse)

Family: gaussian	 Inference: parametric

Number of observations: 3072	 Groups: {'mouse': 4.0}

Log-likelihood: -2758.520 	 AIC: 5529.040

Random effects:

                 Name    Var    Std
mouse     (Intercept)  0.027  0.166
mouse             day  0.000  0.018
Residual               0.349  0.591

               IV1  IV2   Corr
mouse  (Intercept)  day  0.107

Fixed effects:

             Estimate  2.5_ci  97.5_ci     SE     DF  T-stat  P-val Sig
(Intercept)     0.218   0.048    0.387  0.087  3.097   2.513  0.084   .
day             0.009  -0.013    0.031  0.011  2.869   0.766  0.502
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+.1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_44.png]]

**** Overlaps ~ day * tasks

#+begin_src ipython
formula = 'overlaps_ED_LD ~ day * tasks + (1 | mouse)'

data = df_sample.copy()
data = data[data.mouse!='JawsM18']
# data = data[data.mouse!='ACCM04']
glm = Lmer(formula=formula, data=data, family='gaussian')
result = glm.fit()
print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by REML [’lmerMod’]
Formula: overlaps_ED_LD~day*tasks+(1|mouse)

Family: gaussian	 Inference: parametric

Number of observations: 3072	 Groups: {'mouse': 4.0}

Log-likelihood: -2745.017 	 AIC: 5506.034

Random effects:

                 Name    Var    Std
mouse     (Intercept)  0.033  0.180
Residual               0.344  0.587

No random effect correlations specified

Fixed effects:

                   Estimate  2.5_ci  97.5_ci     SE        DF  T-stat  P-val  \
(Intercept)           0.298   0.103    0.493  0.100     4.373   2.989  0.036
day                   0.017  -0.007    0.040  0.012  3063.721   1.409  0.159
tasksDualGo          -0.066  -0.182    0.050  0.059  3063.021  -1.110  0.267
tasksDualNoGo        -0.169  -0.285   -0.053  0.059  3063.021  -2.850  0.004
day:tasksDualGo      -0.022  -0.055    0.011  0.017  3063.021  -1.313  0.189
day:tasksDualNoGo    -0.003  -0.036    0.030  0.017  3063.021  -0.183  0.855

                  Sig
(Intercept)         *
day
tasksDualGo
tasksDualNoGo      **
day:tasksDualGo
day:tasksDualNoGo
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)


df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+.2, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_47.png]]

* distractor dfs
*** data

#+begin_src ipython
name = 'df_distractor_overlaps'
df_dist = pkl_load(name, path="../data/mice/overlaps")
#+end_src

#+RESULTS:
: loading from ../data/mice/overlaps/df_distractor_overlaps.pkl

#+begin_src ipython
df_dist = df_mice.copy()
print(df_dist.head())
#+end_src

#+RESULTS:
#+begin_example
   sample_odor  dist_odor  test_odor tasks      response  laser  day  \
0          0.0        0.0        0.0   DPA   correct_hit    0.0    1
1          0.0        0.0        1.0   DPA  incorrect_fa    0.0    1
2          0.0        0.0        0.0   DPA   correct_hit    0.0    1
3          0.0        0.0        1.0   DPA   correct_rej    0.0    1
4          0.0        0.0        0.0   DPA   correct_hit    0.0    1

                                            overlaps mouse  performance  pair
0  [-0.3442525863647461, -0.04141944274306297, -0...  PP09            1     1
1  [-0.322248250246048, 0.08833469450473785, -0.1...  PP09            0     0
2  [-0.04603399708867073, 0.01701030693948269, -0...  PP09            1     1
3  [-0.16955529153347015, -0.20525024831295013, -...  PP09            1     0
4  [0.3878960907459259, 0.09251184016466141, -0.1...  PP09            1     1
#+end_example

#+begin_src ipython
df_dist['overlaps_diag'] = df_dist['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['MD']
df_dist['overlaps_MD'] = df_dist['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['DIST']
df_dist['overlaps_DIST'] = df_dist['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['ED']
df_dist['overlaps_MD_ED'] = df_dist['overlaps_DIST'].apply(lambda x: avg_epochs(np.array(x), **options))
df_dist['overlaps_diag_ED'] = df_dist['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_dist['sign_overlaps_MD_ED'] = df_dist['overlaps_MD'].apply(lambda x: np.sign(avg_epochs(np.array(x), **options)))
#+end_src

#+RESULTS:

#+begin_src ipython
print(df_dist.head())
#+end_src
#+RESULTS:
#+begin_example
   sample_odor  dist_odor  test_odor tasks      response  laser  day  \
0          0.0        0.0        0.0   DPA   correct_hit    0.0    1
1          0.0        0.0        1.0   DPA  incorrect_fa    0.0    1
2          0.0        0.0        0.0   DPA   correct_hit    0.0    1
3          0.0        0.0        1.0   DPA   correct_rej    0.0    1
4          0.0        0.0        0.0   DPA   correct_hit    0.0    1

                                            overlaps mouse  performance  pair  \
0  [-0.3442525863647461, -0.04141944274306297, -0...  PP09            1     1
1  [-0.322248250246048, 0.08833469450473785, -0.1...  PP09            0     0
2  [-0.04603399708867073, 0.01701030693948269, -0...  PP09            1     1
3  [-0.16955529153347015, -0.20525024831295013, -...  PP09            1     0
4  [0.3878960907459259, 0.09251184016466141, -0.1...  PP09            1     1

                                       overlaps_diag  \
0  [-0.3442525863647461, 0.029838597401976585, -0...
1  [-0.322248250246048, 0.10657349228858948, -0.5...
2  [-0.04603399708867073, -0.06943497806787491, -...
3  [-0.16955529153347015, -0.0035652611404657364,...
4  [0.3878960907459259, -0.13655686378479004, -0....

                                         overlaps_MD  \
0  [0.014985544063771764, -0.1999471535285314, 0....
1  [0.42582574983437854, 0.27422136316696805, 0.4...
2  [-0.07830995290229718, -0.11111781684060891, -...
3  [-0.022336509777233005, 0.04112395582099756, 0...
4  [0.011525196333726248, 0.1604848743105928, -0....

                                       overlaps_DIST  overlaps_MD_ED  \
0  [0.19225353111202517, 0.06317550040936719, 0.1...        0.031609
1  [0.41496171553929645, 0.29091663906971615, 0.3...        0.164930
2  [-0.14071175456047058, -0.08201891540860136, -...        0.352185
3  [0.022185410062472027, 0.13152312518407902, 0....       -0.003053
4  [0.4669429063796997, 0.4767242620388667, -0.27...        0.590973

   overlaps_diag_ED  sign_overlaps_MD_ED
0          0.061470                 -1.0
1         -0.025762                  1.0
2          0.261512                  1.0
3         -0.093867                  1.0
4          0.011589                  1.0
#+end_example

#+begin_src ipython
import seaborn as sns
df = df_dist
# df = df_dist[df_dist.mouse=='ChRM04']
# df = df[df.tasks=='DualGo']
#df.overlaps_MD_ED = df.overlaps_MD_ED
# df.day = np.exp(df.day)
sns.lineplot(data=df, x='day', y='overlaps_MD_ED', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])

# Set plot labels and title
plt.xlabel('Day')
plt.ylabel('Sample Overlap')
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_56.png]]

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height), sharex=True, sharey=True)

df = df_dist[df_dist.mouse!='JawsM18']
# df = df_dist.copy()

for i in range(1, 7):
     plot_overlaps(df, i, 'MD', ax[0])

# plot_overlaps(df, 'first', 'MD', ax[0])
# plot_overlaps(df, 'middle', 'MD', ax[1])
# plot_overlaps(df, 'last', 'MD', ax[2])

# plot_overlaps(df, 'first', 'diag', ax[0])
# plot_overlaps(df, 'middle', 'diag', ax[1])
# plot_overlaps(df, 'last', 'diag', ax[2])

# ax[2].legend(fontsize=10)

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_57.png]]

*** Performance
**** Performance ~ overlaps * days * tasks

#+begin_src ipython
  formula = 'performance ~ day * tasks + (1 | mouse)'

  data = df_dist.copy()
  # data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Cell In[53], line 6
      3 data = df_dist.copy()
      4 # data = data[data.mouse!='JawsM18']
      5 # data = data[data.mouse !='ACCM04']
----> 6 glm = Lmer(formula=formula, data=data, family='binomial')
      7 result = glm.fit()
      8 print(result)

NameError: name 'Lmer' is not defined
#+end_example
:END:

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Cell In[54], line 7
      3 import numpy as np
      5 # Assuming you already have model and glm.coef()
      6 coefficients = {
----> 7     'coef': glm.coefs['Estimate'],
      8     'lower_ci': glm.coefs['2.5_ci'],
      9     'upper_ci': glm.coefs['97.5_ci'],
     10     'p_value': glm.coefs['P-val']
     11 }
     13 df_coefs = pd.DataFrame(coefficients)
     15 # Determine significance markers

NameError: name 'glm' is not defined
#+end_example
:END:

**** Performance ~ day * tasks

#+begin_src ipython
  df_dist['tasks'] = df_dist['tasks'].astype('category')
  # df_dist['day'] = df_dist['day'].astype('int')

  formula = 'performance ~ tasks * day + (1 + tasks + day | mouse)'
  data = df_dist.copy()
  # data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']

  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Cell In[55], line 9
      5 data = df_dist.copy()
      6 # data = data[data.mouse!='JawsM18']
      7 # data = data[data.mouse !='ACCM04']
----> 9 glm = Lmer(formula=formula, data=data, family='binomial')
     10 result = glm.fit()
     11 print(result)

NameError: name 'Lmer' is not defined
#+end_example
:END:

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)


df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Cell In[56], line 7
      3 import numpy as np
      5 # Assuming you already have model and glm.coef()
      6 coefficients = {
----> 7     'coef': glm.coefs['Estimate'],
      8     'lower_ci': glm.coefs['2.5_ci'],
      9     'upper_ci': glm.coefs['97.5_ci'],
     10     'p_value': glm.coefs['P-val']
     11 }
     13 df_coefs = pd.DataFrame(coefficients)
     16 df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

NameError: name 'glm' is not defined
#+end_example
:END:

**** Performance ~ overlaps

#+begin_src ipython
df_dist['sign_overlaps_MD_ED'] = df_dist['overlaps_MD_ED'].apply(lambda x: (2*np.sign(x) - 1) * x)

formula = 'performance ~ overlaps_MD_ED + (1 | mouse)'

data = df_dist[['overlaps_MD_ED', 'sign_overlaps_MD_ED', 'performance', 'mouse', 'day']]
# data = data[data.mouse!='JawsM18']
# data = data[data.mouse !='ACCM04']

glm = Lmer(formula=formula, data=data, family='binomial')
result = glm.fit()
print(result)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Cell In[57], line 9
      5 data = df_dist[['overlaps_MD_ED', 'sign_overlaps_MD_ED', 'performance', 'mouse', 'day']]
      6 # data = data[data.mouse!='JawsM18']
      7 # data = data[data.mouse !='ACCM04']
----> 9 glm = Lmer(formula=formula, data=data, family='binomial')
     10 result = glm.fit()
     11 print(result)

NameError: name 'Lmer' is not defined
#+end_example
:END:

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Cell In[58], line 7
      3 import numpy as np
      5 # Assuming you already have model and glm.coef()
      6 coefficients = {
----> 7     'coef': glm.coefs['Estimate'],
      8     'lower_ci': glm.coefs['2.5_ci'],
      9     'upper_ci': glm.coefs['97.5_ci'],
     10     'p_value': glm.coefs['P-val']
     11 }
     13 df_coefs = pd.DataFrame(coefficients)
     15 df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

NameError: name 'glm' is not defined
#+end_example
:END:


#+begin_src ipython
from rpy2.robjects import r
from rpy2.robjects.packages import importr
from rpy2.robjects import pandas2ri
pandas2ri.activate()

lme4 = importr('lme4')

# Convert dataframe to R dataframe
r_dataframe = pandas2ri.py2rpy(data)

# Fit the model
formula = 'performance ~ sign_overlaps_MD_ED * day + (1 + day | mouse)'
glm = lme4.glmer(formula, data=r_dataframe, family='binomial')

base = importr('base')
summary = base.summary(glm)
print(summary)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
hon
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight
#+end_example
# [goto error]
#+begin_example
---------------------------------------------------------------------------
RRuntimeError                             Traceback (most recent call last)
Cell In[59], line 13
     11 # Fit the model
     12 formula = 'performance ~ sign_overlaps_MD_ED * day + (1 + day | mouse)'
---> 13 glm = lme4.glmer(formula, data=r_dataframe, family='binomial')
     15 base = importr('base')
     16 summary = base.summary(glm)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:208, in SignatureTranslatedFunction.__call__(self, *args, **kwargs)
    206         v = kwargs.pop(k)
    207         kwargs[r_k] = v
--> 208 return (super(SignatureTranslatedFunction, self)
    209         .__call__(*args, **kwargs))

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:131, in Function.__call__(self, *args, **kwargs)
    129     else:
    130         new_kwargs[k] = cv.py2rpy(v)
--> 131 res = super(Function, self).__call__(*new_args, **new_kwargs)
    132 res = cv.rpy2py(res)
    133 return res

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/rinterface_lib/conversion.py:45, in _cdata_res_to_rinterface.<locals>._(*args, **kwargs)
     44 def _(*args, **kwargs):
---> 45     cdata = function(*args, **kwargs)
     46     # TODO: test cdata is of the expected CType
     47     return _cdata_to_rinterface(cdata)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/rinterface.py:817, in SexpClosure.__call__(self, *args, **kwargs)
    810     res = rmemory.protect(
    811         openrlib.rlib.R_tryEval(
    812             call_r,
    813             call_context.__sexp__._cdata,
    814             error_occured)
    815     )
    816     if error_occured[0]:
--> 817         raise embedded.RRuntimeError(_rinterface._geterrmessage())
    818 return res

RRuntimeError: Error: grouping factors must have > 1 sampled level
#+end_example
:END:
#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:

**** Performance ~ overlaps * days

#+begin_src ipython
  formula = 'performance ~ overlaps_MD_ED * day  + (1 + day | mouse)'

  data = df_dist[['performance', 'overlaps_MD_ED', 'mouse', 'day', 'tasks']].copy()
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[61], line 6
:       4 data = data[data.mouse!='JawsM18']
:       5 # data = data[data.mouse !='ACCM04']
: ----> 6 glm = Lmer(formula=formula, data=data, family='binomial')
:       7 result = glm.fit()
:       8 print(result)
:
: NameError: name 'Lmer' is not defined
:END:

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+.1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Cell In[62], line 7
      3 import numpy as np
      5 # Assuming you already have model and glm.coef()
      6 coefficients = {
----> 7     'coef': glm.coefs['Estimate'],
      8     'lower_ci': glm.coefs['2.5_ci'],
      9     'upper_ci': glm.coefs['97.5_ci'],
     10     'p_value': glm.coefs['P-val']
     11 }
     13 df_coefs = pd.DataFrame(coefficients)
     15 # Determine significance markers

NameError: name 'glm' is not defined
#+end_example
:END:

**** Performance ~ overlaps * tasks

#+begin_src ipython
  formula = 'performance ~ tasks * overlaps_MD_ED  + (tasks | mouse)'

  data = df_dist.copy()
  # data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Cell In[63], line 6
      3 data = df_dist.copy()
      4 # data = data[data.mouse!='JawsM18']
      5 # data = data[data.mouse !='ACCM04']
----> 6 glm = Lmer(formula=formula, data=data, family='binomial')
      7 result = glm.fit()
      8 print(result)

NameError: name 'Lmer' is not defined
#+end_example
:END:

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Cell In[64], line 7
      3 import numpy as np
      5 # Assuming you already have model and glm.coef()
      6 coefficients = {
----> 7     'coef': glm.coefs['Estimate'],
      8     'lower_ci': glm.coefs['2.5_ci'],
      9     'upper_ci': glm.coefs['97.5_ci'],
     10     'p_value': glm.coefs['P-val']
     11 }
     13 df_coefs = pd.DataFrame(coefficients)
     15 # Determine significance markers

NameError: name 'glm' is not defined
#+end_example
:END:

**** Performance per day

#+begin_src ipython
results = []
formula = 'performance ~ tasks * overlaps_MD_ED  + (1 + tasks | mouse)'
for day in df_dist.day.unique():
  data = df_dist.copy()
  data = data[data.day==day]
  data = data[data.mouse!='JawsM18']
  data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  glm.fit();
  results.append(glm)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[65], line 8
:       6 data = data[data.mouse!='JawsM18']
:       7 data = data[data.mouse !='ACCM04']
: ----> 8 glm = Lmer(formula=formula, data=data, family='binomial')
:       9 glm.fit();
:      10 results.append(glm)
:
: NameError: name 'Lmer' is not defined
:END:

#+begin_src ipython
import pandas as pd

# Assuming you have the list of results from all sessions
combined_results = []

for i, result in enumerate(results):
    coefficients = {
        'coef': result.coefs['Estimate'],
        'lower_ci': result.coefs['2.5_ci'],
        'upper_ci': result.coefs['97.5_ci'],
        'p_value': result.coefs['P-val'],
        'Sig': result.coefs['Sig'],
        'day': df_dist.day.unique()[i]  # Add a session identifier
    }
    df_result = pd.DataFrame(coefficients)
    combined_results.append(df_result)

df_combined = pd.concat(combined_results)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[66], line 18
     15     df_result = pd.DataFrame(coefficients)
     16     combined_results.append(df_result)
---> 18 df_combined = pd.concat(combined_results)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/reshape/concat.py:380, in concat(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)
    377 elif copy and using_copy_on_write():
    378     copy = False
--> 380 op = _Concatenator(
    381     objs,
    382     axis=axis,
    383     ignore_index=ignore_index,
    384     join=join,
    385     keys=keys,
    386     levels=levels,
    387     names=names,
    388     verify_integrity=verify_integrity,
    389     copy=copy,
    390     sort=sort,
    391 )
    393 return op.get_result()

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/reshape/concat.py:443, in _Concatenator.__init__(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)
    440 self.verify_integrity = verify_integrity
    441 self.copy = copy
--> 443 objs, keys = self._clean_keys_and_objs(objs, keys)
    445 # figure out what our result ndim is going to be
    446 ndims = self._get_ndims(objs)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/reshape/concat.py:505, in _Concatenator._clean_keys_and_objs(self, objs, keys)
    502     objs_list = list(objs)
    504 if len(objs_list) == 0:
--> 505     raise ValueError("No objects to concatenate")
    507 if keys is None:
    508     objs_list = list(com.not_none(*objs_list))

ValueError: No objects to concatenate
#+end_example
:END:

#+begin_src ipython
print(df_combined)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[67], line 1
: ----> 1 print(df_combined)
:
: NameError: name 'df_combined' is not defined
:END:

#+begin_src ipython
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# * Function to determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '**'
    elif p < 0.01:
        return '*'
    elif p < 0.05:
        return '*'
    elif np.round(p, 2) == 0.05:
        return '.'
    else:
        return ''

# Set up the subplots
unique_coefs = df_combined.index.unique()
fig, axes = plt.subplots(nrows=len(unique_coefs) // 3, ncols=3, figsize=(width * 3, (len(unique_coefs) // 3 * height)), sharex=True, sharey=True)
axes = axes.flatten()

for coef, ax in zip(unique_coefs, axes):
    sub_df = df_combined.loc[coef].reset_index()  # Select data for the current coefficient

    sns.lineplot(x='day', y='coef', data=sub_df, ax=ax, marker='o')

    # Plotting the confidence intervals
    ax.fill_between(x=sub_df['day'], y1=sub_df['lower_ci'], y2=sub_df['upper_ci'], alpha=0.3)

    for idx in range(len(sub_df)):
        marker = significance_marker(sub_df.loc[idx, 'p_value'])
        if marker:
            ax.text(sub_df.loc[idx, 'day'], sub_df.loc[idx, 'coef'] + 1, marker, ha='center', fontsize=20, color='red')

    ax.set_title(f'{coef}', fontsize=14)
    ax.set_xlabel('Day')
    ax.set_ylabel('Coefficient Value')

fig.tight_layout()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[68], line 19
:      16         return ''
:      18 # Set up the subplots
: ---> 19 unique_coefs = df_combined.index.unique()
:      20 fig, axes = plt.subplots(nrows=len(unique_coefs) // 3, ncols=3, figsize=(width * 3, (len(unique_coefs) // 3 * height)), sharex=True, sharey=True)
:      21 axes = axes.flatten()
:
: NameError: name 'df_combined' is not defined
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

*** Overlaps
**** Overlaps ~ day

#+begin_src ipython
  formula = 'overlaps_MD_ED ~ day + (1 + tasks | mouse)'

  data = df_dist.copy()
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse!='ACCM04']
  glm = Lmer(formula=formula, data=data, family='gaussian')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[69], line 6
:       4 data = data[data.mouse!='JawsM18']
:       5 # data = data[data.mouse!='ACCM04']
: ----> 6 glm = Lmer(formula=formula, data=data, family='gaussian')
:       7 result = glm.fit()
:       8 print(result)
:
: NameError: name 'Lmer' is not defined
:END:

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)
df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+.1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Cell In[70], line 7
      3 import numpy as np
      5 # Assuming you already have model and glm.coef()
      6 coefficients = {
----> 7     'coef': glm.coefs['Estimate'],
      8     'lower_ci': glm.coefs['2.5_ci'],
      9     'upper_ci': glm.coefs['97.5_ci'],
     10     'p_value': glm.coefs['P-val']
     11 }
     13 df_coefs = pd.DataFrame(coefficients)
     14 df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

NameError: name 'glm' is not defined
#+end_example
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

**** Overlaps ~ day * tasks

#+begin_src ipython
  formula = 'overlaps_MD_ED ~ 1 + day * tasks + (1 + tasks | mouse) '

  data = df_dist.copy()
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse!='ACCM04']
  glm = Lmer(formula=formula, data=data, family='gaussian')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[71], line 6
:       4 data = data[data.mouse!='JawsM18']
:       5 # data = data[data.mouse!='ACCM04']
: ----> 6 glm = Lmer(formula=formula, data=data, family='gaussian')
:       7 result = glm.fit()
:       8 print(result)
:
: NameError: name 'Lmer' is not defined
:END:


#+RESULTS:

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+.1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Cell In[72], line 7
      3 import numpy as np
      5 # Assuming you already have model and glm.coef()
      6 coefficients = {
----> 7     'coef': glm.coefs['Estimate'],
      8     'lower_ci': glm.coefs['2.5_ci'],
      9     'upper_ci': glm.coefs['97.5_ci'],
     10     'p_value': glm.coefs['P-val']
     11 }
     13 df_coefs = pd.DataFrame(coefficients)
     15 df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

NameError: name 'glm' is not defined
#+end_example
:END:

#+begin_src ipython

#+end_src

#+RESULTS:
