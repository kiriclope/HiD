#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session decoder :kernel dual_data :exports results :output-dir ./figures/overlaps :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python

* Imports
#+begin_src ipython
  from sklearn.exceptions import ConvergenceWarning
  warnings.filterwarnings("ignore")
  import traceback

  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import os
  if not sys.warnoptions:
    warnings.simplefilter("ignore")
    os.environ["PYTHONWARNINGS"] = "ignore"

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  import pandas as pd

  from time import perf_counter

  from sklearn.base import clone
  from sklearn.metrics import make_scorer, roc_auc_score
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.model_selection import RepeatedStratifiedKFold, LeaveOneOut, StratifiedKFold

  from src.common.plot_utils import add_vlines, add_vdashed
  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.preprocess.helpers import avg_epochs

  from src.torch.classificationCV import ClassificationCV
  from src.torch.main import get_classification
#+end_src

#+RESULTS:

* Helpers

#+begin_src ipython
def pad_with_nans(array, target_shape):
    result = np.full(target_shape, np.nan)  # Create an array filled with NaNs
    print(result.shape)
    slices = tuple(slice(0, min(dim, target)) for dim, target in zip(array.shape, target_shape))
    result[slices] = array[slices]
    return result
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import numpy as np

  def safe_roc_auc_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return np.nan  # return np.nan where the score cannot be calculated
      return roc_auc_score(y_true, y_score)

  def safe_f1_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return np.nan  # return np.nan where the score cannot be calculated
      return f1_score(y_true, y_score)
      #+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def rescale_coefs(model, coefs, bias):

          try:
                  means = model.named_steps["scaler"].mean_
                  scales = model.named_steps["scaler"].scale_

                  # Rescale the coefficients
                  rescaled_coefs = np.true_divide(coefs, scales)

                  # Adjust the intercept
                  rescaled_bias = bias - np.sum(rescaled_coefs * means)

                  return rescaled_coefs, rescaled_bias
          except:
                  return coefs, bias

#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  from scipy.stats import bootstrap

  def get_bootstrap_ci(data, statistic=np.mean, confidence_level=0.95, n_resamples=1000, random_state=None):
      result = bootstrap((data,), statistic)
      ci_lower, ci_upper = result.confidence_interval
      return np.array([ci_lower, ci_upper])
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

* Parameters

#+begin_src ipython
  DEVICE = 'cuda:0'
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  N_NEURONS = [668, 693, 444, 361, 113]

  tasks = ['DPA', 'DualGo', 'DualNoGo']
  # mice = ['AP02', 'AP12', 'PP09', 'PP17', 'RP17']
  # mice = ['PP09', 'PP17']

  kwargs = {
      'mouse': 'JawsM15', 'laser': 0,
      'trials': '', 'reload': 0, 'data_type': 'dF',
      'prescreen': None, 'pval': 0.05,
      'preprocess': False, 'scaler_BL': 'robust',
      'avg_noise':True, 'unit_var_BL': True,
      'random_state': None, 'T_WINDOW': 0.0,
      'l1_ratio': 0.95,
      'n_comp': None, 'scaler': None,
      'bootstrap': 1, 'n_boots': 128,
      'n_splits': 5, 'n_repeats': 16,
      'class_weight': 0,
      'multilabel':0,
  }

  kwargs['days'] = ['first', 'middle', 'last']
  # kwargs['days'] = 'all'
  options = set_options(**kwargs)
  safe_roc_auc = make_scorer(safe_roc_auc_score, needs_proba=True)
  options['hp_scoring'] = safe_roc_auc
  options['n_jobs'] = 30
#+end_src

#+RESULTS:

#+begin_src ipython
def overlaps_scorer(estimator, X_test, y_test, IF_SIGN=0):
    try:
        coef = estimator.named_steps["net"].coef_.flatten()
    except:
        coef = estimator.best_estimator_.named_steps["net"].coef_.flatten()

    if IF_SIGN:
        dot_product = (2*y_test -1) * np.dot(X_test, coef) / coef.shape[0] * 1000.0 # / np.linalg.norm(coef)
    else:
        dot_product = -np.dot(X_test, coef) / coef.shape[0] * 1000.0 # / np.linalg.norm(coef)

    return dot_product.mean()


options['scoring'] = overlaps_scorer
# options['hp_scoring'] = 'overlaps_scorer'
#+end_src

#+RESULTS:

#+begin_src ipython
def signed_overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1):
    try:
        coef = estimator.named_steps["net"].coef_.flatten()
    except:
        coef = estimator.best_estimator_.named_steps["net"].coef_.flatten()

    if IF_SIGN:
        dot_product = (2*y_test -1) * np.dot(X_test, coef) / coef.shape[0] * 1000.0 # / np.linalg.norm(coef)
    else:
        dot_product = -np.dot(X_test, coef) / coef.shape[0] * 1000.0 # / np.linalg.norm(coef)
    # if IF_SIGN:
    #     dot_product = (2*y_test -1) * np.dot(X_test, coef) / np.linalg.norm(coef)
    # else:
    #     dot_product = -np.dot(X_test, coef) / np.linalg.norm(coef)

    return dot_product.mean()


options['scoring'] = overlaps_scorer
# options['hp_scoring'] = 'overlaps_scorer'
#+end_src

#+RESULTS:

* Decoding vs days
** Model

#+begin_src ipython
from sklearn.linear_model import LogisticRegression
# net = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', n_jobs=None)
net = LogisticRegression(penalty='elasticnet', solver='saga', class_weight='balanced', n_jobs=None, l1_ratio=0.95, max_iter=100, tol=.001)
# net = LogisticRegression(penalty='elasticnet', solver='saga', class_weight='balanced', n_jobs=None, l1_ratio=0.95, max_iter=100, tol=.001, multi_class='multinomial')

params = {'net__C': np.logspace(-4, 4, 10)} # , 'net__l1_ratio': np.linspace(0, 1, 10)}

options['n_jobs'] = -1
options['verbose'] = 0
model = ClassificationCV(net, params, **options)
options['cv'] = LeaveOneOut()
#+end_src

#+RESULTS:

** Sample Overlap

#+begin_src ipython
options['verbose'] = 1
options['features'] = 'sample'
options['epochs'] = ['ED']
options['scoring'] = signed_overlaps_scorer
options['reload'] = 0

tasks = ['DPA', 'DualGo', 'DualNoGo']

dfs = []
mice = ['ChRM23']

for mouse in mice:
    df_mouse = []
    options['mouse'] = mouse
    options = set_options(**options)
    days = options['days']

    for task in tasks:
        options['task'] = task

        for day in days:
            options['day'] = day
            overlaps = get_classification(model, RETURN='df_scores', **options)
            options['reload'] = 0
            df_mouse.append(overlaps)

    df_mouse = pd.concat(df_mouse)
    df_mouse['mouse'] = mouse
    dfs.append(df_mouse)

df_mice = pd.concat(dfs)
print(df_mice.shape)
    #+end_src

#+RESULTS:
#+begin_example
Loading files from /home/leon/dual_task/dual_data/data/ChRM23
DATA: FEATURES sample TASK DPA TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (32, 232, 115) X_S2 (32, 232, 115)
y_labels ['DPA']
X (64, 232, 115) y (64,) [0. 1.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM23
DATA: FEATURES sample TASK DPA TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (32, 232, 115) X_S2 (32, 232, 115)
y_labels ['DPA']
X (64, 232, 115) y (64,) [0. 1.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM23
DATA: FEATURES sample TASK DPA TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (16, 232, 115) X_S2 (16, 232, 115)
y_labels ['DPA']
X (32, 232, 115) y (32,) [0. 1.]
scores (32, 115, 115)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM23
DATA: FEATURES sample TASK DualGo TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (32, 232, 115) X_S2 (32, 232, 115)
y_labels ['DualGo']
X (64, 232, 115) y (64,) [0. 1.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DualGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM23
DATA: FEATURES sample TASK DualGo TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (32, 232, 115) X_S2 (32, 232, 115)
y_labels ['DualGo']
X (64, 232, 115) y (64,) [0. 1.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DualGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM23
DATA: FEATURES sample TASK DualGo TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (16, 232, 115) X_S2 (16, 232, 115)
y_labels ['DualGo']
X (32, 232, 115) y (32,) [0. 1.]
scores (32, 115, 115)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM23
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (32, 232, 115) X_S2 (32, 232, 115)
y_labels ['DualNoGo']
X (64, 232, 115) y (64,) [0. 1.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM23
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (32, 232, 115) X_S2 (32, 232, 115)
y_labels ['DualNoGo']
X (64, 232, 115) y (64,) [0. 1.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM23
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_S1 (16, 232, 115) X_S2 (16, 232, 115)
y_labels ['DualNoGo']
X (32, 232, 115) y (32,) [0. 1.]
scores (32, 115, 115)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
(480, 10)
#+end_example

#+begin_src ipython
df_mice['performance'] = df_mice['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_mice['pair'] = df_mice['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
#+end_src

#+RESULTS:

#+begin_src ipython
if len(days)>3:
    name = 'df_sample_overlaps_days'
else:
    name = 'df_sample_overlaps'

pkl_save(df_mice, '%s' % name, path="../data/mice/overlaps")
#+end_src

#+RESULTS:
: saving to ../data/mice/overlaps/df_sample_overlaps.pkl

** Distractor overlap

#+begin_src ipython
options['verbose'] = 1
options['features'] = 'distractor'
options['epochs'] = ['MD']
options['scoring'] = overlaps_scorer
options['reload'] = 1
tasks = ['DPA', 'Dual']
dfs = []

# mice = ['PP09']
# mice = ['PP09', 'PP17']
# mice = ['AP02', 'AP12']

options['cv'] = LeaveOneOut()

for mouse in mice:
    df_mouse = []
    options['mouse'] = mouse

    options = set_options(**options)
    days = options['days']

    for task in tasks:
        options['task'] = task
        for day in days:

            options['day'] = day

            try:
                overlaps = get_classification(model, RETURN='df_scores', **options)
            except Exception as exc:
                print(traceback.format_exc())
                break

            options['reload'] = 0
            df_mouse.append(overlaps)

    df_mouse = pd.concat(df_mouse)
    df_mouse['mouse'] = mouse
    dfs.append(df_mouse)

df_mice = pd.concat(dfs)
print(df_mice.shape)
    #+end_src

#+RESULTS:
#+begin_example
Reading data from source file
mouse ChRM04 n_days 6 day 1 type dF all data: X (192, 668, 115) y (9, 192)
mouse ChRM04 n_days 6 day 2 type dF all data: X (192, 668, 115) y (9, 192)
mouse ChRM04 n_days 6 day 3 type dF all data: X (192, 668, 115) y (9, 192)
mouse ChRM04 n_days 6 day 4 type dF all data: X (192, 668, 115) y (9, 192)
mouse ChRM04 n_days 6 day 5 type dF all data: X (192, 668, 115) y (9, 192)
mouse ChRM04 n_days 6 day 6 type dF all data: X (192, 668, 115) y (9, 192)
DATA: FEATURES sample TASK DPA TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_test (64, 668, 115) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DPA']
X (128, 668, 115) y (128,) [0. 1. 2. 3.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_test (64, 668, 115) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DPA']
X (128, 668, 115) y (128,) [0. 1. 2. 3.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_test (64, 668, 115) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DPA']
X (128, 668, 115) y (128,) [0. 1. 2. 3.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DualGo' 'DualNoGo']
X (128, 668, 115) y (128,) [0. 1. 2. 3.]
scores (128, 115, 115)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DualGo' 'DualNoGo']
X (128, 668, 115) y (128,) [0. 1. 2. 3.]
scores (128, 115, 115)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DualGo' 'DualNoGo']
X (128, 668, 115) y (128,) [0. 1. 2. 3.]
scores (128, 115, 115)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_test (64, 693, 115) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DPA']
X (128, 693, 115) y (128,) [0. 1. 2. 3.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_test (64, 693, 115) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DPA']
X (128, 693, 115) y (128,) [0. 1. 2. 3.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_test (64, 693, 115) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DPA']
X (128, 693, 115) y (128,) [0. 1. 2. 3.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DualGo' 'DualNoGo']
X (128, 693, 115) y (128,) [0. 1. 2. 3.]
scores (128, 115, 115)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DualGo' 'DualNoGo']
X (128, 693, 115) y (128,) [0. 1. 2. 3.]
scores (128, 115, 115)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DualGo' 'DualNoGo']
X (128, 693, 115) y (128,) [0. 1. 2. 3.]
scores (128, 115, 115)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DPA TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_test (64, 444, 115) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DPA']
X (128, 444, 115) y (128,) [0. 1. 2. 3.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DPA TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_test (64, 444, 115) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DPA']
X (128, 444, 115) y (128,) [0. 1. 2. 3.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DPA TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_test (64, 444, 115) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DPA']
X (128, 444, 115) y (128,) [0. 1. 2. 3.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DualGo' 'DualNoGo']
X (128, 444, 115) y (128,) [0. 1. 2. 3.]
scores (128, 115, 115)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DualGo' 'DualNoGo']
X (128, 444, 115) y (128,) [0. 1. 2. 3.]
scores (128, 115, 115)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DualGo' 'DualNoGo']
X (128, 444, 115) y (128,) [0. 1. 2. 3.]
scores (128, 115, 115)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DPA TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_test (128, 361, 115) y_test (128,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DPA']
X (256, 361, 115) y (256,) [0. 1. 2. 3.]
scores (128, 115, 115)
(128, 1) (128, 8)
y_labels ['DPA']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DPA TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_test (128, 361, 115) y_test (128,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DPA']
X (256, 361, 115) y (256,) [0. 1. 2. 3.]
scores (128, 115, 115)
(128, 1) (128, 8)
y_labels ['DPA']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DPA TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_test (64, 361, 115) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DPA']
X (128, 361, 115) y (128,) [0. 1. 2. 3.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DualGo' 'DualNoGo']
X (256, 361, 115) y (256,) [0. 1. 2. 3.]
scores (256, 115, 115)
(256, 1) (256, 8)
y_labels ['DualGo' 'DualNoGo']
df (256, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DualGo' 'DualNoGo']
X (256, 361, 115) y (256,) [0. 1. 2. 3.]
scores (256, 115, 115)
(256, 1) (256, 8)
y_labels ['DualGo' 'DualNoGo']
df (256, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DualGo' 'DualNoGo']
X (128, 361, 115) y (128,) [0. 1. 2. 3.]
scores (128, 115, 115)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
X_test (128, 113, 115) y_test (128,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DPA']
X (256, 113, 115) y (256,) [0. 1. 2. 3.]
scores (128, 115, 115)
(128, 1) (128, 8)
y_labels ['DPA']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
X_test (128, 113, 115) y_test (128,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DPA']
X (256, 113, 115) y (256,) [0. 1. 2. 3.]
scores (128, 115, 115)
(128, 1) (128, 8)
y_labels ['DPA']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
X_test (64, 113, 115) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DPA']
X (128, 113, 115) y (128,) [0. 1. 2. 3.]
scores (64, 115, 115)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS first LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DualGo' 'DualNoGo']
X (256, 113, 115) y (256,) [0. 1. 2. 3.]
scores (256, 115, 115)
(256, 1) (256, 8)
y_labels ['DualGo' 'DualNoGo']
df (256, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS middle LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DualGo' 'DualNoGo']
X (256, 113, 115) y (256,) [0. 1. 2. 3.]
scores (256, 115, 115)
(256, 1) (256, 8)
y_labels ['DualGo' 'DualNoGo']
df (256, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS last LASER 0
multiple days, discard 0 first 2 middle 2
y_labels ['DualGo' 'DualNoGo']
X (128, 113, 115) y (128,) [0. 1. 2. 3.]
scores (128, 115, 115)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
(3648, 10)
#+end_example

#+begin_src ipython

#+end_src

#+RESULTS:

#+begin_src ipython
df_mice['performance'] = df_mice['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_mice['pair'] = df_mice['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
#+end_src

#+RESULTS:

#+begin_src ipython
print(df_mice.day.unique())
#+end_src

#+RESULTS:
: ['first' 'middle' 'last']

#+begin_src ipython
if len(days)>3:
    name = 'df_distractor_overlaps_days'
else:
    name = 'df_distractor_overlaps'
if len(mice)==1:
    pkl_save(df_mice, '%s' % name, path="../data/%s/overlaps" % options['mouse'])
else:
    if len(mice)==2:
        pkl_save(df_mice, '%s' % name, path="../data/mice/overlaps_ACC")

#+end_src

#+RESULTS:

* Plots

#+begin_src ipython
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p <.1:
        return '.'
    else:
        return ''
#+end_src

#+RESULTS:

#+begin_src ipython
# import rpy2.robjects as robjects
# from rpy2.robjects.packages import importr

# Set the .libPaths in R
# custom_r_libpath = '~/R/x86_64-pc-linux-gnu-library/4.3/'
# robjects.r('.libPaths("{0}")'.format(custom_r_libpath))

from pymer4.models import Lmer
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_overlaps(df, day, epoch, ax):
    df_ = df[df.day == day].copy()
    colors = ['r', 'b', 'g']
    time_points = np.linspace(0, 14, 115)

    mean_overlaps = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.mean(np.stack(x), axis=0))
    # lower_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
    # upper_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    for i, task in enumerate(mean_overlaps.index):
        ax.plot(time_points, mean_overlaps[task], label=f"Day {task}", color=colors[i])
        # ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)

    ax.set_xlabel('Time (s)')
    ax.set_ylabel('Overlap')
    add_vlines(ax)

def bootstrap_ci_per_task(x, n_bootstrap, ci_idx):
    stacked = np.stack(x)
    return np.array([bootstrap_ci(stacked[:, i], n_bootstrap)[ci_idx] for i in range(stacked.shape[1])])
#+end_src

#+RESULTS:

#+begin_src ipython
def bootstrap_ci(data, n_bootstrap=1000, ci=95):
    bootstrapped_means = np.array([np.mean(np.random.choice(data, size=len(data))) for _ in range(n_bootstrap)])
    lower_bound = np.percentile(bootstrapped_means, (100-ci)/2)
    upper_bound = np.percentile(bootstrapped_means, 100 - (100-ci)/2)
    return lower_bound, upper_bound
#+end_src

#+RESULTS:

* Sample dfs
*** Data

#+begin_src ipython
name = 'df_sample_overlaps'
df_sample = pkl_load(name, path="../data/mice/overlaps")
#+end_src

#+RESULTS:
: loading from ../data/mice/overlaps/df_sample_overlaps.pkl

#+begin_src ipython
df_sample = df_mice.copy()
#+end_src

#+RESULTS:

 #+begin_src ipython
df_sample['overlaps_diag'] = df_sample['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(115, 115)))
#+end_src

#+RESULTS:

 #+begin_src ipython
options['epochs'] = ['ED']
df_sample['overlaps_ED'] = df_sample['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(115, 115).T, **options))
#+end_src

#+RESULTS:

 #+begin_src ipython
options['epochs'] = ['MD']
df_sample['overlaps_MD'] = df_sample['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(115, 115).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['LD']
df_sample['overlaps_ED_LD'] = df_sample['overlaps_ED'].apply(lambda x: avg_epochs(np.array(x), **options))
df_sample['overlaps_diag_LD'] = df_sample['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_sample['overlaps_MD_LD'] = df_sample['overlaps_MD'].apply(lambda x: avg_epochs(np.array(x), **options))
# print(df_sample.head())
#+end_src

#+RESULTS:

#+begin_src ipython
import seaborn as sns
df = df_sample[df_sample.mouse=='JawsM15']
sns.lineplot(data=df, x='day', y='performance', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])

# Set plot labels and title
plt.xlabel('Day')
plt.ylabel('Behavior')
plt.title('Behavior vs Day per Task')
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_30.png]]

#+begin_src ipython
import seaborn as sns
sns.lineplot(data=df_sample, x='day', y='overlaps_ED_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])

# Set plot labels and title
plt.xlabel('Day')
plt.ylabel('Sample Overlap')
plt.title('Behavior vs Day per Task')
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_31.png]]


#+RESULTS:

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height), sharex=True, sharey=True)

# df = df_sample[df_sample.mouse!='JawsM18']
# df = df_dist.copy()

# plot_overlaps(df, 'first', 'ED', ax[0])
# plot_overlaps(df, 'middle', 'ED', ax[1])
# plot_overlaps(df, 'last', 'ED', ax[2])

plot_overlaps(df, 'first', 'diag', ax[0])
plot_overlaps(df, 'middle', 'diag', ax[1])
plot_overlaps(df, 'last', 'diag', ax[2])

ax[2].legend(fontsize=10)

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_32.png]]

*** Performance
**** Performance ~ day * tasks

#+begin_src ipython
  formula = 'performance ~ tasks * day + (day + tasks | mouse)'
  data = df_sample.copy()
  # data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']

  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Model failed to converge with max|grad| = 0.0108763 (tol = 0.002, component 1)

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*day+(day+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1765.235 	 AIC: 3578.470

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.230  0.480
mouse        daylast  0.558  0.747
mouse      daymiddle  0.191  0.437
mouse    tasksDualGo  0.103  0.321
mouse  tasksDualNoGo  0.017  0.129

               IV1            IV2   Corr
mouse  (Intercept)        daylast  0.163
mouse  (Intercept)      daymiddle  0.873
mouse  (Intercept)    tasksDualGo -0.233
mouse  (Intercept)  tasksDualNoGo -0.908
mouse      daylast      daymiddle  0.588
mouse      daylast    tasksDualGo -0.405
mouse      daylast  tasksDualNoGo -0.435
mouse    daymiddle    tasksDualGo -0.536
mouse    daymiddle  tasksDualNoGo -0.979
mouse  tasksDualGo  tasksDualNoGo  0.591

Fixed effects:

                         Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
(Intercept)                 0.769   0.297    1.241  0.241  2.159      1.346
tasksDualGo                -0.209  -0.617    0.199  0.208  0.811      0.540
tasksDualNoGo              -0.045  -0.361    0.272  0.161  0.956      0.697
daylast                     1.858   1.044    2.672  0.415  6.410      2.1151
daymiddle                   1.412   0.878    1.946  0.272  4.103      2.405
tasksDualGo:daylast        -0.204  -0.808    0.399  0.308  0.815      0.446
tasksDualNoGo:daylast      -0.366  -0.968    0.236  0.307  0.693      0.380
tasksDualGo:daymiddle      -0.402  -0.858    0.053  0.232  0.669      0.424
tasksDualNoGo:daymiddle    -0.128  -0.601    0.345  0.241  0.880      0.548

                         OR_97.5_ci   Prob  Prob_2.5_ci  Prob_97.5_ci  Z-stat  \
(Intercept)                   3.461  0.683        0.574         0.776   3.195
tasksDualGo                   1.220  0.448        0.350         0.550  -1.005
tasksDualNoGo                 1.312  0.489        0.411         0.567  -0.277
daylast                      14.463  0.865        0.740         0.935   4.474
daymiddle                     6.998  0.804        0.706         0.875   5.182
tasksDualGo:daylast           1.491  0.449        0.308         0.599  -0.664
tasksDualNoGo:daylast         1.266  0.409        0.275         0.559  -1.192
tasksDualGo:daymiddle         1.055  0.401        0.298         0.513  -1.730
tasksDualNoGo:daymiddle       1.412  0.468        0.354         0.585  -0.530

                         P-val  Sig
(Intercept)              0.001   **
tasksDualGo              0.315
tasksDualNoGo            0.782
daylast                  0.000  ***
daymiddle                0.000  ***
tasksDualGo:daylast      0.507
tasksDualNoGo:daylast    0.233
tasksDualGo:daymiddle    0.0115    .
tasksDualNoGo:daymiddle  0.596
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)
df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+.5*np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_33.png]]

**** Performance ~ overlaps * days * tasks

#+begin_src ipython
  formula = 'performance ~ day * tasks * overlaps_ED_LD  + (1 + day + tasks | mouse)'

  data = df_sample.copy()
  # data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Model failed to converge with max|grad| = 0.0113298 (tol = 0.002, component 1)

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~day*tasks*overlaps_ED_LD+(1+day+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1756.355 	 AIC: 3578.709

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.223  0.472
mouse        daylast  0.5115  0.764
mouse      daymiddle  0.189  0.435
mouse    tasksDualGo  0.063  0.251
mouse  tasksDualNoGo  0.011  0.105

               IV1            IV2   Corr
mouse  (Intercept)        daylast  0.127
mouse  (Intercept)      daymiddle  0.1159
mouse  (Intercept)    tasksDualGo -0.154
mouse  (Intercept)  tasksDualNoGo -0.964
mouse      daylast      daymiddle  0.565
mouse      daylast    tasksDualGo -0.383
mouse      daylast  tasksDualNoGo -0.385
mouse    daymiddle    tasksDualGo -0.536
mouse    daymiddle  tasksDualNoGo -0.935
mouse  tasksDualGo  tasksDualNoGo  0.224

Fixed effects:

                                        Estimate  2.5_ci  97.5_ci     SE  \
(Intercept)                                0.739   0.264    1.215  0.243
daylast                                    1.606   0.766    2.446  0.429
daymiddle                                  1.365   0.805    1.925  0.286
tasksDualGo                               -0.186  -0.571    0.199  0.196
tasksDualNoGo                              0.003  -0.328    0.334  0.169
overlaps_ED_LD                             0.098  -0.269    0.466  0.188
daylast:tasksDualGo                        0.144  -0.499    0.788  0.328
daymiddle:tasksDualGo                     -0.316  -0.811    0.178  0.252
daylast:tasksDualNoGo                     -0.128  -0.756    0.499  0.320
daymiddle:tasksDualNoGo                   -0.104  -0.613    0.405  0.260
daylast:overlaps_ED_LD                     1.772   0.672    2.873  0.561
daymiddle:overlaps_ED_LD                   0.137  -0.536    0.810  0.343
tasksDualGo:overlaps_ED_LD                -0.057  -0.542    0.428  0.248
tasksDualNoGo:overlaps_ED_LD              -0.189  -0.723    0.346  0.273
daylast:tasksDualGo:overlaps_ED_LD        -2.169  -3.479   -0.859  0.669
daymiddle:tasksDualGo:overlaps_ED_LD      -0.345  -1.199    0.508  0.435
daylast:tasksDualNoGo:overlaps_ED_LD      -1.662  -2.980   -0.345  0.672
daymiddle:tasksDualNoGo:overlaps_ED_LD     0.001  -0.943    0.945  0.482

                                           OR  OR_2.5_ci  OR_97.5_ci   Prob  \
(Intercept)                             2.095      1.302       3.370  0.677
daylast                                 4.982      2.151      11.540  0.833
daymiddle                               3.914      2.236       6.852  0.797
tasksDualGo                             0.830      0.565       1.220  0.454
tasksDualNoGo                           1.003      0.721       1.397  0.501
overlaps_ED_LD                          1.103      0.764       1.594  0.525
daylast:tasksDualGo                     1.155      0.607       2.199  0.536
daymiddle:tasksDualGo                   0.729      0.445       1.195  0.422
daylast:tasksDualNoGo                   0.880      0.470       1.648  0.468
daymiddle:tasksDualNoGo                 0.902      0.542       1.500  0.474
daylast:overlaps_ED_LD                  5.885      1.958      17.686  0.855
daymiddle:overlaps_ED_LD                1.147      0.585       2.247  0.534
tasksDualGo:overlaps_ED_LD              0.945      0.581       1.535  0.486
tasksDualNoGo:overlaps_ED_LD            0.828      0.485       1.413  0.453
daylast:tasksDualGo:overlaps_ED_LD      0.114      0.031       0.424  0.103
daymiddle:tasksDualGo:overlaps_ED_LD    0.708      0.301       1.662  0.414
daylast:tasksDualNoGo:overlaps_ED_LD    0.190      0.051       0.708  0.159
daymiddle:tasksDualNoGo:overlaps_ED_LD  1.001      0.390       2.573  0.500

                                        Prob_2.5_ci  Prob_97.5_ci  Z-stat  \
(Intercept)                                   0.566         0.771   3.049
daylast                                       0.683         0.920   3.747
daymiddle                                     0.691         0.873   4.777
tasksDualGo                                   0.361         0.550  -0.948
tasksDualNoGo                                 0.419         0.583   0.020
overlaps_ED_LD                                0.433         0.614   0.525
daylast:tasksDualGo                           0.378         0.687   0.440
daymiddle:tasksDualGo                         0.308         0.544  -1.254
daylast:tasksDualNoGo                         0.320         0.622  -0.400
daymiddle:tasksDualNoGo                       0.351         0.600  -0.399
daylast:overlaps_ED_LD                        0.662         0.946   3.157
daymiddle:overlaps_ED_LD                      0.369         0.692   0.399
tasksDualGo:overlaps_ED_LD                    0.368         0.605  -0.230
tasksDualNoGo:overlaps_ED_LD                  0.327         0.586  -0.692
daylast:tasksDualGo:overlaps_ED_LD            0.030         0.298  -3.245
daymiddle:tasksDualGo:overlaps_ED_LD          0.232         0.624  -0.793
daylast:tasksDualNoGo:overlaps_ED_LD          0.048         0.415  -2.474
daymiddle:tasksDualNoGo:overlaps_ED_LD        0.280         0.720   0.002

                                        P-val  Sig
(Intercept)                             0.002   **
daylast                                 0.000  ***
daymiddle                               0.000  ***
tasksDualGo                             0.343
tasksDualNoGo                           0.9115
overlaps_ED_LD                          0.600
daylast:tasksDualGo                     0.660
daymiddle:tasksDualGo                   0.210
daylast:tasksDualNoGo                   0.689
daymiddle:tasksDualNoGo                 0.690
daylast:overlaps_ED_LD                  0.002   **
daymiddle:overlaps_ED_LD                0.690
tasksDualGo:overlaps_ED_LD              0.818
tasksDualNoGo:overlaps_ED_LD            0.489
daylast:tasksDualGo:overlaps_ED_LD      0.001   **
daymiddle:tasksDualGo:overlaps_ED_LD    0.428
daylast:tasksDualNoGo:overlaps_ED_LD    0.013    *
daymiddle:tasksDualNoGo:overlaps_ED_LD  0.998
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_35.png]]

**** Performance per day

#+begin_src ipython
results = []
formula = 'performance ~ tasks * overlaps_ED_LD  + (1 + tasks | mouse)'
for day in df_sample.day.unique():
  data = df_sample.copy()
  data = data[data.day==day]
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  glm.fit();
  results.append(glm)
#+end_src

#+RESULTS:
#+begin_example
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_ED_LD+(1+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 1152	 Groups: {'mouse': 4.0}

Log-likelihood: -759.007 	 AIC: 1542.015

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.186  0.432
mouse    tasksDualGo  0.004  0.066
mouse  tasksDualNoGo  0.007  0.083

               IV1            IV2  Corr
mouse  (Intercept)    tasksDualGo  -1.0
mouse  (Intercept)  tasksDualNoGo  -1.0
mouse  tasksDualGo  tasksDualNoGo   1.0

Fixed effects:
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_ED_LD+(1+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 1152	 Groups: {'mouse': 4.0}

Log-likelihood: -546.648 	 AIC: 1117.296

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.923  0.961
mouse    tasksDualGo  0.390  0.625
mouse  tasksDualNoGo  0.063  0.251

               IV1            IV2   Corr
mouse  (Intercept)    tasksDualGo -0.901
mouse  (Intercept)  tasksDualNoGo -0.986
mouse  tasksDualGo  tasksDualNoGo  0.814

Fixed effects:
Model failed to converge with max|grad| = 0.00690125 (tol = 0.002, component 1)

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_ED_LD+(1+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 768	 Groups: {'mouse': 4.0}

Log-likelihood: -288.533 	 AIC: 601.066

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.321  0.567
mouse    tasksDualGo  0.007  0.082
mouse  tasksDualNoGo  0.070  0.265

               IV1            IV2  Corr
mouse  (Intercept)    tasksDualGo   1.0
mouse  (Intercept)  tasksDualNoGo  -1.0
mouse  tasksDualGo  tasksDualNoGo  -1.0

Fixed effects:
#+end_example

#+begin_src ipython
import pandas as pd

# Assuming you have the list of results from all sessions
combined_results = []

for i, result in enumerate(results):
    coefficients = {
        'coef': result.coefs['Estimate'],
        'lower_ci': result.coefs['2.5_ci'],
        'upper_ci': result.coefs['97.5_ci'],
        'p_value': result.coefs['P-val'],
        'Sig': result.coefs['Sig'],
        'day': df_sample.day.unique()[i]  # Add a session identifier
    }
    df_result = pd.DataFrame(coefficients)
    combined_results.append(df_result)

df_combined = pd.concat(combined_results)
#+end_src

#+RESULTS:

#+begin_src ipython
print(df_combined)
#+end_src

#+RESULTS:
#+begin_example
                                  coef  lower_ci  upper_ci       p_value  Sig  \
(Intercept)                   0.590960  0.095447  1.086472  1.941326e-02    *
tasksDualGo                  -0.219893 -0.571313  0.131526  2.200456e-01
tasksDualNoGo                 0.065029 -0.292921  0.422979  7.217907e-01
overlaps_ED_LD                0.148187 -0.235214  0.531589  4.487264e-01
tasksDualGo:overlaps_ED_LD   -0.0511538 -0.557718  0.4401153  8.185568e-01
tasksDualNoGo:overlaps_ED_LD -0.252372 -0.808545  0.303800  3.738065e-01
(Intercept)                   2.111160  1.060521  3.161800  8.203970e-05  ***
tasksDualGo                  -0.8811514 -1.711319 -0.065508  3.434580e-02    *
tasksDualNoGo                -0.304023 -0.933322  0.325276  3.436974e-01
overlaps_ED_LD               -0.1115518 -0.1158397  0.479361  5.859250e-01
tasksDualGo:overlaps_ED_LD    0.078341 -0.735617  0.892300  8.503743e-01
tasksDualNoGo:overlaps_ED_LD  0.176529 -0.712100  1.065159  6.970145e-01
(Intercept)                   1.860035  1.1263115  2.593686  6.725706e-07  ***
tasksDualGo                   0.150633 -0.506137  0.807403  6.530530e-01
tasksDualNoGo                -0.096611 -0.753401  0.560178  7.731141e-01
overlaps_ED_LD                1.940209  0.903424  2.976994  2.446276e-04  ***
tasksDualGo:overlaps_ED_LD   -2.381316 -3.638778 -1.123854  2.058891e-04  ***
tasksDualNoGo:overlaps_ED_LD -1.850660 -3.042371 -0.658950  2.336759e-03   **

                                 day
(Intercept)                    first
tasksDualGo                    first
tasksDualNoGo                  first
overlaps_ED_LD                 first
tasksDualGo:overlaps_ED_LD     first
tasksDualNoGo:overlaps_ED_LD   first
(Intercept)                   middle
tasksDualGo                   middle
tasksDualNoGo                 middle
overlaps_ED_LD                middle
tasksDualGo:overlaps_ED_LD    middle
tasksDualNoGo:overlaps_ED_LD  middle
(Intercept)                     last
tasksDualGo                     last
tasksDualNoGo                   last
overlaps_ED_LD                  last
tasksDualGo:overlaps_ED_LD      last
tasksDualNoGo:overlaps_ED_LD    last
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import seaborn as sns

# Thresholds for significance markers
p_value_annotations = [(0.001, '***'), (0.01, '**'), (0.05, '*'), (0.1, '.')]

# Set up the subplots
unique_coefs = df_combined.index.unique()
fig, axes = plt.subplots(nrows=len(unique_coefs) // 3, ncols=3, figsize=(3*width, len(unique_coefs) // 3
                                                                    ,* height), sharex=True)

for coef, ax in zip(unique_coefs, axes.flatten()):
    sub_df = df_combined.loc[coef].reset_index()  # Select data for the current coefficient

    sns.lineplot(x='day', y='coef', data=sub_df, ax=ax, marker='o')

    # Plotting the confidence intervals
    ax.fill_between(x=sub_df['day'], y1=sub_df['lower_ci'], y2=sub_df['upper_ci'], alpha=0.3)

    for idx in range(len(sub_df)):
        for threshold, marker in p_value_annotations:
            if sub_df.loc[idx, 'p_value'] <= threshold:
                ax.text(sub_df.loc[idx, 'day'], sub_df.loc[idx, 'coef'] + 1 , marker, ha='center', fontsize=20, color='red')
                break

    ax.set_title(f'Evolution of {coef} over Time', fontsize=10)
    # ax.legend()
    ax.set_xlabel('Day')
    ax.set_ylabel('Coefficient Value')

fig.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_41.png]]

*** Overlaps
**** Overlaps ~ day * tasks

#+begin_src ipython
  formula = 'overlaps_ED_LD ~ day * tasks + (1 + day + tasks | mouse)'

  data = df_sample.copy()
  # data = data[data.mouse!='JawsM18']
  # data = data[data.mouse!='ACCM04']
  glm = Lmer(formula=formula, data=data, family='gaussian')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by REML [’lmerMod’]
Formula: overlaps_ED_LD~day*tasks+(1+day+tasks|mouse)

Family: gaussian	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -2997.676 	 AIC: 6045.352

Random effects:

                   Name    Var    Std
mouse       (Intercept)  0.044  0.209
mouse           daylast  0.006  0.079
mouse         daymiddle  0.001  0.030
mouse       tasksDualGo  0.005  0.068
mouse     tasksDualNoGo  0.011  0.105
Residual                 0.298  0.546

               IV1            IV2   Corr
mouse  (Intercept)        daylast  0.946
mouse  (Intercept)      daymiddle -0.640
mouse  (Intercept)    tasksDualGo -0.933
mouse  (Intercept)  tasksDualNoGo -0.998
mouse      daylast      daymiddle -0.854
mouse      daylast    tasksDualGo -0.766
mouse      daylast  tasksDualNoGo -0.963
mouse    daymiddle    tasksDualGo  0.321
mouse    daymiddle  tasksDualNoGo  0.682
mouse  tasksDualGo  tasksDualNoGo  0.912

Fixed effects:

                         Estimate  2.5_ci  97.5_ci     SE        DF  T-stat  \
(Intercept)                 0.271   0.081    0.461  0.097     4.362   2.792
daylast                     0.110   0.005    0.215  0.053    11.358   2.058
daymiddle                   0.062  -0.015    0.138  0.039    33.233   1.586
tasksDualGo                -0.078  -0.172    0.015  0.048    11.1150  -1.641
tasksDualNoGo              -0.104  -0.221    0.012  0.059     7.619  -1.751
daylast:tasksDualGo        -0.108  -0.219    0.002  0.057  3452.471  -1.916
daymiddle:tasksDualGo      -0.086  -0.187    0.015  0.052  3630.577  -1.662
daylast:tasksDualNoGo      -0.091  -0.202    0.020  0.057  3629.040  -1.606
daymiddle:tasksDualNoGo    -0.055  -0.156    0.046  0.052  3630.577  -1.069

                         P-val Sig
(Intercept)              0.045   *
daylast                  0.063   .
daymiddle                0.122
tasksDualGo              0.127
tasksDualNoGo            0.120
daylast:tasksDualGo      0.055   .
daymiddle:tasksDualGo    0.097   .
daylast:tasksDualNoGo    0.108
daymiddle:tasksDualNoGo  0.285
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 2.0 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_41.png]]

* distractor dfs
** data

#+begin_src ipython
name = 'df_distractor_overlaps'
df_dist = pkl_load(name, path="../data/mice/overlaps")
#+end_src

#+RESULTS:
: loading from ../data/mice/overlaps/df_distractor_overlaps.pkl

#+begin_src ipython
df_dist = df_mice.copy()
print(df_dist.head())
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[17], line 1
: ----> 1 df_dist = df_mice.copy()
:       2 print(df_dist.head())
:
: NameError: name 'df_mice' is not defined
:END:

#+begin_src ipython
print()
#+end_src
#+RESULTS:
:

#+begin_src ipython
df_dist['overlaps_diag'] = df_dist['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(115, 115)))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['MD']
df_dist['overlaps_MD'] = df_dist['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(115, 115).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['DIST']
df_dist['overlaps_DIST'] = df_dist['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(115, 115).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['ED']
df_dist['overlaps_MD_ED'] = df_dist['overlaps_MD'].apply(lambda x: avg_epochs(np.array(x), **options))
df_dist['overlaps_diag_ED'] = df_dist['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_dist['sign_overlaps_MD_ED'] = df_dist['overlaps_MD'].apply(lambda x: np.sign(avg_epochs(np.array(x), **options)))
#+end_src

#+RESULTS:

#+begin_src ipython
print(df_dist.head())
#+end_src

#+RESULTS:
#+begin_example
   index  sample_odor  test_odor      response   tasks  laser    day  \
0      2          1.0        0.0  incorrect_fa  DualGo    0.0  first
1      5          1.0        1.0   correct_hit  DualGo    0.0  first
2     18          0.0        0.0   correct_hit  DualGo    0.0  first
3     21          0.0        1.0  incorrect_fa  DualGo    0.0  first
4     26          1.0        0.0  incorrect_fa  DualGo    0.0  first

   dist_odor  choice                                           overlaps  \
0        0.0     1.0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...
1        0.0     1.0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...
2        0.0     1.0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...
3        0.0     1.0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...
4        0.0     1.0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...

    mouse  performance  pair  \
0  ChRM04            0     0
1  ChRM04            1     1
2  ChRM04            1     1
3  ChRM04            0     0
4  ChRM04            0     0

                                       overlaps_diag  \
0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...
1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...
2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...
3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...
4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...

                                         overlaps_MD  \
0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...
1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...
2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...
3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...
4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...

                                       overlaps_DIST  overlaps_MD_ED  \
0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...             0.0
1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...             0.0
2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...             0.0
3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...             0.0
4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...             0.0

   overlaps_diag_ED  sign_overlaps_MD_ED
0               0.0                  0.0
1               0.0                  0.0
2               0.0                  0.0
3               0.0                  0.0
4               0.0                  0.0
#+end_example

#+begin_src ipython
import seaborn as sns
df = df_dist
# df = df_dist[df_dist.mouse=='ACCM03']
# df = df[df.tasks=='DualGo']
#df.overlaps_MD_ED = df.overlaps_MD_ED
# df.day = np.exp(df.day)
sns.lineplot(data=df, x='day', y='overlaps_MD_ED', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])

# Set plot labels and title
plt.xlabel('Day')
plt.ylabel('Overlap')
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_53.png]]

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height), sharex=True, sharey=True)

df = df_dist[df_dist.mouse=='ChRM04']
#df = df_dist.copy()

# for i in range(1, 7):
#      plot_overlaps(df, i, 'MD', ax[0])

plot_overlaps(df, 'first', 'MD', ax[0])
plot_overlaps(df, 'middle', 'MD', ax[1])
plot_overlaps(df, 'last', 'MD', ax[2])

# plot_overlaps(df, 'first', 'diag', ax[0])
# plot_overlaps(df, 'middle', 'diag', ax[1])
# plot_overlaps(df, 'last', 'diag', ax[2])

# ax[2].legend(fontsize=10)

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_54.png]]

** Performance
*** Performance ~ overlaps * days * tasks

#+begin_src ipython
  formula = 'performance ~ day * overlaps_MD_ED + (1 + day | mouse)'

  data = df_dist.copy()
  data = data[data.mouse!='DPA']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
boundary (singular) fit: see help('isSingular')
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~day*overlaps_MD_ED+(1+day|mouse)

Family: binomial	 Inference: parametric

Number of observations: 2432	 Groups: {'mouse': 5.0}

Log-likelihood: -1229.447 	 AIC: 2482.894

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.165  0.406
mouse      daylast  0.232  0.482
mouse    daymiddle  0.173  0.416

               IV1        IV2   Corr
mouse  (Intercept)    daylast  0.114
mouse  (Intercept)  daymiddle  0.1156
mouse      daylast  daymiddle  0.625

Fixed effects:

                          Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
(Intercept)                  0.665   0.270    1.060  0.202  1.944      1.310
daylast                      1.440   0.900    1.979  0.275  4.219      2.461
daymiddle                    1.046   0.578    1.514  0.239  2.1156      1.782
overlaps_MD_ED              -0.183  -0.654    0.288  0.240  0.833      0.520
daylast:overlaps_MD_ED       0.6115  -0.133    1.500  0.417  1.981      0.876
daymiddle:overlaps_MD_ED     0.459  -0.281    1.199  0.378  1.583      0.755

                          OR_97.5_ci   Prob  Prob_2.5_ci  Prob_97.5_ci  \
(Intercept)                    2.886  0.660        0.567         0.743
daylast                        7.233  0.808        0.711         0.879
daymiddle                      4.544  0.740        0.641         0.820
overlaps_MD_ED                 1.334  0.454        0.342         0.571
daylast:overlaps_MD_ED         4.483  0.665        0.467         0.818
daymiddle:overlaps_MD_ED       3.318  0.613        0.430         0.768

                          Z-stat  P-val  Sig
(Intercept)                3.299  0.001  ***
daylast                    5.234  0.000  ***
daymiddle                  4.379  0.000  ***
overlaps_MD_ED            -0.762  0.446
daylast:overlaps_MD_ED     1.641  0.101
daymiddle:overlaps_MD_ED   1.216  0.224
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, 1.5 * np.max(df_coefs.coef), f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_56.png]]

*** Performance ~ overlaps

#+begin_src ipython
df_dist['sign_overlaps_MD_ED'] = df_dist['overlaps_MD_ED'].apply(lambda x: (2*np.sign(x) - 1))
formula = 'performance ~ sign_overlaps_MD_ED + (1 | mouse)'
data = df_dist[['overlaps_MD_ED', 'sign_overlaps_MD_ED', 'performance', 'mouse', 'day']]
#+end_src

#+RESULTS:

#+begin_src ipython
import numpy as np
import matplotlib.pyplot as plt
from rpy2.robjects import pandas2ri
import rpy2.robjects as ro

pandas2ri.activate()

# Extract model summary
summary = ro.r.summary(glm)
coefs = np.array(summary.rx2('coefficients'))

# Extract coefficient estimates and confidence intervals
estimates = coefs[:,0]
stderr = coefs[:,1]
p_values = coefs[:, 3]
ci_low = estimates - 1.96 * stderr
ci_high = estimates + 1.96 * stderr

# Labels for the coefficients
# labels = summary.rx2('coefficients').rownames

# Plotting
plt.figure(figsize=(8, 6))
plt.errorbar(range(len(estimates)), estimates, yerr=[estimates - ci_low, ci_high - estimates], fmt='o')
plt.axhline(0, color='gray', linestyle='--')
# plt.xticks(range(len(estimates)), labels, rotation=45, ha='right')
plt.xlabel('Coefficients')
plt.ylabel('Estimate')
# plt.title('Coefficients with 95% Confidence Intervals')
for i, (est, ci_l, ci_h, p) in enumerate(zip(estimates, ci_low, ci_high, p_values)):
    significance = significance_marker(p)
    plt.text(i, ci_h + 0.05, significance, ha='center', va='bottom', color='red', fontsize=20)

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
Cell In[29], line 9
      6 pandas2ri.activate()
      8 # Extract model summary
----> 9 summary = ro.r.summary(glm)
     10 coefs = np.array(summary.rx2('coefficients'))
     12 # Extract coefficient estimates and confidence intervals

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:208, in SignatureTranslatedFunction.__call__(self, *args, **kwargs)
    206         v = kwargs.pop(k)
    207         kwargs[r_k] = v
--> 208 return (super(SignatureTranslatedFunction, self)
    209         .__call__(*args, **kwargs))

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:123, in Function.__call__(self, *args, **kwargs)
    121 def __call__(self, *args, **kwargs):
    122     cv = conversion.get_conversion()
--> 123     new_args = [cv.py2rpy(a) for a in args]
    124     new_kwargs = {}
    125     for k, v in kwargs.items():
    126         # TODO: shouldn't this be handled by the conversion itself ?

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:123, in <listcomp>(.0)
    121 def __call__(self, *args, **kwargs):
    122     cv = conversion.get_conversion()
--> 123     new_args = [cv.py2rpy(a) for a in args]
    124     new_kwargs = {}
    125     for k, v in kwargs.items():
    126         # TODO: shouldn't this be handled by the conversion itself ?

File ~/mambaforge/envs/dual_data/lib/python3.11/functools.py:909, in singledispatch.<locals>.wrapper(*args, **kw)
    905 if not args:
    906     raise TypeError(f'{funcname} requires at least '
    907                     '1 positional argument')
--> 909 return dispatch(args[0].__class__)(*args, **kw)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/conversion.py:240, in _py2rpy(obj)
    238 if isinstance(obj, _rinterface_capi.SupportsSEXP):
    239     return obj
--> 240 raise NotImplementedError(
    241     "Conversion 'py2rpy' not defined for objects of type '%s'" %
    242     str(type(obj))
    243 )

NotImplementedError: Conversion 'py2rpy' not defined for objects of type '<class 'pymer4.models.Lmer.Lmer'>'
#+end_example
:END:

#+begin_src ipython
from rpy2.robjects import r
from rpy2.robjects.packages import importr
from rpy2.robjects import pandas2ri
pandas2ri.activate()

lme4 = importr('lme4')

# Convert dataframe to R dataframe
r_dataframe = pandas2ri.py2rpy(data)

# Fit the model
formula = 'performance ~ sign_overlaps_MD_ED + (1 | mouse)'
glm = lme4.glmer(formula, data=r_dataframe, family='binomial') ;
#+end_src

#+RESULTS:

*** Performance per day

#+begin_src ipython
results = []
formula = 'performance ~ tasks * overlaps_MD_ED *day + (1 + tasks | mouse)'
for day in df_dist.day.unique():
  data = df_dist.copy()
  data = data[data.day==day]
  # data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  glm.fit();
  results.append(glm)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
RRuntimeError                             Traceback (most recent call last)
Cell In[31], line 9
      6 # data = data[data.mouse!='JawsM18']
      7 # data = data[data.mouse !='ACCM04']
      8 glm = Lmer(formula=formula, data=data, family='binomial')
----> 9 glm.fit();
     10 results.append(glm)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pymer4/models/Lmer.py:440, in Lmer.fit(self, conf_int, n_boot, factors, permute, ordered, verbose, REML, rank, rank_group, rank_exclude_cols, no_warnings, control, old_optimizer, **kwargs)
    438         _fam = self.family
    439     lmc = robjects.r(f"glmerControl({control})")
--> 440     self.model_obj = lmer.glmer(
    441         self.formula,
    442         data=data,
    443         family=_fam,
    444         control=lmc,
    445         contrasts=contrasts,
    446     )
    448 # Store design matrix and get number of IVs for inference
    449 design_matrix = stats.model_matrix(self.model_obj)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:208, in SignatureTranslatedFunction.__call__(self, *args, **kwargs)
    206         v = kwargs.pop(k)
    207         kwargs[r_k] = v
--> 208 return (super(SignatureTranslatedFunction, self)
    209         .__call__(*args, **kwargs))

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:131, in Function.__call__(self, *args, **kwargs)
    129     else:
    130         new_kwargs[k] = cv.py2rpy(v)
--> 131 res = super(Function, self).__call__(*new_args, **new_kwargs)
    132 res = cv.rpy2py(res)
    133 return res

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/rinterface_lib/conversion.py:45, in _cdata_res_to_rinterface.<locals>._(*args, **kwargs)
     44 def _(*args, **kwargs):
---> 45     cdata = function(*args, **kwargs)
     46     # TODO: test cdata is of the expected CType
     47     return _cdata_to_rinterface(cdata)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/rinterface.py:869, in SexpClosure.__call__(self, *args, **kwargs)
    862     res = rmemory.protect(
    863         openrlib.rlib.R_tryEval(
    864             call_r,
    865             call_context.__sexp__._cdata,
    866             error_occured)
    867     )
    868     if error_occured[0]:
--> 869         raise embedded.RRuntimeError(_rinterface._geterrmessage())
    870 return res

RRuntimeError: Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
  contrasts can be applied only to factors with 2 or more levels
#+end_example
:END:

#+begin_src ipython
import pandas as pd

# Assuming you have the list of results from all sessions
combined_results = []

for i, result in enumerate(results):
    coefficients = {
        'coef': result.coefs['Estimate'],
        'lower_ci': result.coefs['2.5_ci'],
        'upper_ci': result.coefs['97.5_ci'],
        'p_value': result.coefs['P-val'],
        'Sig': result.coefs['Sig'],
        'day': df_dist.day.unique()[i]  # Add a session identifier
    }
    df_result = pd.DataFrame(coefficients)
    combined_results.append(df_result)

df_combined = pd.concat(combined_results)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[32], line 18
     15     df_result = pd.DataFrame(coefficients)
     16     combined_results.append(df_result)
---> 18 df_combined = pd.concat(combined_results)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/reshape/concat.py:380, in concat(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)
    377 elif copy and using_copy_on_write():
    378     copy = False
--> 380 op = _Concatenator(
    381     objs,
    382     axis=axis,
    383     ignore_index=ignore_index,
    3115     join=join,
    385     keys=keys,
    386     levels=levels,
    387     names=names,
    388     verify_integrity=verify_integrity,
    389     copy=copy,
    390     sort=sort,
    391 )
    393 return op.get_result()

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/reshape/concat.py:443, in _Concatenator.__init__(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)
    440 self.verify_integrity = verify_integrity
    441 self.copy = copy
--> 443 objs, keys = self._clean_keys_and_objs(objs, keys)
    445 # figure out what our result ndim is going to be
    446 ndims = self._get_ndims(objs)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/reshape/concat.py:505, in _Concatenator._clean_keys_and_objs(self, objs, keys)
    502     objs_list = list(objs)
    504 if len(objs_list) == 0:
--> 505     raise ValueError("No objects to concatenate")
    507 if keys is None:
    508     objs_list = list(com.not_none(*objs_list))

ValueError: No objects to concatenate
#+end_example
:END:

#+begin_src ipython
print(df_combined)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[33], line 1
: ----> 1 print(df_combined)
:
: NameError: name 'df_combined' is not defined
:END:

#+begin_src ipython
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Set up the subplots
unique_coefs = df_combined.index.unique()
fig, axes = plt.subplots(nrows=len(unique_coefs) // 3, ncols=3, figsize=(width * 3, (len(unique_coefs) // 3 * height)), sharex=True, sharey=True)
axes = axes.flatten()

for coef, ax in zip(unique_coefs, axes):
    sub_df = df_combined.loc[coef].reset_index()  # Select data for the current coefficient

    sns.lineplot(x='day', y='coef', data=sub_df, ax=ax, marker='o')

    # Plotting the confidence intervals
    ax.fill_between(x=sub_df['day'], y1=sub_df['lower_ci'], y2=sub_df['upper_ci'], alpha=0.3)

    for idx in range(len(sub_df)):
        marker = significance_marker(sub_df.loc[idx, 'p_value'])
        if marker:
            ax.text(sub_df.loc[idx, 'day'], sub_df.loc[idx, 'coef'] + 1, marker, ha='center', fontsize=20, color='red')

    ax.set_title(f'{coef}', fontsize=14)
    ax.set_xlabel('Day')
    ax.set_ylabel('Coefficient Value')

fig.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_73.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

** Overlaps
*** Overlaps ~ day * tasks

#+begin_src ipython
  formula = 'overlaps_MD_ED ~ day * tasks + (1 + day | mouse)'
  data = df_dist.copy()
  # data = data[data.mouse!='JawsM18']
  # data = data[data.mouse!='ACCM04']
  glm = Lmer(formula=formula, data=data, family='gaussian')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
RRuntimeError                             Traceback (most recent call last)
Cell In[28], line 6
      3 # data = data[data.mouse!='JawsM18']
      4 # data = data[data.mouse!='ACCM04']
      5 glm = Lmer(formula=formula, data=data, family='gaussian')
----> 6 result = glm.fit()
      7 print(result)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pymer4/models/Lmer.py:422, in Lmer.fit(self, conf_int, n_boot, factors, permute, ordered, verbose, REML, rank, rank_group, rank_exclude_cols, no_warnings, control, old_optimizer, **kwargs)
    417 if verbose:
    418     print(
    419         f"Fitting linear model using lmer with {conf_int} confidence intervals...\n"
    420     )
--> 422 lmer = importr("lmerTest")
    423 lmc = robjects.r(f"lmerControl({control})")
    424 self.model_obj = lmer.lmer(
    425     self.formula, data=data, REML=REML, control=lmc, contrasts=contrasts
    426 )

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/packages.py:486, in importr(name, lib_loc, robject_translations, signature_translation, suppress_messages, on_conflict, symbol_r2python, symbol_resolve, data)
    483 exported_names: typing.Optional[typing.Set[str]]
    4115 if _package_has_namespace(name,
    485                           _system_file(package=name)):
--> 486     env = _get_namespace(name)
    487     version = _get_namespace_version(name)[0]
    488     exported_names = set(_get_namespace_exports(name))

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/rinterface_lib/conversion.py:45, in _cdata_res_to_rinterface.<locals>._(*args, **kwargs)
     44 def _(*args, **kwargs):
---> 45     cdata = function(*args, **kwargs)
     46     # TODO: test cdata is of the expected CType
     47     return _cdata_to_rinterface(cdata)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/rinterface.py:817, in SexpClosure.__call__(self, *args, **kwargs)
    810     res = rmemory.protect(
    811         openrlib.rlib.R_tryEval(
    812             call_r,
    813             call_context.__sexp__._cdata,
    814             error_occured)
    815     )
    816     if error_occured[0]:
--> 817         raise embedded.RRuntimeError(_rinterface._geterrmessage())
    818 return res

RRuntimeError: Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object '/home/leon/R/x86_64-pc-linux-gnu-library/4.3/lme4/libs/lme4.so':
  /home/leon/mambaforge/envs/dual_data/lib/python3.11/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6: version `CXXABI_1.3.15' not found (required by /home/leon/R/x86_64-pc-linux-gnu-library/4.3/lme4/libs/lme4.so)
#+end_example
:END:

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+.1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_62.png]]

#+begin_src ipython

#+end_src

#+RESULTS:
