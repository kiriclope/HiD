#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session decoder :kernel dual_data :exports results :output-dir ./figures/overlaps :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python

* Imports
#+begin_src ipython
  from sklearn.exceptions import ConvergenceWarning
  warnings.filterwarnings("ignore")

  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import os
  if not sys.warnoptions:
    warnings.simplefilter("ignore")
    os.environ["PYTHONWARNINGS"] = "ignore"

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  import pandas as pd

  from time import perf_counter

  from sklearn.base import clone
  from sklearn.metrics import make_scorer, roc_auc_score
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.model_selection import RepeatedStratifiedKFold, LeaveOneOut, StratifiedKFold

  from src.common.plot_utils import add_vlines, add_vdashed
  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.preprocess.helpers import avg_epochs

  from src.torch.classificationCV import ClassificationCV
  from src.torch.main import get_classification
#+end_src

#+RESULTS:

* Helpers

#+begin_src ipython
def pad_with_nans(array, target_shape):
    result = np.full(target_shape, np.nan)  # Create an array filled with NaNs
    print(result.shape)
    slices = tuple(slice(0, min(dim, target)) for dim, target in zip(array.shape, target_shape))
    result[slices] = array[slices]
    return result
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import numpy as np

  def safe_roc_auc_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return np.nan  # return np.nan where the score cannot be calculated
      return roc_auc_score(y_true, y_score)
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def rescale_coefs(model, coefs, bias):

          try:
                  means = model.named_steps["scaler"].mean_
                  scales = model.named_steps["scaler"].scale_

                  # Rescale the coefficients
                  rescaled_coefs = np.true_divide(coefs, scales)

                  # Adjust the intercept
                  rescaled_bias = bias - np.sum(rescaled_coefs * means)

                  return rescaled_coefs, rescaled_bias
          except:
                  return coefs, bias

#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  from scipy.stats import bootstrap

  def get_bootstrap_ci(data, statistic=np.mean, confidence_level=0.95, n_resamples=1000, random_state=None):
      result = bootstrap((data,), statistic)
      ci_lower, ci_upper = result.confidence_interval
      return np.array([ci_lower, ci_upper])
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

* Parameters

#+begin_src ipython
  DEVICE = 'cuda:0'
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  N_NEURONS = [668, 693, 444, 361, 113]

  tasks = ['DPA', 'DualGo', 'DualNoGo']
  # mice = ['AP02', 'AP12', 'PP09', 'PP17', 'RP17']

  kwargs = {
      'mouse': 'ChRM04', 'laser': 0,
      'trials': '', 'reload': 0, 'data_type': 'dF',
      'prescreen': None, 'pval': 0.05,
      'preprocess': False, 'scaler_BL': 'robust',
      'avg_noise':True, 'unit_var_BL': True,
      'random_state': None, 'T_WINDOW': 0.0,
      'l1_ratio': 0.95,
      'n_comp': None, 'scaler': None,
      'bootstrap': 1, 'n_boots': 128,
      'n_splits': 3, 'n_repeats': 32,
      'class_weight': 0,
      'multilabel':0,
  }

  # kwargs['days'] = ['first', 'middle', 'last']
  options = set_options(**kwargs)
  days = np.arange(1, options['n_days']+1)
  # days = ['first', 'middle', 'last']

  safe_roc_auc = make_scorer(safe_roc_auc_score, needs_proba=True)
  options['hp_scoring'] = safe_roc_auc
  options['n_jobs'] = 30
#+end_src

#+RESULTS:

#+begin_src ipython
def overlaps_scorer(estimator, X_test, y_test, IF_SIGN=0):
    coef = estimator.named_steps["net"].coef_.flatten()
    if IF_SIGN:
        dot_product = (2*y_test -1) * np.dot(X_test, coef) / np.linalg.norm(coef)
    else:
        dot_product = -np.dot(X_test, coef) / np.linalg.norm(coef)

    return dot_product.mean()


options['scoring'] = overlaps_scorer
# options['hp_scoring'] = 'overlaps_scorer'
#+end_src

#+RESULTS:

#+begin_src ipython
def signed_overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1):
    coef = estimator.named_steps["net"].coef_.flatten()
    if IF_SIGN:
        dot_product = (2*y_test -1) * np.dot(X_test, coef) / np.linalg.norm(coef)
    else:
        dot_product = -np.dot(X_test, coef) / np.linalg.norm(coef)

    return dot_product.mean()


options['scoring'] = overlaps_scorer
# options['hp_scoring'] = 'overlaps_scorer'
#+end_src

#+RESULTS:

* Decoding vs days
** Model

#+begin_src ipython
from sklearn.linear_model import LogisticRegression
# net = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', n_jobs=None)
net = LogisticRegression(penalty='elasticnet', solver='saga', class_weight='balanced', n_jobs=None, l1_ratio=0.95, max_iter=100, tol=.001)
# net = LogisticRegression(penalty='elasticnet', solver='saga', class_weight='balanced', n_jobs=None, l1_ratio=0.95, max_iter=100, tol=.001, multi_class='multinomial')

params = {'net__C': np.logspace(-4, 4, 20)}

options['n_jobs'] = -1
options['verbose'] = 0
model = ClassificationCV(net, params, **options)
options['verbose'] = 1
options['cv'] = LeaveOneOut()
#+end_src

#+RESULTS:

** Sample Overlap

#+begin_src ipython
options['features'] = 'sample'
options['epochs'] = ['ED']
options['scoring'] = signed_overlaps_scorer

tasks = ['DPA', 'DualGo', 'DualNoGo']

dfs = []
for mouse in mice:
    df_mouse = []
    options['mouse'] = mouse
    options = set_options(**options)
    days = np.arange(1, options['n_days']+1)

    for task in tasks:
        options['task'] = task

        for day in days:
            options['day'] = day
            overlaps = get_classification(model, RETURN='df_scores', **options)
            options['reload'] = 0
            df_mouse.append(overlaps)

    df_mouse = pd.concat(df_mouse)
    df_mouse['mouse'] = mouse
    dfs.append(df_mouse)

df_mice = pd.concat(dfs)
print(df_mice.shape)
    #+end_src

#+RESULTS:
#+begin_example
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 1 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DPA']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 2 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DPA']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 3 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DPA']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 4 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DPA']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 5 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DPA']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 6 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DPA']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 1 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DualGo']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 2 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DualGo']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 3 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DualGo']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 4 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DualGo']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 5 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DualGo']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 6 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DualGo']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 1 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DualNoGo']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 2 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DualNoGo']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 3 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DualNoGo']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 4 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DualNoGo']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 5 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DualNoGo']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 6 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
y_labels ['DualNoGo']
X (32, 668, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 1 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DPA']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 2 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DPA']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 3 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DPA']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 4 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DPA']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 5 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DPA']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 6 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DPA']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 1 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DualGo']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 2 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DualGo']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 3 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DualGo']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 4 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DualGo']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 5 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DualGo']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 6 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DualGo']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 1 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DualNoGo']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 2 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DualNoGo']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 3 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DualNoGo']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 4 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DualNoGo']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 5 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DualNoGo']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 6 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
y_labels ['DualNoGo']
X (32, 693, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DPA TRIALS  DAYS 1 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DPA']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DPA TRIALS  DAYS 2 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DPA']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DPA TRIALS  DAYS 3 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DPA']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DPA TRIALS  DAYS 4 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DPA']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DPA TRIALS  DAYS 5 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DPA']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DPA TRIALS  DAYS 6 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DPA']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 1 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DualGo']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 2 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DualGo']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 3 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DualGo']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 4 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DualGo']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 5 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DualGo']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 6 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DualGo']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 1 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DualNoGo']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 2 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DualNoGo']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 3 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DualNoGo']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 4 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DualNoGo']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 5 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DualNoGo']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 6 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
y_labels ['DualNoGo']
X (32, 444, 84) y (32,) [0. 1.]
X_test==X_train
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DualNoGo']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DPA TRIALS  DAYS 1 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
y_labels ['DPA']
X (64, 361, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DPA TRIALS  DAYS 2 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
y_labels ['DPA']
X (64, 361, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DPA TRIALS  DAYS 3 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
y_labels ['DPA']
X (64, 361, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DPA TRIALS  DAYS 4 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
y_labels ['DPA']
X (64, 361, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DPA TRIALS  DAYS 5 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
y_labels ['DPA']
X (64, 361, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 1 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
y_labels ['DualGo']
X (64, 361, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 2 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
y_labels ['DualGo']
X (64, 361, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 3 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
y_labels ['DualGo']
X (64, 361, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 4 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
y_labels ['DualGo']
X (64, 361, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 5 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
y_labels ['DualGo']
X (64, 361, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 1 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
y_labels ['DualNoGo']
X (64, 361, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 2 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
y_labels ['DualNoGo']
X (64, 361, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 3 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
y_labels ['DualNoGo']
X (64, 361, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 4 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
y_labels ['DualNoGo']
X (64, 361, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 5 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
y_labels ['DualNoGo']
X (64, 361, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 1 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
y_labels ['DPA']
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 2 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
y_labels ['DPA']
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 3 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
y_labels ['DPA']
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 4 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
y_labels ['DPA']
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 5 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
y_labels ['DPA']
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 1 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
y_labels ['DualGo']
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 2 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
y_labels ['DualGo']
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 3 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
y_labels ['DualGo']
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 4 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
y_labels ['DualGo']
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DualGo TRIALS  DAYS 5 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
y_labels ['DualGo']
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 1 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
y_labels ['DualNoGo']
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 2 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
y_labels ['DualNoGo']
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 3 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
y_labels ['DualNoGo']
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 4 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
y_labels ['DualNoGo']
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DualNoGo TRIALS  DAYS 5 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
y_labels ['DualNoGo']
X (64, 113, 84) y (64,) [0. 1.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualNoGo']
df (64, 9)
(3648, 10)
#+end_example

#+begin_src ipython
df_mice['performance'] = df_mice['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_mice['pair'] = df_mice['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
#+end_src

#+RESULTS:

#+begin_src ipython
if len(days)>3:
    name = 'df_sample_overlaps_days'
else:
    name = 'df_sample_overlaps'

pkl_save(df_mice, '%s' % name, path="../data/mice/overlaps")
#+end_src

#+RESULTS:
: saving to ../data/mice/overlaps/df_sample_overlaps_days.pkl

** Distractor overlap
*** overlaps

#+begin_src ipython
options['features'] = 'distractor'
options['epochs'] = ['MD']
options['scoring'] = overlaps_scorer

tasks = ['DPA', 'Dual']
dfs = []
# mice = ['JawsM15']
options['cv'] = LeaveOneOut()
for mouse in mice:
    df_mouse = []
    options['mouse'] = mouse

    options = set_options(**options)
    days = np.arange(1, options['n_days']+1)

    for task in tasks:
        options['task'] = task
        for day in days:
            options['day'] = day
            overlaps = get_classification(model, RETURN='df_scores', **options)
            options['reload'] = 0
            df_mouse.append(overlaps)

    df_mouse = pd.concat(df_mouse)
    df_mouse['mouse'] = mouse
    dfs.append(df_mouse)

df_mice = pd.concat(dfs)
print(df_mice.shape)
    #+end_src

#+RESULTS:
#+begin_example
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 1 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
X_test (32, 668, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 1 LASER 0
X_S1 (32, 668, 84) X_S2 (32, 668, 84)
y_labels ['DPA']
X (64, 668, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 2 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
X_test (32, 668, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 2 LASER 0
X_S1 (32, 668, 84) X_S2 (32, 668, 84)
y_labels ['DPA']
X (64, 668, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 3 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
X_test (32, 668, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 3 LASER 0
X_S1 (32, 668, 84) X_S2 (32, 668, 84)
y_labels ['DPA']
X (64, 668, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 4 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
X_test (32, 668, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 4 LASER 0
X_S1 (32, 668, 84) X_S2 (32, 668, 84)
y_labels ['DPA']
X (64, 668, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 5 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
X_test (32, 668, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 5 LASER 0
X_S1 (32, 668, 84) X_S2 (32, 668, 84)
y_labels ['DPA']
X (64, 668, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 6 LASER 0
X_S1 (16, 668, 84) X_S2 (16, 668, 84)
X_test (32, 668, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 6 LASER 0
X_S1 (32, 668, 84) X_S2 (32, 668, 84)
y_labels ['DPA']
X (64, 668, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 1 LASER 0
X_S1 (32, 668, 84) X_S2 (32, 668, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 668, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 2 LASER 0
X_S1 (32, 668, 84) X_S2 (32, 668, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 668, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 3 LASER 0
X_S1 (32, 668, 84) X_S2 (32, 668, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 668, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 4 LASER 0
X_S1 (32, 668, 84) X_S2 (32, 668, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 668, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 5 LASER 0
X_S1 (32, 668, 84) X_S2 (32, 668, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 668, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ChRM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 6 LASER 0
X_S1 (32, 668, 84) X_S2 (32, 668, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 668, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 1 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X_test (32, 693, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 1 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
y_labels ['DPA']
X (64, 693, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 2 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X_test (32, 693, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 2 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
y_labels ['DPA']
X (64, 693, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 3 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X_test (32, 693, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 3 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
y_labels ['DPA']
X (64, 693, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 4 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X_test (32, 693, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 4 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
y_labels ['DPA']
X (64, 693, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 5 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X_test (32, 693, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 5 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
y_labels ['DPA']
X (64, 693, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES sample TASK DPA TRIALS  DAYS 6 LASER 0
X_S1 (16, 693, 84) X_S2 (16, 693, 84)
X_test (32, 693, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 6 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
y_labels ['DPA']
X (64, 693, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 1 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 693, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 2 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 693, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 3 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 693, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 4 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 693, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 5 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 693, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM15
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 6 LASER 0
X_S1 (32, 693, 84) X_S2 (32, 693, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 693, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DPA TRIALS  DAYS 1 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
X_test (32, 444, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 1 LASER 0
X_S1 (32, 444, 84) X_S2 (32, 444, 84)
y_labels ['DPA']
X (64, 444, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DPA TRIALS  DAYS 2 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
X_test (32, 444, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 2 LASER 0
X_S1 (32, 444, 84) X_S2 (32, 444, 84)
y_labels ['DPA']
X (64, 444, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DPA TRIALS  DAYS 3 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
X_test (32, 444, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 3 LASER 0
X_S1 (32, 444, 84) X_S2 (32, 444, 84)
y_labels ['DPA']
X (64, 444, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DPA TRIALS  DAYS 4 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
X_test (32, 444, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 4 LASER 0
X_S1 (32, 444, 84) X_S2 (32, 444, 84)
y_labels ['DPA']
X (64, 444, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DPA TRIALS  DAYS 5 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
X_test (32, 444, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 5 LASER 0
X_S1 (32, 444, 84) X_S2 (32, 444, 84)
y_labels ['DPA']
X (64, 444, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES sample TASK DPA TRIALS  DAYS 6 LASER 0
X_S1 (16, 444, 84) X_S2 (16, 444, 84)
X_test (32, 444, 84) y_test (32,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 6 LASER 0
X_S1 (32, 444, 84) X_S2 (32, 444, 84)
y_labels ['DPA']
X (64, 444, 84) y (64,) [0. 1. 2. 3.]
scores (32, 84, 84)
(32, 1) (32, 8)
y_labels ['DPA']
df (32, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 1 LASER 0
X_S1 (32, 444, 84) X_S2 (32, 444, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 444, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 2 LASER 0
X_S1 (32, 444, 84) X_S2 (32, 444, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 444, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 3 LASER 0
X_S1 (32, 444, 84) X_S2 (32, 444, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 444, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 4 LASER 0
X_S1 (32, 444, 84) X_S2 (32, 444, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 444, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 5 LASER 0
X_S1 (32, 444, 84) X_S2 (32, 444, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 444, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/JawsM18
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 6 LASER 0
X_S1 (32, 444, 84) X_S2 (32, 444, 84)
y_labels ['DualGo' 'DualNoGo']
X (64, 444, 84) y (64,) [0. 1. 2. 3.]
X_test==X_train
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DualGo' 'DualNoGo']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DPA TRIALS  DAYS 1 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
X_test (64, 361, 84) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 1 LASER 0
X_S1 (64, 361, 84) X_S2 (64, 361, 84)
y_labels ['DPA']
X (128, 361, 84) y (128,) [0. 1. 2. 3.]
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DPA TRIALS  DAYS 2 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
X_test (64, 361, 84) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 2 LASER 0
X_S1 (64, 361, 84) X_S2 (64, 361, 84)
y_labels ['DPA']
X (128, 361, 84) y (128,) [0. 1. 2. 3.]
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DPA TRIALS  DAYS 3 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
X_test (64, 361, 84) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 3 LASER 0
X_S1 (64, 361, 84) X_S2 (64, 361, 84)
y_labels ['DPA']
X (128, 361, 84) y (128,) [0. 1. 2. 3.]
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DPA TRIALS  DAYS 4 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
X_test (64, 361, 84) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 4 LASER 0
X_S1 (64, 361, 84) X_S2 (64, 361, 84)
y_labels ['DPA']
X (128, 361, 84) y (128,) [0. 1. 2. 3.]
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES sample TASK DPA TRIALS  DAYS 5 LASER 0
X_S1 (32, 361, 84) X_S2 (32, 361, 84)
X_test (64, 361, 84) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 5 LASER 0
X_S1 (64, 361, 84) X_S2 (64, 361, 84)
y_labels ['DPA']
X (128, 361, 84) y (128,) [0. 1. 2. 3.]
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 1 LASER 0
X_S1 (64, 361, 84) X_S2 (64, 361, 84)
y_labels ['DualGo' 'DualNoGo']
X (128, 361, 84) y (128,) [0. 1. 2. 3.]
X_test==X_train
scores (128, 84, 84)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 2 LASER 0
X_S1 (64, 361, 84) X_S2 (64, 361, 84)
y_labels ['DualGo' 'DualNoGo']
X (128, 361, 84) y (128,) [0. 1. 2. 3.]
X_test==X_train
scores (128, 84, 84)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 3 LASER 0
X_S1 (64, 361, 84) X_S2 (64, 361, 84)
y_labels ['DualGo' 'DualNoGo']
X (128, 361, 84) y (128,) [0. 1. 2. 3.]
X_test==X_train
scores (128, 84, 84)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 4 LASER 0
X_S1 (64, 361, 84) X_S2 (64, 361, 84)
y_labels ['DualGo' 'DualNoGo']
X (128, 361, 84) y (128,) [0. 1. 2. 3.]
X_test==X_train
scores (128, 84, 84)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM03
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 5 LASER 0
X_S1 (64, 361, 84) X_S2 (64, 361, 84)
y_labels ['DualGo' 'DualNoGo']
X (128, 361, 84) y (128,) [0. 1. 2. 3.]
X_test==X_train
scores (128, 84, 84)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 1 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
X_test (64, 113, 84) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 1 LASER 0
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
y_labels ['DPA']
X (128, 113, 84) y (128,) [0. 1. 2. 3.]
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 2 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
X_test (64, 113, 84) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 2 LASER 0
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
y_labels ['DPA']
X (128, 113, 84) y (128,) [0. 1. 2. 3.]
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 3 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
X_test (64, 113, 84) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 3 LASER 0
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
y_labels ['DPA']
X (128, 113, 84) y (128,) [0. 1. 2. 3.]
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 4 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
X_test (64, 113, 84) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 4 LASER 0
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
y_labels ['DPA']
X (128, 113, 84) y (128,) [0. 1. 2. 3.]
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES sample TASK DPA TRIALS  DAYS 5 LASER 0
X_S1 (32, 113, 84) X_S2 (32, 113, 84)
X_test (64, 113, 84) y_test (64,)
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 5 LASER 0
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
y_labels ['DPA']
X (128, 113, 84) y (128,) [0. 1. 2. 3.]
scores (64, 84, 84)
(64, 1) (64, 8)
y_labels ['DPA']
df (64, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 1 LASER 0
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
y_labels ['DualGo' 'DualNoGo']
X (128, 113, 84) y (128,) [0. 1. 2. 3.]
X_test==X_train
scores (128, 84, 84)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 2 LASER 0
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
y_labels ['DualGo' 'DualNoGo']
X (128, 113, 84) y (128,) [0. 1. 2. 3.]
X_test==X_train
scores (128, 84, 84)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 3 LASER 0
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
y_labels ['DualGo' 'DualNoGo']
X (128, 113, 84) y (128,) [0. 1. 2. 3.]
X_test==X_train
scores (128, 84, 84)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 4 LASER 0
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
y_labels ['DualGo' 'DualNoGo']
X (128, 113, 84) y (128,) [0. 1. 2. 3.]
X_test==X_train
scores (128, 84, 84)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
Loading files from /home/leon/dual_task/dual_data/data/ACCM04
DATA: FEATURES distractor TASK Dual TRIALS  DAYS 5 LASER 0
X_S1 (64, 113, 84) X_S2 (64, 113, 84)
y_labels ['DualGo' 'DualNoGo']
X (128, 113, 84) y (128,) [0. 1. 2. 3.]
X_test==X_train
scores (128, 84, 84)
(128, 1) (128, 8)
y_labels ['DualGo' 'DualNoGo']
df (128, 9)
(3648, 10)
#+end_example

#+begin_src ipython
df_mice['performance'] = df_mice['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
df_mice['pair'] = df_mice['response'].apply(lambda x: 0 if (('rej' in x) or ('fa' in x)) else 1)
#+end_src

#+RESULTS:

#+begin_src ipython
if len(days)>3:
    name = 'df_distractor_overlaps_days'
else:
    name = 'df_distractor_overlaps'
pkl_save(df_mice, '%s' % name, path="../data/mice/overlaps")
#+end_src

#+RESULTS:
: saving to ../data/mice/overlaps/df_distractor_overlaps_days.pkl

* Plots
** Utils
#+begin_src ipython
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p <.1:
        return '.'
    else:
        return ''
#+end_src

#+RESULTS:

#+begin_src ipython
import rpy2.robjects as robjects
from rpy2.robjects.packages import importr

# Set the .libPaths in R
custom_r_libpath = '~/R/x86_64-pc-linux-gnu-library/4.3/'
robjects.r('.libPaths("{0}")'.format(custom_r_libpath))

from pymer4.models import Lmer
#+end_src

#+RESULTS:
: Warning message:
: package ‘methods’ was built under R version 4.3.3
: During startup - Warning messages:
: 1: package ‘datasets’ was built under R version 4.3.3
: 2: package ‘utils’ was built under R version 4.3.3
: 3: package ‘grDevices’ was built under R version 4.3.3
: 4: package ‘graphics’ was built under R version 4.3.3
: 5: package ‘stats’ was built under R version 4.3.3

#+begin_src ipython
def bootstrap_ci(data, n_bootstrap=1000, ci=95):
    bootstrapped_means = np.array([np.mean(np.random.choice(data, size=len(data))) for _ in range(n_bootstrap)])
    lower_bound = np.percentile(bootstrapped_means, (100-ci)/2)
    upper_bound = np.percentile(bootstrapped_means, 100 - (100-ci)/2)
    return lower_bound, upper_bound
#+end_src

#+RESULTS:

* Sample dfs
*** Data
#+begin_src ipython
name = 'df_sample_overlaps_days'
df_sample = pkl_load(name, path="../data/mice/overlaps")
#+end_src

#+RESULTS:
: loading from ../data/mice/overlaps/df_sample_overlaps_days.pkl

 #+begin_src ipython
df_sample['overlaps_diag'] = df_sample['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
#+end_src

#+RESULTS:

 #+begin_src ipython
options['epochs'] = ['ED']
df_sample['overlaps_ED'] = df_sample['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src
#+RESULTS:

 #+begin_src ipython
options['epochs'] = ['MD']
df_sample['overlaps_MD'] = df_sample['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['LD']
df_sample['overlaps_ED_LD'] = df_sample['overlaps_ED'].apply(lambda x: avg_epochs(np.array(x), **options))
df_sample['overlaps_diag_LD'] = df_sample['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_sample['overlaps_MD_LD'] = df_sample['overlaps_MD'].apply(lambda x: avg_epochs(np.array(x), **options))
# print(df_sample.head())
#+end_src

#+RESULTS:

#+begin_src ipython
import seaborn as sns
sns.lineplot(data=df_sample, x='day', y='performance', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])

# Set plot labels and title
plt.xlabel('Day')
plt.ylabel('Behavior')
plt.title('Behavior vs Day per Task')
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_27.png]]

#+begin_src ipython
import seaborn as sns
sns.lineplot(data=df_sample, x='day', y='overlaps_ED_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])

# Set plot labels and title
plt.xlabel('Day')
plt.ylabel('Sample Overlap')
plt.title('Behavior vs Day per Task')
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_28.png]]

#+begin_src ipython
def plot_overlaps(df, day, epoch, ax):
    df_ = df[df.day == day].copy()
    colors = ['r', 'b', 'g']
    time_points = np.linspace(0, 14, 84)

    mean_overlaps = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.mean(np.stack(x), axis=0))
    lower_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 0))
    upper_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, 1000, 1))

    for i, task in enumerate(mean_overlaps.index):
        ax.plot(time_points, mean_overlaps[task], label=f"Day {task}", color=colors[i])
        ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)

    ax.set_xlabel('Time (s)')
    ax.set_ylabel('Overlap')
    add_vlines(ax)

def bootstrap_ci_per_task(x, n_bootstrap, ci_idx):
    stacked = np.stack(x)
    return np.array([bootstrap_ci(stacked[:, i], n_bootstrap)[ci_idx] for i in range(stacked.shape[1])])
#+end_src

#+RESULTS:

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height), sharex=True, sharey=True)

df = df_sample[df_sample.mouse!='JawsM18']
# df = df_dist.copy()

# plot_overlaps(df, 'first', 'ED', ax[0])
# plot_overlaps(df, 'middle', 'ED', ax[1])
# plot_overlaps(df, 'last', 'ED', ax[2])

plot_overlaps(df, 'first', 'diag', ax[0])
plot_overlaps(df, 'middle', 'diag', ax[1])
plot_overlaps(df, 'last', 'diag', ax[2])

ax[2].legend(fontsize=10)

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_28.png]]

*** Performance
**** Performance ~ day * tasks

#+begin_src ipython
  df_sample['tasks'] = df_sample['tasks'].astype('category')
  # df_sample['day'] = df_sample['day'].astype('int')

  formula = 'performance ~ tasks * day + (1 + tasks + day | mouse)'
  data = df_sample.copy()
  # data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']

  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*day+(1+tasks+day|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1754.357 	 AIC: 3540.714

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.189  0.434
mouse    tasksDualGo  0.100  0.317
mouse  tasksDualNoGo  0.020  0.141
mouse            day  0.035  0.187

                 IV1            IV2   Corr
mouse    (Intercept)    tasksDualGo  0.098
mouse    (Intercept)  tasksDualNoGo -0.648
mouse    (Intercept)            day -0.047
mouse    tasksDualGo  tasksDualNoGo  0.530
mouse    tasksDualGo            day -0.571
mouse  tasksDualNoGo            day -0.697

Fixed effects:

                   Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
(Intercept)          -0.035  -0.538    0.468  0.257  0.966      0.584
tasksDualGo          -0.088  -0.608    0.432  0.265  0.916      0.544
tasksDualNoGo         0.085  -0.374    0.544  0.234  1.089      0.688
day                   0.564   0.363    0.764  0.102  1.757      1.438
tasksDualGo:day      -0.104  -0.249    0.040  0.074  0.901      0.780
tasksDualNoGo:day    -0.089  -0.236    0.059  0.075  0.915      0.789

                   OR_97.5_ci   Prob  Prob_2.5_ci  Prob_97.5_ci  Z-stat  \
(Intercept)             1.597  0.491        0.369         0.615  -0.135
tasksDualGo             1.540  0.478        0.352         0.606  -0.333
tasksDualNoGo           1.723  0.521        0.408         0.633   0.363
day                     2.147  0.637        0.590         0.682   5.507
tasksDualGo:day         1.041  0.474        0.438         0.510  -1.414
tasksDualNoGo:day       1.061  0.478        0.441         0.515  -1.177

                   P-val  Sig
(Intercept)        0.892
tasksDualGo        0.739
tasksDualNoGo      0.716
day                0.000  ***
tasksDualGo:day    0.157
tasksDualNoGo:day  0.239
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)


df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_32.png]]

**** Performance ~ overlaps

#+begin_src ipython
  df_sample['tasks'] = df_sample['tasks'].astype('category')
  # df_sample['day'] = df_sample['day'].astype('int')

  formula = 'performance ~ overlaps_ED_LD + (1 + tasks | mouse)'

  data = df_sample.copy()
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~overlaps_ED_LD+(1+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3072	 Groups: {'mouse': 4.0}

Log-likelihood: -1705.129 	 AIC: 3426.257

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.278  0.527
mouse    tasksDualGo  0.199  0.446
mouse  tasksDualNoGo  0.014  0.119

               IV1            IV2   Corr
mouse  (Intercept)    tasksDualGo -0.491
mouse  (Intercept)  tasksDualNoGo -0.911
mouse  tasksDualGo  tasksDualNoGo  0.806

Fixed effects:

                Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
(Intercept)        1.134   0.533    1.735  0.307  3.108      1.703
overlaps_ED_LD     0.055  -0.091    0.202  0.075  1.057      0.913

                OR_97.5_ci   Prob  Prob_2.5_ci  Prob_97.5_ci  Z-stat  P-val  \
(Intercept)          5.671  0.757        0.630          0.85   3.695  0.000
overlaps_ED_LD       1.223  0.514        0.477          0.55   0.742  0.458

                Sig
(Intercept)     ***
overlaps_ED_LD
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)


df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_34.png]]

**** Performance ~ overlaps * days

#+begin_src ipython
  df_sample['tasks'] = df_sample['tasks'].astype('category')
  formula = 'performance ~ day * overlaps_ED_LD  + (1 + day | mouse)'

  data = df_sample.copy()
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~day*overlaps_ED_LD+(1+day|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3072	 Groups: {'mouse': 4.0}

Log-likelihood: -1606.931 	 AIC: 3227.862

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.233  0.482
mouse          day  0.015  0.123

               IV1  IV2   Corr
mouse  (Intercept)  day -0.557

Fixed effects:

                    Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
(Intercept)           -0.025  -0.543    0.494  0.265  0.976      0.581
day                    0.403   0.265    0.541  0.070  1.496      1.304
overlaps_ED_LD        -0.046  -0.378    0.287  0.170  0.955      0.685
day:overlaps_ED_LD     0.042  -0.066    0.149  0.055  1.042      0.936

                    OR_97.5_ci   Prob  Prob_2.5_ci  Prob_97.5_ci  Z-stat  \
(Intercept)              1.639  0.494        0.367         0.621  -0.093
day                      1.718  0.599        0.566         0.632   5.726
overlaps_ED_LD           1.332  0.489        0.407         0.571  -0.269
day:overlaps_ED_LD       1.161  0.510        0.483         0.537   0.756

                    P-val  Sig
(Intercept)         0.926
day                 0.000  ***
overlaps_ED_LD      0.788
day:overlaps_ED_LD  0.450
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)


df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_36.png]]

**** Performance ~ overlaps * days * tasks

#+begin_src ipython
  df_sample['tasks'] = df_sample['tasks'].astype('category')
  formula = 'performance ~ day * tasks * overlaps_ED_LD  + (1 + day | mouse)'

  data = df_sample.copy()
  # data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
,**NOTE**: Column for 'residuals' not created in model.data, but saved in model.resid only. This is because you have rows with NaNs in your data.

,**NOTE** Column for 'fits' not created in model.data, but saved in model.fits only. This is because you have rows with NaNs in your data.

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~day*tasks*overlaps_ED_LD+(1+day|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1767.491 	 AIC: 3582.981

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.174  0.418
mouse      daylast  0.560  0.749
mouse    daymiddle  0.224  0.473

               IV1        IV2   Corr
mouse  (Intercept)    daylast  0.004
mouse  (Intercept)  daymiddle  0.808
mouse      daylast  daymiddle  0.593

Fixed effects:

                                        Estimate  2.5_ci  97.5_ci     SE  \
(Intercept)                                0.736   0.316    1.155  0.214
daylast                                    1.830   1.023    2.638  0.412
daymiddle                                  1.385   0.835    1.935  0.281
tasksDualGo                               -0.184  -0.460    0.092  0.141
tasksDualNoGo                              0.015  -0.264    0.295  0.143
overlaps_ED_LD                             0.311  -0.095    0.717  0.207
daylast:tasksDualGo                       -0.161  -0.747    0.426  0.299
daymiddle:tasksDualGo                     -0.347  -0.792    0.099  0.227
daylast:tasksDualNoGo                     -0.381  -0.970    0.207  0.300
daymiddle:tasksDualNoGo                   -0.084  -0.546    0.379  0.236
daylast:overlaps_ED_LD                    -0.152  -0.960    0.656  0.412
daymiddle:overlaps_ED_LD                  -0.190  -0.871    0.490  0.347
tasksDualGo:overlaps_ED_LD                -0.382  -0.913    0.148  0.271
tasksDualNoGo:overlaps_ED_LD              -0.174  -0.672    0.323  0.254
daylast:tasksDualGo:overlaps_ED_LD         0.158  -0.937    1.252  0.558
daymiddle:tasksDualGo:overlaps_ED_LD       0.293  -0.536    1.121  0.423
daylast:tasksDualNoGo:overlaps_ED_LD       0.048  -1.013    1.110  0.542
daymiddle:tasksDualNoGo:overlaps_ED_LD     0.196  -0.698    1.090  0.456

                                           OR  OR_2.5_ci  OR_97.5_ci   Prob  \
(Intercept)                             2.087      1.371       3.175  0.676
daylast                                 6.235      2.781      13.980  0.862
daymiddle                               3.994      2.304       6.926  0.800
tasksDualGo                             0.832      0.631       1.097  0.454
tasksDualNoGo                           1.016      0.768       1.343  0.504
overlaps_ED_LD                          1.365      0.909       2.048  0.577
daylast:tasksDualGo                     0.852      0.474       1.531  0.460
daymiddle:tasksDualGo                   0.707      0.453       1.104  0.414
daylast:tasksDualNoGo                   0.683      0.379       1.230  0.406
daymiddle:tasksDualNoGo                 0.920      0.579       1.461  0.479
daylast:overlaps_ED_LD                  0.859      0.383       1.926  0.462
daymiddle:overlaps_ED_LD                0.827      0.418       1.633  0.453
tasksDualGo:overlaps_ED_LD              0.682      0.402       1.160  0.406
tasksDualNoGo:overlaps_ED_LD            0.840      0.511       1.382  0.457
daylast:tasksDualGo:overlaps_ED_LD      1.171      0.392       3.498  0.539
daymiddle:tasksDualGo:overlaps_ED_LD    1.340      0.585       3.068  0.573
daylast:tasksDualNoGo:overlaps_ED_LD    1.049      0.363       3.034  0.512
daymiddle:tasksDualNoGo:overlaps_ED_LD  1.216      0.498       2.973  0.549

                                        Prob_2.5_ci  Prob_97.5_ci  Z-stat  \
(Intercept)                                   0.578         0.760   3.435
daylast                                       0.736         0.933   4.443
daymiddle                                     0.697         0.874   4.932
tasksDualGo                                   0.387         0.523  -1.305
tasksDualNoGo                                 0.434         0.573   0.109
overlaps_ED_LD                                0.476         0.672   1.502
daylast:tasksDualGo                           0.321         0.605  -0.537
daymiddle:tasksDualGo                         0.312         0.525  -1.525
daylast:tasksDualNoGo                         0.275         0.551  -1.271
daymiddle:tasksDualNoGo                       0.367         0.594  -0.355
daylast:overlaps_ED_LD                        0.277         0.658  -0.369
daymiddle:overlaps_ED_LD                      0.295         0.620  -0.548
tasksDualGo:overlaps_ED_LD                    0.286         0.537  -1.413
tasksDualNoGo:overlaps_ED_LD                  0.338         0.580  -0.686
daylast:tasksDualGo:overlaps_ED_LD            0.282         0.778   0.282
daymiddle:tasksDualGo:overlaps_ED_LD          0.369         0.754   0.693
daylast:tasksDualNoGo:overlaps_ED_LD          0.266         0.752   0.089
daymiddle:tasksDualNoGo:overlaps_ED_LD        0.332         0.748   0.430

                                        P-val  Sig
(Intercept)                             0.001  ***
daylast                                 0.000  ***
daymiddle                               0.000  ***
tasksDualGo                             0.192
tasksDualNoGo                           0.914
overlaps_ED_LD                          0.133
daylast:tasksDualGo                     0.591
daymiddle:tasksDualGo                   0.127
daylast:tasksDualNoGo                   0.204
daymiddle:tasksDualNoGo                 0.723
daylast:overlaps_ED_LD                  0.712
daymiddle:overlaps_ED_LD                0.583
tasksDualGo:overlaps_ED_LD              0.158
tasksDualNoGo:overlaps_ED_LD            0.493
daylast:tasksDualGo:overlaps_ED_LD      0.778
daymiddle:tasksDualGo:overlaps_ED_LD    0.488
daylast:tasksDualNoGo:overlaps_ED_LD    0.929
daymiddle:tasksDualNoGo:overlaps_ED_LD  0.667
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_36.png]]

**** Performance per day

#+begin_src ipython
results = []
formula = 'performance ~ tasks * overlaps_ED_LD  + (1 + tasks | mouse)'
for day in df_sample.day.unique():
  data = df_sample.copy()
  data = data[data.day==day]
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  glm.fit();
  results.append(glm)
#+end_src

#+RESULTS:
#+begin_example
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_ED_LD+(1+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 1152	 Groups: {'mouse': 4.0}

Log-likelihood: -759.007 	 AIC: 1542.015

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.186  0.432
mouse    tasksDualGo  0.004  0.066
mouse  tasksDualNoGo  0.007  0.083

               IV1            IV2  Corr
mouse  (Intercept)    tasksDualGo  -1.0
mouse  (Intercept)  tasksDualNoGo  -1.0
mouse  tasksDualGo  tasksDualNoGo   1.0

Fixed effects:
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_ED_LD+(1+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 1152	 Groups: {'mouse': 4.0}

Log-likelihood: -546.648 	 AIC: 1117.296

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.923  0.961
mouse    tasksDualGo  0.390  0.625
mouse  tasksDualNoGo  0.063  0.251

               IV1            IV2   Corr
mouse  (Intercept)    tasksDualGo -0.901
mouse  (Intercept)  tasksDualNoGo -0.986
mouse  tasksDualGo  tasksDualNoGo  0.814

Fixed effects:
Model failed to converge with max|grad| = 0.00690125 (tol = 0.002, component 1)

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_ED_LD+(1+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 768	 Groups: {'mouse': 4.0}

Log-likelihood: -288.533 	 AIC: 601.066

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.321  0.567
mouse    tasksDualGo  0.007  0.082
mouse  tasksDualNoGo  0.070  0.265

               IV1            IV2  Corr
mouse  (Intercept)    tasksDualGo   1.0
mouse  (Intercept)  tasksDualNoGo  -1.0
mouse  tasksDualGo  tasksDualNoGo  -1.0

Fixed effects:
#+end_example

#+begin_src ipython
import pandas as pd

# Assuming you have the list of results from all sessions
combined_results = []

for i, result in enumerate(results):
    coefficients = {
        'coef': result.coefs['Estimate'],
        'lower_ci': result.coefs['2.5_ci'],
        'upper_ci': result.coefs['97.5_ci'],
        'p_value': result.coefs['P-val'],
        'Sig': result.coefs['Sig'],
        'day': df_sample.day.unique()[i]  # Add a session identifier
    }
    df_result = pd.DataFrame(coefficients)
    combined_results.append(df_result)

df_combined = pd.concat(combined_results)
#+end_src

#+RESULTS:

#+begin_src ipython
print(df_combined)
#+end_src

#+RESULTS:
#+begin_example
                                  coef  lower_ci  upper_ci       p_value  Sig  \
(Intercept)                   0.590960  0.095447  1.086472  1.941326e-02    *
tasksDualGo                  -0.219893 -0.571313  0.131526  2.200456e-01
tasksDualNoGo                 0.065029 -0.292921  0.422979  7.217907e-01
overlaps_ED_LD                0.148187 -0.235214  0.531589  4.487264e-01
tasksDualGo:overlaps_ED_LD   -0.058438 -0.557718  0.440843  8.185568e-01
tasksDualNoGo:overlaps_ED_LD -0.252372 -0.808545  0.303800  3.738065e-01
(Intercept)                   2.111160  1.060521  3.161800  8.203970e-05  ***
tasksDualGo                  -0.888414 -1.711319 -0.065508  3.434580e-02    *
tasksDualNoGo                -0.304023 -0.933322  0.325276  3.436974e-01
overlaps_ED_LD               -0.184518 -0.848397  0.479361  5.859250e-01
tasksDualGo:overlaps_ED_LD    0.078341 -0.735617  0.892300  8.503743e-01
tasksDualNoGo:overlaps_ED_LD  0.176529 -0.712100  1.065159  6.970145e-01
(Intercept)                   1.860035  1.126384  2.593686  6.725706e-07  ***
tasksDualGo                   0.150633 -0.506137  0.807403  6.530530e-01
tasksDualNoGo                -0.096611 -0.753401  0.560178  7.731141e-01
overlaps_ED_LD                1.940209  0.903424  2.976994  2.446276e-04  ***
tasksDualGo:overlaps_ED_LD   -2.381316 -3.638778 -1.123854  2.058891e-04  ***
tasksDualNoGo:overlaps_ED_LD -1.850660 -3.042371 -0.658950  2.336759e-03   **

                                 day
(Intercept)                    first
tasksDualGo                    first
tasksDualNoGo                  first
overlaps_ED_LD                 first
tasksDualGo:overlaps_ED_LD     first
tasksDualNoGo:overlaps_ED_LD   first
(Intercept)                   middle
tasksDualGo                   middle
tasksDualNoGo                 middle
overlaps_ED_LD                middle
tasksDualGo:overlaps_ED_LD    middle
tasksDualNoGo:overlaps_ED_LD  middle
(Intercept)                     last
tasksDualGo                     last
tasksDualNoGo                   last
overlaps_ED_LD                  last
tasksDualGo:overlaps_ED_LD      last
tasksDualNoGo:overlaps_ED_LD    last
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import seaborn as sns

# Thresholds for significance markers
p_value_annotations = [(0.001, '***'), (0.01, '**'), (0.05, '*'), (0.1, '.')]

# Set up the subplots
unique_coefs = df_combined.index.unique()
fig, axes = plt.subplots(nrows=len(unique_coefs) // 3, ncols=3, figsize=(3*width, len(unique_coefs) // 3
                                                                    ,* height), sharex=True)

for coef, ax in zip(unique_coefs, axes.flatten()):
    sub_df = df_combined.loc[coef].reset_index()  # Select data for the current coefficient

    sns.lineplot(x='day', y='coef', data=sub_df, ax=ax, marker='o')

    # Plotting the confidence intervals
    ax.fill_between(x=sub_df['day'], y1=sub_df['lower_ci'], y2=sub_df['upper_ci'], alpha=0.3)

    for idx in range(len(sub_df)):
        for threshold, marker in p_value_annotations:
            if sub_df.loc[idx, 'p_value'] <= threshold:
                ax.text(sub_df.loc[idx, 'day'], sub_df.loc[idx, 'coef'] + 1 , marker, ha='center', fontsize=20, color='red')
                break

    ax.set_title(f'Evolution of {coef} over Time', fontsize=10)
    # ax.legend()
    ax.set_xlabel('Day')
    ax.set_ylabel('Coefficient Value')

fig.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_41.png]]

*** Overlaps
**** Overlaps ~ day * tasks
#+begin_src ipython
df_sample_day = df_sample.day.astype('category')
#+end_src

#+RESULTS:
: [1 2 3 4 5 6]

#+begin_src ipython
  formula = 'overlaps_ED_LD ~ day + (1 + day | mouse)'

  data = df_sample.copy()
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse!='ACCM04']
  glm = Lmer(formula=formula, data=data, family='gaussian')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by REML [’lmerMod’]
Formula: overlaps_ED_LD~day+(1+day|mouse)

Family: gaussian	 Inference: parametric

Number of observations: 3072	 Groups: {'mouse': 4.0}

Log-likelihood: -2758.520 	 AIC: 5529.040

Random effects:

                 Name    Var    Std
mouse     (Intercept)  0.027  0.166
mouse             day  0.000  0.018
Residual               0.349  0.591

               IV1  IV2   Corr
mouse  (Intercept)  day  0.107

Fixed effects:

             Estimate  2.5_ci  97.5_ci     SE     DF  T-stat  P-val Sig
(Intercept)     0.218   0.048    0.387  0.087  3.097   2.513  0.084   .
day             0.009  -0.013    0.031  0.011  2.869   0.766  0.502
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+.1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_44.png]]

**** Overlaps ~ day * tasks

#+begin_src ipython
formula = 'overlaps_ED_LD ~ day * tasks + (1 | mouse)'

data = df_sample.copy()
data = data[data.mouse!='JawsM18']
# data = data[data.mouse!='ACCM04']
glm = Lmer(formula=formula, data=data, family='gaussian')
result = glm.fit()
print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by REML [’lmerMod’]
Formula: overlaps_ED_LD~day*tasks+(1|mouse)

Family: gaussian	 Inference: parametric

Number of observations: 3072	 Groups: {'mouse': 4.0}

Log-likelihood: -2745.017 	 AIC: 5506.034

Random effects:

                 Name    Var    Std
mouse     (Intercept)  0.033  0.180
Residual               0.344  0.587

No random effect correlations specified

Fixed effects:

                   Estimate  2.5_ci  97.5_ci     SE        DF  T-stat  P-val  \
(Intercept)           0.298   0.103    0.493  0.100     4.373   2.989  0.036
day                   0.017  -0.007    0.040  0.012  3063.721   1.409  0.159
tasksDualGo          -0.066  -0.182    0.050  0.059  3063.021  -1.110  0.267
tasksDualNoGo        -0.169  -0.285   -0.053  0.059  3063.021  -2.850  0.004
day:tasksDualGo      -0.022  -0.055    0.011  0.017  3063.021  -1.313  0.189
day:tasksDualNoGo    -0.003  -0.036    0.030  0.017  3063.021  -0.183  0.855

                  Sig
(Intercept)         *
day
tasksDualGo
tasksDualNoGo      **
day:tasksDualGo
day:tasksDualNoGo
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)


df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+.2, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_47.png]]

* distractor dfs
*** data

#+begin_src ipython
name = 'df_distractor_overlaps_days'
df_dist = pkl_load(name, path="../data/mice/overlaps")
#+end_src

#+RESULTS:
: loading from ../data/mice/overlaps/df_distractor_overlaps_days.pkl

#+begin_src ipython
df_dist['overlaps_diag'] = df_dist['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['MD']
df_dist['overlaps_MD'] = df_dist['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['ED']
df_dist['overlaps_MD_ED'] = df_dist['overlaps_MD'].apply(lambda x: avg_epochs(np.array(x), **options))
df_dist['sign_overlaps_MD_ED'] = df_dist['overlaps_MD'].apply(lambda x: np.sign(avg_epochs(np.array(x), **options)))
#+end_src

#+RESULTS:
#+begin_src ipython
df.keys()
#+end_src

#+RESULTS:
: Index(['sample_odor', 'test_odor', 'response', 'tasks', 'laser', 'day',
:        'dist_odor', 'choice', 'overlaps', 'mouse', 'performance', 'pair',
:        'overlaps_diag', 'overlaps_MD', 'overlaps_MD_ED',
:        'sign_overlaps_MD_ED'],
:       dtype='object')

#+begin_src ipython
import seaborn as sns
df = df_dist[df_dist.mouse!='JawsM18']
#df.overlaps_MD_ED = df.overlaps_MD_ED
# df.day = np.exp(df.day)
sns.lineplot(data=df, x='day', y='overlaps_MD_ED', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'])

# Set plot labels and title
plt.xlabel('Day')
plt.ylabel('Sample Overlap')
plt.title('Behavior vs Day per Task')
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_51.png]]

#+begin_src ipython
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height), sharex=True, sharey=True)

df = df_dist[df_dist.mouse!='JawsM18']
# df = df_dist.copy()

plot_overlaps(df, 'first', 'MD', ax[0])
plot_overlaps(df, 'middle', 'MD', ax[1])
plot_overlaps(df, 'last', 'MD', ax[2])

# plot_overlaps(df, 'first', 'diag', ax[0])
# plot_overlaps(df, 'middle', 'diag', ax[1])
# plot_overlaps(df, 'last', 'diag', ax[2])

# ax[2].legend(fontsize=10)

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_52.png]]

*** Performance
**** Performance ~ day * tasks

#+begin_src ipython
  df_dist['tasks'] = df_dist['tasks'].astype('category')
  # df_dist['day'] = df_dist['day'].astype('int')

  formula = 'performance ~ tasks * day + (1 + tasks + day | mouse)'
  data = df_dist.copy()
  # data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']

  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
unable to evaluate scaled gradient

Model failed to converge: degenerate  Hessian with 1 negative eigenvalues

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*day+(1+tasks+day|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1765.252 	 AIC: 3578.504

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.229  0.479
mouse    tasksDualGo  0.104  0.322
mouse  tasksDualNoGo  0.016  0.125
mouse        daylast  0.554  0.744
mouse      daymiddle  0.191  0.437

                 IV1            IV2   Corr
mouse    (Intercept)    tasksDualGo -0.231
mouse    (Intercept)  tasksDualNoGo -0.909
mouse    (Intercept)        daylast  0.146
mouse    (Intercept)      daymiddle  0.869
mouse    tasksDualGo  tasksDualNoGo  0.616
mouse    tasksDualGo        daylast -0.386
mouse    tasksDualGo      daymiddle -0.525
mouse  tasksDualNoGo        daylast -0.283
mouse  tasksDualNoGo      daymiddle -0.928
mouse        daylast      daymiddle  0.585

Fixed effects:

                         Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
(Intercept)                 0.768   0.297    1.239  0.240  2.155      1.345
tasksDualGo                -0.209  -0.617    0.200  0.208  0.812      0.540
tasksDualNoGo              -0.044  -0.359    0.270  0.161  0.957      0.698
daylast                     1.852   1.042    2.662  0.413  6.373      2.835
daymiddle                   1.409   0.876    1.942  0.272  4.092      2.401
tasksDualGo:daylast        -0.202  -0.805    0.402  0.308  0.817      0.447
tasksDualNoGo:daylast      -0.357  -0.949    0.235  0.302  0.700      0.387
tasksDualGo:daymiddle      -0.401  -0.856    0.055  0.232  0.670      0.425
tasksDualNoGo:daymiddle    -0.126  -0.598    0.346  0.241  0.882      0.550

                         OR_97.5_ci   Prob  Prob_2.5_ci  Prob_97.5_ci  Z-stat  \
(Intercept)                   3.453  0.683        0.574         0.775   3.194
tasksDualGo                   1.221  0.448        0.350         0.550  -1.001
tasksDualNoGo                 1.310  0.489        0.411         0.567  -0.276
daylast                      14.326  0.864        0.739         0.935   4.482
daymiddle                     6.975  0.804        0.706         0.875   5.179
tasksDualGo:daylast           1.495  0.450        0.309         0.599  -0.655
tasksDualNoGo:daylast         1.265  0.412        0.279         0.559  -1.182
tasksDualGo:daymiddle         1.056  0.401        0.298         0.514  -1.724
tasksDualNoGo:daymiddle       1.414  0.469        0.355         0.586  -0.523

                         P-val  Sig
(Intercept)              0.001   **
tasksDualGo              0.317
tasksDualNoGo            0.782
daylast                  0.000  ***
daymiddle                0.000  ***
tasksDualGo:daylast      0.513
tasksDualNoGo:daylast    0.237
tasksDualGo:daymiddle    0.085    .
tasksDualNoGo:daymiddle  0.601
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)


df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/landscape/figure_43.png]]

**** Performance ~ overlaps

#+begin_src ipython
df_dist['sign_overlaps_MD_ED'] = df_dist['overlaps_MD_ED'].apply(lambda x: (2*np.sign(x) - 1) * x)

# Step 4: Define formula using the sign of overlaps_MD_ED
#  formula = 'performance ~ sign_overlaps_MD_ED + (1 | mouse)'
formula = 'performance ~ overlaps_MD_ED * day + (1 | mouse)'

# data = df_dist.copy()
data = df_dist[['overlaps_MD_ED', 'sign_overlaps_MD_ED', 'performance', 'mouse', 'day']]
# data.sign_overlaps_MD_ED = data.sign_overlaps_MD_ED.astype('category')

data = data[data.mouse!='JawsM18']
# data = data[data.mouse =='ACCM04']
glm = Lmer(formula=formula, data=data, family='binomial')
result = glm.fit()
print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~overlaps_MD_ED*day+(1|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3072	 Groups: {'mouse': 4.0}

Log-likelihood: -1612.136 	 AIC: 3234.271

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.165  0.407

No random effect correlations specified

Fixed effects:

                    Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
(Intercept)           -0.009  -0.452    0.434  0.226  0.991      0.636
overlaps_MD_ED        -0.120  -0.582    0.341  0.236  0.887      0.559
day                    0.400   0.339    0.460  0.031  1.491      1.404
overlaps_MD_ED:day    -0.018  -0.146    0.110  0.065  0.982      0.865

                    OR_97.5_ci   Prob  Prob_2.5_ci  Prob_97.5_ci  Z-stat  \
(Intercept)              1.543  0.498        0.389         0.607  -0.041
overlaps_MD_ED           1.407  0.470        0.358         0.585  -0.511
day                      1.584  0.599        0.584         0.613  12.938
overlaps_MD_ED:day       1.116  0.496        0.464         0.527  -0.276

                    P-val  Sig
(Intercept)         0.967
overlaps_MD_ED      0.609
day                 0.000  ***
overlaps_MD_ED:day  0.783
#+end_example

#+begin_src ipython
from rpy2.robjects import r
from rpy2.robjects.packages import importr
from rpy2.robjects import pandas2ri
pandas2ri.activate()

lme4 = importr('lme4')

# Convert dataframe to R dataframe
r_dataframe = pandas2ri.py2rpy(data)

# Fit the model
formula = 'performance ~ sign_overlaps_MD_ED * day + (1 | mouse)'
model = lme4.glmer(formula, data=r_dataframe, family='binomial')

base = importr('base')
summary = base.summary(model)
print(summary)
#+end_src

#+RESULTS:
#+begin_example
Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: performance ~ sign_overlaps_MD_ED * day + (1 | mouse)
   Data:
structure(list(sign_overlaps_MD_ED = c(1.77434982690546, 0.493754493732316,
0.812844572899242, 1.8998912382457, 0.22497312862564, 1.30623260140419,
1.19008546529545, 1.96565655867259, 0.852803650053425, 2.25422665807936,
1.06033631439722, 0.942888307074706, 1.05788146828612, 1.48418015903897,
0.931750876208146, 0.710619051138767, 0.22735186822333, 0.157523844623938,
0.935729993714227, 0.249826251339443, 0.225035374358952, 0.519049936836516,
0.911033378707038, 0.350935431973388, 0.941374061284242, 0.194380784665959,
0.29804226062778, 0.0906395121408557, 1.23021677550342, 0.275723749461273,
0.985688990809851, 0.0593081935679678, 3.11103901267052, 0.290501818287238,
0.787828738490741, 1.28282216605213, 3.13944283127785, 0.446426801642196,
1.48309978511598, 1.10147234362861, 0.00919845930076446, 0.101749972589055,
0.338576966405122, 0.0597377746469445, 0.150420914843885, 0.398826288369795,
0.865458525355078, 0.722338494637774, 2.26228502558337, 0.747775705117318,
0.692916028822462, 0.238638825947419, 0.0429702890278013, 0.270515384462972,
0.0408167877532024, 0.441945145320561, 0.490125137122555, 0.102431637545427,
0.143519697736742, 0.00677481969533902, 0.575554926362303, 0.173404632333485,
0.927034128043387, 0.247595907085472, 0.112899736346056, 0.923648888762626,
0.790420886129141, 0.769462712885191, 2.68115055892203, 1.32891655464967,
2.82344598571459, 0.118610729993735, 0.525721929691456, 0.844494438005818,
0.476731621996603, 0.356892360299955, 0.0869534882432264, 0.44998695432312,
0.462917603836912, 0.47225651372638, 2.82872822218471, 1.36287518673473,
0.184335775356481, 0.311590980453831, 0.0865752844191674, 0.166725526805277,
0.095231901983627, 0.238852963110225, 1.69808322853512, 0.755759811106448,
0.665853496007104, 0.175183988668222, 0.800862063136366, 0.407478694687598,
0.454102722281176, 0.0334401203360391, 1.12501375501355, 0.142983622159119,
0.0890052287097744, 0.0767025117012155, 0.256417969710633, 0.812650320016675,
0.0205801169482853, 0.323587530775479, 0.813074456872763, 0.542536127070586,
1.17808000136305, 0.152587535062425, 0.314185021897881, 0.962364738738095,
0.128950854832376, 0.654832841776725, 0.176343888321383, 1.16721247522919,
1.03517915474044, 1.22341060196912, 0.631352197792795, 0.323671921518528,
0.600126185902843, 0.63770518038008, 0.451597214848907, 0.533347712898696,
0.589189517553206, 0.206254997549372, 0.558021263391883, 0.49826358920998,
0.152536432000084, 0.409017269810041, 0.0296953305498593, 1.28226575586531,
0.142605815220762, 0.460129301581118, 0.205438489120247, 1.37517244506765,
0.0770367897908997, 0.856250637107425, 0.340739479362835, 0.258630798594957,
0.008159350776286, 1.15425337078395, 0.044752593085394, 0.09746086852694,
0.37621597298615, 0.274813667349345, 0.0215371596040549, 0.427669856421373,
0.940993593246848, 0.667444894711177, 1.00644323119411, 0.976180999367325,
1.30350452109619, 0.864552940483446, 0.35218162594915, 0.535785738999645,
0.822542474915584, 0.609609730265759, 0.249849281480743, 0.488256888671054,
0.0508298003977096, 0.44508634474025, 1.66672491282225, 0.4763389709923,
0.672722668568086, 0.490159642917139, 1.3571960164441, 0.624957939402925,
1.17180389952328, 1.15591796156433, 0.284274057381683, 0.208903319392077,
0.158142521416906, 1.15776583676537, 0.919009213646253, 0.605344516829872,
0.451685741252732, 0.513532398579021, 0.552262907690386, 0.681211408822694,
0.16300123297023, 0.51272556038263, 0.811102317922093, 0.150885936260844,
0.254293435546397, 0.209590969848688, 0.00714705864488172, 0.160330076059499,
0.128411582873755, 0.304988498351088, 0.00381066949382701, 0.0621468755589039,
0.448828509560338, 0.212257634537915, 0.369003854554009, 0.295353583267166,
2.06458792359465, 2.39765053159661, 0.3256307768062, 1.88618136280113,
1.36857144658764, 0.286357880983916, 2.8837785306904, 2.04525209797753,
0.256031456938082, 3.81444645590252, 1.25939977489826, 0.187063951148755,
2.88522676295704, 2.21029766400655, 0.505592839287905, 0.0307091890168118,
1.58644759654999, 0.0319233475408206, 0.257922243902511, 0.48011771744738,
1.84939614435037, 1.0287521208326, 1.32433711902963, 3.41099894709057,
0.228490645117644, 1.32311667998632, 1.94580781790945, 1.68347067634265,
1.57542393149601, 1.96122388707267, 2.30723498585737, 0.392969206613661,
2.58487512336837, 0.305789549438352, 1.60983836899201, 3.22680016027557,
0.803997988088264, 0.105113000216618, 0.0449539888650179, 0.306318000131459,
0.708357745076581, 0.0966128889488539, 2.08198091553317, 0.00150135676462754,
0.509238029519717, 0.693440768867731, 1.83676460695763, 1.0441255272987,
2.65034102400144, 0.304565061556382, 0.0183886652726128, 2.10645382437441,
0.897270621938838, 0.565875608333954, 0.33745968998496, 0.128150619993297,
0.29173234284476, 0.46975224930793, 1.60542058530781, 3.41937884026104,
0.0785071112978686, 1.32676965329382, 0.0310713412300511, 0.00545582088590082,
0.102269792394644, 0.289579946599487, 0.0446102383289986, 0.106438468779541,
2.8525359282891, 1.78905153274536, 0.219430005039882, 1.60434541685714,
0.085300515026406, 1.00437055983477, 0.890542499384739, 2.48549660046895,
1.64030239648289, 0.489990703209683, 0.132532436228185, 0.78982043118837,
0.47807379367037, 1.54180762834019, 0.896547105965308, 2.11544253428777,
0.0913411347859505, 0.573811103589833, 0.27205798142111, 0.849451777835687,
1.22608341478432, 0.00182889613508316, 0.0997671068094119, 0.192295874030269,
0.571655229665339, 0.0821186364973309, 2.27803804477056, 0.0102830997202545,
1.0721427883125, 0.447981709510916, 0.0349644291369865, 1.99553025099966,
0.223629426961351, 0.649239129904244, 0.0942481319264819, 0.241179197767956,
0.57322146029522, 0.104708536148623, 0.193392018373642, 1.11017171334889,
0.566604448068473, 0.0582366879399935, 3.67272745569547, 0.25031297295613,
0.148850287552233, 0.570733324831558, 0.389727103148794, 0.713510695741408,
0.0523200425345244, 0.190743031532124, 1.18722636004289, 0.218795702309796,
0.376595686810712, 0.709786002006796, 0.547620203759935, 0.0293699789455988,
0.036074083026809, 1.32344534636165, 2.1322438629965, 0.210560830258247,
0.0936211927457609, 1.32407072269254, 1.55215559237533, 0.582150808897697,
0.144743191207656, 1.06568306850062, 0.925629466772079, 0.826807725864152,
0.992325488270985, 0.804850762089094, 0.127916802568102, 0.101613396071587,
1.30108120447646, 2.23866981764635, 0.975858019457923, 0.234451292248667,
0.105292833617164, 0.119307645467213, 0.966553519887384, 0.589385017028285,
0.420412760800294, 0.0176393216415481, 0.463603112070511, 0.0473374369709442,
0.768578035756946, 3.37730705406931, 0.723813047425614, 0.600180978472862,
0.0826457369063671, 0.807229861047947, 0.168765475999357, 0.975637633974354,
0.174742172407504, 0.150421356316656, 1.24147505520119, 0.113647962127019,
0.750681635509763, 0.0886994429370302, 0.888329314326661, 1.42835097346041,
0.196966437735008, 0.12201554617948, 2.20419412023491, 0.852674318994913,
1.58823637333181, 0.752588767144415, 0.88093569709195, 0.612439034559227,
0.199052522308193, 0.449524811855453, 2.11139948583312, 0.46008585283481,
0.113213041570917, 0.0688608517278529, 0.0100376583803963, 0.849926294551955,
0.130045104125101, 2.3364948083957, 0.620769725077682, 1.48454723672734,
0.121624950428668, 1.90750321083599, 0.870348278717655, 0.410166228992037,
0.827857329432542, 0.87112260195944, 0.802767602157676, 0.0767805345951476,
0.827772527312239, 0.0897105938897261, 0.0764852797222341, 0.866247362819397,
0.130103064959662, 0.585135995203422, 0.0693256252065853, 0.604551203134987,
0.597158698985974, 0.299624285401983, 0.164750383186199, 0.463913622363988,
0.0813729388604837, 0.317289279948454, 0.147205976277797, 0.52343458259323,
0.122211844246421, 0.903426203779721, 0.0967180724945609, 0.798276582732797,
0.297522053588182, 1.71607472830349, 0.736747615867191, 0.204955543494887,
0.500018935831678, 0.468200832915803, 1.97643595892522, 0.000185754965059459,
0.275142408208922, 0.692307675153845, 0.182766902605417, 0.239179121291575,
0.534463589403054, 0.500005023967889, 0.599502469516463, 0.614422553943263,
0.419665152413978, 0.331998467341893, 0.0746077566614581, 0.219279575780362,
0.692343594299422, 0.6212213230384, 0.300600511099522, 0.639813892802017,
0.970050058379355, 0.2185670115847, 0.10190426067156, 0.0962308063430505,
0.106835124703745, 0.285565057999015, 0.546808314250989, 0.318962164132649,
1.48936036311918, 0.0750892579539039, 2.053088758102, 0.482993624138611,
0.406562742852354, 0.622031058184803, 0.208954058518564, 0.859981773076234,
1.87267174985674, 1.37155476874775, 0.261700122858639, 0.07948846935674,
0.769629049632284, 1.55333776827212, 0.126757415570629, 3.4236789693435,
1.35542389529723, 0.824983358383179, 0.338179800374847, 1.32962117813252,
0.470696212758345, 1.61547732794726, 0.0922361458996656, 0.574803435692081,
0.320626832027402, 2.45186728680575, 0.256500572871624, 1.60107762062991,
0.673129755589697, 0.537112820341631, 0.0448083060649272, 0.153135465147595,
0.555783575340347, 1.20172962215212, 0.267646465917264, 0.424942152298711,
0.403777080018901, 0.332061994626808, 0.61036373845612, 0.251290127807469,
0.348899914520896, 0.0219878580214249, 0.445416883737953, 1.45419464619071,
1.68506774875439, 0.255021394592606, 0.0963072504986215, 0.00363259283929233,
0.470794441074961, 0.370151519076899, 0.43842486243833, 0.186880452729787,
0.936312624701747, 1.07018792022158, 1.03317802040665, 1.94576076666514,
0.0570878974093055, 0.0278311353866701, 0.727408913041776, 0.421970651364299,
0.483010895420901, 0.461751855909824, 0.155759738827193, 0.3765422709726,
0.640588660758955, 0.30149405157297, 0.175290754626918, 0.751046517932857,
1.01395418136208, 0.366109342900691, 0.0285695130005479, 0.104944690199638,
0.129973289832749, 0.0785960080964422, 1.38774141007, 1.73996649020248,
1.26747374650505, 0.452102012656353, 0.739181123880876, 0.54408402133871,
0.0549296304719367, 2.61395587109857, 0.0476782052158982, 0.484177942129059,
0.043435384535567, 0.520975390518153, 0.803821357717324, 0.109618370809282,
0.121835815858234, 0.770873941067192, 0.267883358109329, 1.0232631510848,
0.34899758020334, 0.525084446546518, 0.0942092596303189, 0.194336538668722,
0.0192175281958448, 0.159787104969534, 0.211496847181546, 0.241251529405687,
0.260649211622809, 0.879263958997197, 0.270492684425941, 0.555436062040152,
0.0201788817756568, 0.676259524085456, 0.273551770382457, 0.0410269864110483,
0.93644604857804, 0.115233761206683, 0.20647402021482, 0.966459320030279,
0.592483129490305, 0.167498294057118, 0.48079081133215, 0.580132956209127,
0.194717253144417, 0.398627626936003, 0.119562658326079, 1.61977627542284,
0.0279840827381661, 0.772441606830668, 0.144400931843039, 0.179006482129572,
0.092312755373617, 0.431462089910551, 0.266429407250447, 0.177976567522381,
0.281162973152715, 0.511769693430122, 0.146941056625952, 0.545157673113324,
0.160517151310597, 0.275785293550817, 0.360090877912525, 1.55090786516666,
0.289311688272627, 0.511676772739048, 0.666429634619918, 0.149981631699053,
0.5540952373434, 0.516826325544605, 0.172669842811215, 0.157593042279283,
0.713198265267743, 0.244979277718812, 0.361069589128925, 0.829356933633486,
0.669218444249256, 0.674332079512102, 0.141087232091835, 0.538456701570087,
0.336084273471325, 0.250823103719287, 0.865326840568472, 1.05800251055647,
0.323884393890492, 0.36683343499209, 0.34471041907953, 0.335352271519325,
0.492369923326704, 0.290983138123044, 1.2425643812727, 0.475648447871208,
1.10155623268198, 0.815368290300723, 0.150789381867206, 1.32456847901146,
1.5263163993756, 1.72695158587562, 2.3261513710022, 0.127250509905732,
0.561197199548284, 1.96927325096395, 0.169427420413639, 0.660595299676061,
0.0606820201565925, 0.303888237013275, 0.202105724114787, 0.429551980755706,
0.567648501307876, 0.119485505703509, 0.587236158687759, 0.428245972704004,
1.09341886308458, 0.571309600715284, 1.1393821504381, 1.17195258869065,
0.761054928104083, 0.862084010133037, 0.876645433681983, 0.556233474501857,
0.246899018340089, 0.742199843680417, 2.48448331488503, 0.035804542971568,
2.95304642452134, 0.791709527925209, 0.293153006928387, 0.309888764758836,
0.219007699543403, 1.23163060457618, 0.431185578237529, 0.889703149044955,
0.805469360064577, 0.334009257731614, 0.119209630902063, 0.449384584746979,
0.307776270572234, 0.586600371257023, 0.203949935389338, 0.317322099572737,
1.5391898949941, 0.808201644155714, 1.22056324759291, 0.268987373310935,
0.560981959656433, 0.436938644335088, 0.501484285626147, 0.554186231008282,
0.463696602180048, 0.443809312328489, 0.631540866085777, 0.555605991433064,
0.471655493799416, 2.01763397165471, 1.93312074740728, 0.220534178027366,
0.786755034217128, 0.162273760315859, 0.14797438391812, 2.63060624400775,
1.07274113015996, 2.03142705890867, 4.92361040910085, 3.3628099411726,
0.912533487451987, 0.572170194403346, 1.71099560128318, 2.559590280056,
0.0948348232131037, 1.02571611892846, 3.58598106106122, 3.03282849987348,
1.03707555205458, 1.2701677478229, 0.430726130389505, 1.03224504435504,
4.85813938909107, 5.32364875740475, 0.305415983572689, 0.261345511664533,
1.34211221295926, 4.2180372344123, 0.35461620034443, 0.159011097642145,
0.164114469750698, 1.60922818434321, 0.714224519311554, 0.763437590613547,
1.17891162437283, 2.41472432017326, 0.501934823511099, 0.290284404237927,
0.330105731315497, 0.960612579145365, 3.987637973494, 0.494373675987676,
1.15362373773112, 3.29046938485569, 0.0617851789488837, 0.522051358112583,
0.0258719883341756, 0.705900588521251, 1.11257994726852, 2.26437456078,
0.426018314505065, 1.03548518009484, 0.857004368574255, 1.51151728630066,
0.818269206650762, 6.33212071657181, 0.454105055761627, 0.262944655458408,
0.301299494725687, 1.86845206055376, 0.408425768371672, 0.557397030845836,
2.25193116565545, 0.292529637407925, 1.00391450834771, 0.121292745138312,
0.253766301610826, 0.20108282287105, 0.150476197919084, 0.652013518019683,
4.1766853498088, 4.80509142080943, 3.24463654557864, 3.5726425713963,
5.43751391437319, 2.76325466897752, 5.05170154571533, 3.70844636360804,
3.80965554383066, 3.25269799100028, 5.05628027021885, 3.22045361333423,
4.14093606339561, 2.79316042529212, 0.423890091918616, 1.48027719867726,
4.23219839069578, 1.75573839247227, 2.68409741255972, 2.47060379717085,
0.193953879746712, 3.50252772370974, 2.62495039072302, 3.60415418942769,
2.03033367130491, 0.0286274170759026, 0.0585439414717257, 2.23185521033075,
0.558478331676236, 4.00880443387561, 0.39752350150849, 0.360021283229192,
0.516845796119284, 0.54708006757277, 0.398062519729137, 1.01772425792835,
1.14045571949747, 0.064502647114245, 1.03502914309502, 1.81208622014081,
0.295037708374568, 0.813091542985704, 0.389433574159975, 0.304548103224348,
0.0879617486692344, 1.01930398963116, 0.837365809966017, 1.56519077221553,
0.52614828666103, 0.821199386208146, 0.373121022626206, 0.289713785414481,
0.158372746642541, 0.0476710095212588, 0.780433940666693, 0.0762481821358152,
1.49762425157759, 1.52250689930386, 0.244850453739572, 1.11708605841354,
1.25903224282795, 0.241786528344232, 0.26942877610283, 0.799180232816272,
0.110166985886516, 0.301757534276004, 0.633905244370302, 0.189844951671721,
0.287185561187841, 0.392286628208778, 0.602068352754469, 0.43955921738719,
0.40055834364008, 1.54618868121394, 0.284247310625182, 0.251141113453303,
0.182872789377278, 0.597779933915094, 0.579667327410587, 0.282385021931043,
1.00963638386586, 0.304730521239064, 0.517167515914749, 0.638546722078765,
0.572522874783587, 0.441186848475977, 0.0661468583124655, 0.893457859754562,
1.2259326957994, 0.0446525087528345, 0.320792537148076, 0.168365760990936,
0.58445892593375, 0.483292488105319, 0.182724908339205, 0.442554173189112,
0.220504102555828, 0.00923716421325312, 0.260740871903383, 0.942078950504462,
0.868062920454476, 0.242360841189684, 0.0415164169820922, 1.82497934169239,
0.089515233050204, 1.24058747539918, 0.842247166015484, 1.03570133337268,
1.48223739641684, 0.499248341277794, 0.397650165690316, 0.0571893972465423,
0.615278911259439, 1.28409891437601, 0.0080048012961116, 1.58268531384291,
0.235862626176741, 0.764965602326103, 0.428601446940943, 0.110019745356921,
0.252929523483747, 1.27516733385898, 0.456567001425558, 1.45770153775811,
1.08483522985544, 0.0556358665365864, 2.15724565254317, 0.141821679831655,
0.048600813270443, 0.175450005982485, 0.116028014863669, 0.976397024260627,
0.176289979825486, 0.298682918634128, 0.232929831405205, 0.402559194851805,
0.312556748105972, 0.857142251950723, 0.607352904423519, 0.272813105886733,
0.014333983489821, 0.0186091231535775, 1.00573726986638, 0.346489470590044,
0.234302224949244, 0.143997436134938, 0.0296976964455098, 1.83427001039187,
1.42986285107003, 1.31353416928539, 0.281103444734105, 0.453172159553678,
0.120781460190537, 3.70368915134006, 2.24603655934334, 0.0454728057504528,
0.0527927075626967, 0.418605517458033, 0.240483260351337, 0.53705940160176,
0.922662261459563, 0.376555949725487, 0.191429091307024, 0.513795363216626,
0.132146576033577, 0.586009857865671, 0.630399088340777, 1.08624287115203,
1.15431232584847, 0.524163186826088, 0.534709802932209, 0.915242038391255,
1.69348254910222, 1.78677813212077, 1.07738199940434, 1.05579139899324,
1.78539734637296, 0.661308629839267, 0.0975746661942038, 0.863605066030114,
1.39385538741394, 0.983419698697549, 0.57857688145574, 0.739062939529066,
0.64397416125845, 1.17687937286165, 0.517562000346111, 0.144249415689114,
0.900127295542646, 0.920798714514132, 0.211903222840327, 0.369056351206921,
0.665363745005042, 0.762048677291238, 0.231579792039055, 0.742083891122429,
0.360291210158418, 0.868897112983244, 1.14775499591121, 0.103774044438507,
0.50685450806567, 0.447004059950511, 1.57969816525777, 0.540086364580525,
0.488100575214183, 0.252532382737155, 0.186861996349223, 0.139383554458618,
1.01102559161545, 0.715881099303564, 0.833742928035833, 1.35740112264951,
0.521712652235119, 1.00743129959813, 0.318479462561232, 0.766451558788066,
0.27968979868348, 0.910560420817799, 0.904468639029397, 1.28464329573843,
1.49153600577955, 1.00713665297048, 1.66497829887602, 1.58324711273114,
0.899213722182645, 0.728389981823663, 0.129621809348464, 2.93080934716596,
1.29995665657851, 0.00402722615076022, 2.32118903266059, 1.91697872761223,
2.98029252555635, 0.144446606374846, 0.931855985894799, 2.06740069389343,
1.9963094935649, 3.61723726656702, 1.79066928972801, 0.175948142051412,
0.313697403434802, 0.313696665108889, 0.562477084359637, 0.940078693131606,
0.553572396864183, 1.25162044819444, 1.40659296843741, 2.67131516502963,
0.933104986066206, 0.717582089043895, 2.55064856343799, 0.0098532453024139,
2.89741227693028, 1.77956409504016, 0.659097110697379, 0.044358127138198,
0.317067428979229, 0.0293432688340544, 0.233535238384825, 0.523049272596836,
3.02635723352432, 2.13003019326263, 3.55344631605678, 2.8923209309578,
1.95697181589074, 4.3801843755775, 1.05848696413967, 2.14403181771437,
3.15543247262637, 0.656992401591398, 0.506094406410638, 1.25973740551207,
0.868466005867554, 0.198439320342408, 2.48386304411623, 1.91952057162093,
2.38458797004488, 3.29986380040646, 1.55536580996381, 2.07672144969304,
0.129487879557052, 1.6698269057605, 0.746081853181952, 1.3779322637452,
1.21650595507688, 0.935277316857267, 0.529451651886726, 0.290530746498714,
0.773194897505972, 0.339117400020499, 0.482043565871815, 0.357964037831321,
0.38475367701095, 0.492161187619247, 0.474689489437474, 0.476692038001838,
1.30423309736782, 0.27301464178082, 0.464232359633402, 0.0476573174991817,
0.21949484511451, 2.87652439872424, 0.402814037390743, 1.70075945100851,
0.474219550137167, 0.683696416793046, 1.51456437508265, 0.0104637012247824,
0.0909621028080841, 0.0265760260539267, 0.188893037718824, 0.221660491531818,
1.24691276307459, 0.0166427238404544, 0.475711044338014, 0.234023680373664,
1.72643849046694, 0.225006794022327, 0.363398298431464, 3.5767586198118,
7.85572122865253, 2.323454712828, 1.74199471157044, 0.652520459714449,
0.748204073972172, 3.55164986848831, 1.78631892634763, 1.76411989538206,
0.972894642088149, 1.68048058015605, 0.760874366594685, 0.0975800844737224,
0.287431496924169, 0.0556863004134761, 0.0695945883462964, 0.633395133488294,
0.235700366682269, 1.56726423365035, 0.590684366722902, 1.2217633362549,
0.966259212336606, 0.176147776397152, 5.51600844992532, 0.2554630389851,
1.25958209898737, 0.774381029937002, 0.0356890454940084, 0.456011203854966,
0.126588102744858, 0.476528753009107, 6.28625728024377, 0.994410512192796,
1.01564708476265, 0.131882854978795, 3.24170789453718, 1.34503247493154,
0.713610992387489, 2.41817257553339, 2.78487568265862, 0.0427317731944775,
1.13178576630566, 0.173858548393818, 2.51212988959418, 4.49267937077416,
1.62329392797417, 2.33785026437706, 1.69170126318932, 5.10476465357675,
2.23078571259975, 3.3361028979222, 3.4786223868529, 1.1691519493858,
4.65307221810023, 3.89394231306182, 2.27483505176173, 2.25558359258705,
3.00631627440453, 3.16690863751703, 3.40065463052856, 1.04785059599413,
7.13102646668752, 4.90421176619, 0.958971605118778, 0.751159323586358,
2.99076777696609, 1.42179399480422, 2.22367431388961, 2.03135940763685,
3.10645871857802, 3.73811373942428, 0.376835955099927, 0.848557840256641,
1.08488680132561, 4.28556280997064, 3.16932689150174, 0.462430083917247,
2.21221998540892, 2.30203932854864, 6.79522746801377, 3.49720561173227,
4.91563580102391, 4.68661571211285, 2.52543483674526, 1.64589102731811,
7.2924780315823, 2.49452906019158, 3.24630415108469, 2.86231407192018,
3.1191853152381, 2.71843519475725, 2.15742627282937, 2.04028253691892,
2.72530753082699, 1.87281395991643, 1.31457502089648, 1.18887358420115,
0.186500398983265, 0.533064047771471, 0.233118277155208, 0.0389145119622333,
0.64683637695594, 0.67875090048269, 0.516084490274941, 0.355572777694087,
0.195427613946878, 0.263360520522973, 0.100067904632952, 0.156323384079668,
0.683183912084335, 0.832273016373316, 0.480414821869797, 0.346269601386868,
0.675508632704064, 0.435874950175208, 0.552671962038234, 0.361638121755311,
0.629279904895359, 0.24922186483767, 0.080496990846263, 0.436905177793017,
1.02512503967241, 1.71007699582777, 0.287318891431722, 1.61395685333345,
0.352670151343638, 0.178241860293956, 0.371530981251487, 0.0588099922363957,
0.710532453876955, 0.0874012545251322, 0.688117854573108, 1.31386057535807,
0.483334409141982, 1.11907647938157, 0.623392807802668, 0.414212163417014,
0.305844353994838, 0.720062319327284, 0.314469254437696, 0.198533952857057,
0.104235683464342, 0.595535933178056, 0.109722609243666, 0.167890055570751,
1.64713646968206, 0.747111352505507, 0.0366873510841591, 0.452073006994194,
0.136280031965321, 0.252020885409028, 0.385887682696597, 0.541216020506841,
0.379638193175197, 0.451635644176147, 0.490676506663914, 0.0507713616049538,
0.52502560781108, 0.238301551072962, 0.0941681641981834, 0.896700432731046,
0.175628301491357, 0.162783361738548, 0.221736227748571, 0.275857232620991,
0.532304544415739, 0.0671321211934642, 0.204931623759438, 0.279625448639746,
0.509109148634943, 0.5888302039562, 1.07592368622621, 0.480284604347414,
0.274161671512519, 0.133469431109175, 0.457026761249398, 0.256414949066109,
0.782097662074698, 0.0802391165160333, 0.124528442293888, 0.753964793454442,
0.0781407062593778, 0.170335967964665, 0.098533707274193, 0.10195110824511,
0.0361232577598895, 0.308342002746132, 0.263891295982628, 0.260977717978811,
0.316914655406166, 0.237286996350762, 0.045557123531277, 0.163918688091346,
0.501009734002528, 0.267424874641519, 1.18853914282388, 0.341069928059975,
1.19035065831203, 0.520567658978204, 0.323860664075861, 0.176068325867635,
1.83538329601288, 0.270655185148051, 1.11175128279461, 0.775605843505926,
0.198140514988659, 0.13526324979547, 0.150271660807818, 0.351510174572468,
0.378895842746176, 0.0195879783606398, 0.00663707584438574, 0.0686002707872022,
1.90869418448872, 0.799382677784673, 0.00206943533676504, 0.02309715657288,
0.28781753902634, 0.047770736711283, 0.886891277299987, 0.117569950512714,
0.16578801660971, 0.691991558781377, 0.13765606722747, 0.0189356485347229,
2.11213809003433, 0.0939015510612754, 0.354699385145472, 0.321674935358007,
0.0552119262283668, 0.444073770885114, 0.0174007323706367, 0.0441401822328636,
0.123266502766422, 0.441834998213583, 0.36955997209858, 0.250418641432016,
0.132153189077077, 0.222621083768361, 0.196394316211808, 0.0225876246813978,
0.214942052822422, 0.114729498119333, 0.0822111914210298, 0.354246720119759,
0.666505605034116, 0.0890005422751764, 0.0761842758748335, 0.0686936101410538,
0.519215183953444, 0.253208107418484, 0.119292747087052, 0.0716537000720294,
0.481475661888167, 0.201690653041522, 0.166600669440986, 0.239692151145492,
0.0541571847150206, 0.0879878903646453, 0.115722100946759, 0.064215163118206,
0.113311095357252, 0.383924530612098, 0.0459430463144801, 0.0416112285779996,
0.370742933074426, 0.344752346751867, 0.218145786331863, 0.0551027172089865,
0.0285476129760759, 0.163653728034761, 0.0687251524036078, 1.72402664108409,
0.0223090568938965, 0.570406614492337, 0.448883295335152, 0.422534150045572,
0.178258072998789, 0.375290038685004, 0.373374480064268, 0.552586355130188,
0.0137279873080034, 0.499651228388151, 0.378715513756982, 0.102107806301555,
0.575862650791856, 0.402421464798627, 0.0698177170275745, 0.615958431804622,
0.492356859871911, 0.182333206867851, 0.32073667369507, 0.0915788245361505,
0.696939265389961, 0.906471292729731, 1.12276526402544, 0.150003386281983,
0.644235812334551, 1.14620396660434, 0.56645116513526, 0.0836269875764157,
0.689477325624062, 0.350913766668075, 0.641379563068902, 1.29679046957581,
0.65563836786896, 0.256602374750569, 0.638202159631032, 1.10301078069541,
0.261437686988049, 0.0139593431514287, 0.13751135337063, 0.308244496790899,
1.49643020166291, 0.809364513166387, 0.534472715782209, 1.28874751925468,
0.875377539027896, 0.634270061497335, 0.200327451512243, 0.548043889993871,
0.447710330994731, 0.124002756895842, 0.0213263995246962, 0.417848343960941,
0.106863483027728, 0.0702624290521878, 0.619441347630022, 0.451358276108901,
0.220047497363002, 0.259699035642876, 0.797376969346294, 0.135235150586124,
0.00707938124994851, 0.353466894727683, 0.14099287761039, 0.00959205940469273,
0.137249628068983, 0.0677400154009875, 0.12199829014113, 1.46265212115314,
0.693191603378013, 0.398142288620066, 0.731694830788507, 0.0551737356042765,
0.517411784475876, 1.16580166892769, 0.000742415520276323, 0.0706165489326749,
0.0338702643186682, 0.392121388059523, 0.893404224473569, 0.921856028338273,
0.0169748244807124, 1.2568007176742, 0.553723157073061, 1.22836789374964,
0.365497426660214, 3.57616389294465, 0.0335700949998917, 1.36493986762232,
0.658369920319981, 1.8646788539158, 0.872444858722803, 2.51184711025821,
3.05765981682473, 2.93509663807021, 0.706001067469414, 0.782804162965881,
0.347023964031703, 1.25252838412093, 2.55707803906666, 0.0511911525800652,
0.546478814238475, 0.0812400457776945, 3.20285707701825, 0.168550752824457,
3.74332266714838, 0.29695561397562, 1.91241277671523, 3.36086744732327,
1.48602595097489, 1.34531680328978, 1.28219938360982, 0.949396286884116,
0.552194053604682, 1.08778983147608, 1.94693195592198, 1.80895905527804,
2.40127400888337, 2.0086386617687, 0.0933981732060029, 1.24480251305633,
0.103463496909373, 0.893116587566005, 1.58662825491693, 1.81281748910745,
2.84001457360056, 0.633295193831954, 0.677721063865142, 2.29877803723017,
1.04114209488034, 3.89412295156055, 2.17287284798092, 1.82997640139527,
0.0422565589520942, 2.76315112908681, 0.363889541696861, 2.40922693245941,
1.33800837149223, 1.63862974445025, 3.49767819378111, 2.72051641345024,
2.26356852468517, 2.11044231719441, 0.207195443998056, 0.340501028647715,
0.461710241261042, 0.212496905328913, 0.0685143134517906, 0.351022031848077,
0.0791439033207426, 1.37988261161027, 0.223062417582022, 0.645103590907874,
0.33595985977876, 0.239551620519099, 0.793165808474576, 0.0447657419448391,
0.143655817058903, 0.323357865076374, 0.149620578719165, 0.512807714028491,
0.958218113415771, 0.121507212316997, 0.127516217029619, 0.857468369365152,
0.52721098224046, 0.600661940872669, 1.18240924345122, 0.674083094354029,
0.493803026223624, 0.666682176550643, 0.298865904941017, 0.90348188035811,
1.2901569435166, 0.746403601986391, 0.797655341267172, 0.641388176078046,
0.633962102924232, 0.0480634410934592, 0.347498238431635, 0.11220718835722,
0.868721041414473, 0.250882403028232, 0.789513462507683, 0.0819679731115078,
1.45955719925567, 0.75475130820026, 0.0606155734491983, 0.0640698086332392,
0.170807536637531, 0.120889082915339, 0.00711651725901497, 0.334121711207209,
0.0998931075575658, 0.0337871212977916, 0.200036901372692, 0.10226684179226,
0.155099045468011, 0.21092543587966, 0.326846480171231, 0.221128681208938,
0.190547146705083, 0.227352892350474, 0.0319957122361908, 0.647733609709475,
0.723950289465763, 0.167002955940983, 0.481091812046038, 0.246322769249134,
0.785713280516642, 0.296782235968513, 0.142089222185421, 0.220641981655111,
0.280230493930166, 0.292810846922091, 0.60623011044744, 0.451957721815065,
0.584932498081967, 0.471858608501929, 1.40885982062254, 0.839060754687698,
0.495130991735668, 0.150680450567355, 0.0888976654193054, 0.362911036419165,
0.4647504662474, 0.612936109131961, 0.0912498205057259, 0.399149194480506,
0.930422175675631, 0.0387169216539607, 0.171220506728989, 0.467869986676508,
0.121787019459858, 0.0605484760987262, 0.39173469459638, 1.57263309977673,
0.2263656980703, 0.529581940344845, 1.43304259468008, 0.524421486089489,
0.331346652918944, 0.297300420287583, 0.0813674786024623, 0.107271902235139,
0.194091188359178, 0.00201377382984868, 0.222098662078174, 0.535092453196369,
0.337247458183103, 1.13256799512439, 0.554604080264215, 1.16408581328061,
0.264112906289045, 0.160999420555998, 1.10617675273507, 1.10219977409751,
0.761050057105927, 1.72372659099185, 0.629235435346211, 0.671610755776917,
0.543322192849936, 0.346582388298379, 0.214538591280062, 1.23874078083921,
0.0201480066472734, 0.106949653178971, 0.167728643942003, 0.474914896681353,
0.319563338533044, 0.31454386431034, 0.0345962824767749, 0.147013557557431,
0.704504161284098, 0.732292765699741, 0.0108262462696681, 0.457096372498199,
0.297865987548398, 0.68944480859985, 0.0723781161424187, 0.0962715791538358,
0.412601507255911, 0.0512888812270291, 0.138137491074977, 0.229827503363291,
0.0594729161392833, 0.264664746792901, 0.293770328509035, 0.32066063500113,
0.488461403521123, 0.0553095828120907, 0.0395842860280364, 0.352904741995088,
0.0297120941492418, 0.601091632800591, 0.168958437627966, 0.0448879455733631,
0.0493573010467959, 0.214517239688171, 0.10953708037872, 0.648754397562395,
1.05265357262558, 0.207761973073637, 0.292465473413123, 0.00967992579616192,
0.0498374859905905, 0.665932742930535, 0.122254458618247, 0.060422953911324,
0.102324811780515, 0.657450899488241, 0.458773515368294, 0.432081289934339,
0.0819027936943005, 0.0327987719103004, 0.448548265858941, 0.114031653924569,
0.123328542707626, 0.468969093687418, 0.592065028570316, 0.634357010544692,
0.110965317981835, 1.63728514644835, 0.306722981861741, 0.0433665929595008,
0.232666182676675, 1.03499319802763, 0.0999664389528334, 0.373142798189764,
0.195545934183799, 0.256834812453707, 0.215590373393045, 0.687746543575216,
0.300104647573015, 0.195589530307593, 1.10896771076498, 0.283502884319104,
0.412097299540484, 0.0711132228305494, 0.00209775746420578, 0.689112841229265,
0.0700760598507191, 0.358256488866, 0.08556769705481, 0.140479506717788,
0.659350687706912, 0.718115401764711, 0.348720929072307, 0.865802549964024,
0.225422778886881, 0.060223428817052, 0.305506489481087, 0.192238386461718,
0.627407199806637, 0.426118169117857, 0.250546301508115, 0.0869084114545129,
0.507419588113273, 0.444499937494078, 0.428100614924915, 0.171181546593154,
0.469268801311652, 0.059910133905726, 0.1169006170498, 0.305229264070038,
0.696034121702218, 0.794124478543246, 0.190564461811273, 0.200548941398867,
0.88710051174793, 0.0248282982836288, 0.666138290807053, 1.13057005653779,
0.309389979613048, 0.0836371104200629, 0.33810469844482, 1.19635564337174,
0.521123274927959, 0.546239381587064, 0.501277350147979, 0.0727411495797612,
0.709129059756244, 0.625806307903043, 1.35738120807542, 0.12453967198127,
0.217400468743613, 0.0965983658377943, 0.141307456160171, 0.145221839020788,
0.850072973976946, 0.267384415319948, 0.126224568398255, 0.0467080758858679,
0.228617232292891, 0.156502520283943, 0.984528829136656, 0.200559198576095,
0.726905075488267, 0.0931982506428742, 0.0874365931807983, 0.0635543155658524,
0.0573273326606593, 0.0145616336117706, 0.128075677936, 0.0145805544808456,
0.32809755295791, 0.00973213000947402, 0.0211311284349196, 0.208411679948094,
0.254679489466879, 0.162686072186463, 0.111734505658711, 0.0711234339374911,
0.311215280658669, 0.225540262543493, 0.108235041222845, 0.101435510757491,
0.259764089009776, 0.233877333501975, 0.465712415399375, 0.295357169169519,
0.109901372050108, 0.0192114263627445, 0.0736051337196976, 0.0735273132789492,
0.358801638065078, 0.176285265397315, 0.139262800113539, 0.0277304961065831,
0.144078797253314, 0.0634207497695806, 0.0194405854627904, 0.0784848224685885,
0.0730760105135333, 0.192247129976749, 0.301707166557511, 0.405513824136169,
0.30102249800607, 0.0694166345767573, 0.119804514891089, 0.177740444705166,
0.338002631117383, 0.246231402233847, 0.0319462612756912, 0.215023833913384,
0.341789499891025, 0.245927337212143, 0.329034583229158, 0.0909960962124859,
1.6022525495953, 0.00754529199373253, 0.268420072755328, 0.370136730096958,
0.0943753183819354, 0.42996203209515, 0.136952682984648, 0.200559093133995,
0.0202627922952632, 1.06620660190108, 0.174251813443671, 0.120104105384262,
0.181903265347635, 0.0977782665027513, 0.0287489580783855, 0.120778012813793,
0.000525837843909999, 0.210750723947529, 0.0804240230483831,
0.0272637732947866, 0.130734043060026, 0.132137625366104, 0.0948620569090255,
0.259028395965557, 0.0322843683243264, 0.27884464752343, 0.0347497869986034,
1.19392430885798, 0.252333231770468, 0.132036234603557, 0.177148510635123,
0.111873134229056, 0.0678361298309432, 0.0719268424177749, 1.52335759599373,
0.0282096542047199, 0.174650875506578, 0.07832462578598, 0.151353651864661,
0.327925476719867, 0.409000460196424, 0.0707274661399424, 0.184512143708869,
0.223808907507056, 0.381486628342558, 0.498854702661952, 0.401999946502555,
0.426266371789906, 0.520763164041219, 0.273347156743209, 0.142317532182292,
0.0835228336805745, 0.331563926267403, 0.113817378223218, 0.267445669402756,
0.0327473503227035, 0.0593385177543732, 1.40492692382799, 0.374453648368621,
0.292720709409979, 0.0883134656016611, 0.277379655017285, 0.109858610270614,
0.0727738391993895, 0.352936226063994, 0.359008089208079, 0.535345631893034,
0.0663285987986321, 0.145428886085197, 0.22752392657653, 0.800671677312089,
0.178020382575967, 0.343254627970358, 0.575236171070072, 0.231883646092481,
0.0998944035317335, 0.585310158354265, 0.0706102412180001, 0.329601346687586,
0.448822834425502, 0.805922563049804, 0.416107453923259, 0.184890053217748,
0.74895547758098, 0.0818641577735198, 0.0381609975506931, 0.0815330259674401,
0.146526438529017, 0.223483890163522, 0.0258797904480835, 0.0415052664207502,
0.781465213331911, 1.59719519151582, 0.139986932246959, 0.532426078286436,
0.0592209694700109, 0.146011237451738, 0.0705035589462905, 1.01036586088163,
1.353866044018, 0.240138217936166, 0.322651856216706, 0.152595009206346,
0.309473688679713, 0.149292479665881, 0.252558676043042, 0.331067591388193,
0.993807618264799, 0.856154903614273, 0.0628381455812983, 0.660648643280621,
0.183874998948778, 0.496151003641663, 1.13703330523438, 0.48432187370404,
0.372246394554774, 0.0168665112254934, 0.482088884985488, 0.696801958812608,
0.0368149551407745, 1.20240766306718, 0.793671152657933, 0.454995695372216,
0.152263477305597, 0.678839362226427, 0.115659194080056, 0.0180964471504989,
0.00291281866116656, 0.569747298360906, 0.482857872007622, 0.215310113952944,
0.32273670465306, 0.0412727133004443, 1.20941247747935, 0.978929006093596,
0.572946673742047, 0.145323328512152, 0.0306968009196377, 1.09266178294395,
0.00188281270675362, 1.43270565176176, 0.945565158915189, 0.00999659339194531,
0.861908732570656, 0.0164485950436857, 1.62665498411904, 0.643725113253351,
0.635246094316244, 0.206477582782369, 0.500292980974471, 0.063744080472841,
0.426348476360242, 0.0303415094752348, 4.71576043797864, 0.247799044035168,
0.297351828164042, 0.76383430100072, 0.491654379707244, 0.054028623520733,
0.100607625868482, 0.366502546498345, 0.3921236704897, 0.673499683952994,
0.24394166955069, 2.60945971475707, 0.191761799971573, 0.876495407273372,
1.01829134093391, 1.48132758574502, 0.00775445455548362, 0.0110231900794638,
0.298947346396744, 0.716617376931633, 0.864570021629334, 0.436246804755043,
0.0882967062514379, 0.15837739708109, 0.870226634045442, 1.59548684513127,
0.890233760078748, 0.2270853628094, 0.364007062304558, 0.0450379444475941,
0.174857031722139, 0.163711913628504, 0.257307778181577, 1.05352779284672,
0.0159858985765216, 0.864581442360456, 3.12447922097312, 1.56192855592127,
0.288919222489413, 0.152799929164488, 0.147202553980403, 0.315216507003815,
1.06551531619496, 0.712641755170706, 0.164218550914989, 0.451622485700581,
0.0130762901260621, 0.692092150449753, 0.148882429704018, 0.21029859905765,
0.141042934773766, 1.59213193174866, 0.374471303972381, 1.17855684751541,
2.99502004848586, 1.72104245093134, 0.577087360097923, 4.38051312830713,
2.50136671132512, 1.28538292335967, 0.463260349058719, 0.773144387497773,
1.22481173690822, 1.09277468505833, 0.394393783424877, 1.00372938728995,
1.40239078655011, 2.95019108719296, 4.1705770028962, 0.668815039650158,
0.27414655999315, 0.760689265957033, 1.39842128761423, 1.30084194794849,
3.64447696838114, 1.95183946357833, 4.82601593931516, 2.92510347730584,
2.38439417640782, 2.19347187379996, 2.33824967179033, 5.62672858105765,
3.42426536480586, 0.177883726360354, 4.18723326921463, 0.536571717372647,
0.447227993669609, 1.27505090956887, 1.01876520357716, 0.525634936561498,
1.92163948300812, 0.615310381218377, 3.34195561210314, 0.701388737018634,
4.42667606804106, 0.226350465582477, 1.27077099329068, 0.780512208895137,
4.42926655875312, 0.0976363757314781, 2.51266229897738, 0.0946914934622193,
2.28871888998482, 1.53260447498825, 2.20428497178687, 2.46008859905932,
0.293500010131134, 3.48448150687748, 2.73324016067717, 0.15083403809479,
0.198483592050185, 0.0326239448040724, 0.504207993663537, 1.90877598565486,
3.03212252921528, 3.98867422673437, 2.35030103723208, 2.8834343817499,
0.964526210394171, 0.802584426982018, 1.46665146532986, 0.313903495063574,
1.10907057900396, 3.39897258414163, 1.40280484077003, 0.606056536858281,
0.900519093091134, 0.111229614837578, 1.51535406294796, 0.80644673978289,
1.56961160608464, 0.152109285954524, 0.51459109791796, 3.14413324660725,
0.874389369040728, 4.54620148738225, 1.61960587319401, 1.92647231618563,
0.18498639067359, 2.48466214703189, 1.94480176601145, 1.72954592108726,
2.29871787793106, 0.340198113824482, 4.30383105576038, 2.94663700295819,
2.87491996089617, 0.323966561519127, 1.56530998895566, 0.200537452160562,
2.86438408493996, 1.89420934932099, 1.40721283908244, 0.338215070052279,
0.70573504785231, 3.53191785348786, 2.96446970105171, 0.963126522695853,
2.01833570334646, 1.75488492494656, 0.156252808515866, 0.551788844763198,
1.72727169841528, 0.120853459954055, 3.43367489882641, 0.421897854914682,
0.152541260240401, 0.481267009594443, 4.80265518691805, 1.0295175608351,
0.316493946024113, 3.08792945080333, 3.19109644492467, 3.26621415714423,
1.83665752742026, 2.2394136554665, 3.10523450043466, 3.97060697608524,
2.17568231953515, 2.6732486585776, 0.950841250053297, 0.0480754415092869,
0.381795314683889, 0.12844076554541, 0.0656728614617518, 0.615001744901141,
0.288009795463747, 0.122138739261977, 0.348093470713745, 1.01625286208259,
0.111130335471696, 0.447624577649145, 0.200814861597286, 0.0206728748765912,
0.100348966817061, 0.279063249821775, 0.0173890883964271, 0.119068606635901,
0.158050102181733, 0.0190120624091058, 0.257343829971635, 0.00281952519866603,
0.157255608898898, 0.406539471147375, 0.113742726462617, 0.152010528797594,
0.371912666674082, 0.162638732007946, 0.059706263231217, 0.374056781443802,
0.08913752842798, 0.449502207131849, 0.240859511318073, 0.0629171648200739,
0.0523528772475267, 0.702842428168676, 0.04309906749943, 0.47380736643552,
0.0966331661264929, 0.427336583793577, 0.101454453732542, 0.0987856723599921,
0.113161016773019, 0.201551744248718, 0.0864058054759408, 0.209325957905363,
0.0588648518961337, 0.122891614484683, 0.123875642661005, 0.181761068667078,
0.184303521790921, 0.0848351519606594, 0.334496147361481, 0.0916454145615851,
0.0479876676194922, 0.19232361712299, 0.223560185352754, 0.147077555630218,
0.0108475228512867, 0.206914607952866, 0.0955096442269644, 0.201975366928511,
0.18410230766016, 0.0374373619065241, 0.233125690810589, 0.434876649064285,
0.186215956651722, 0.0284735757935171, 0.44451093301177, 0.67898119510048,
0.261256461057605, 0.0149596184319644, 0.0564336641864092, 0.0367059841907273,
0.566645419147486, 0.0425921776089429, 0.0934808371045316, 0.0224913337733596,
0.438206867082044, 0.00491431785189046, 0.133043575113536, 0.113412421985736,
0.0196410655884796, 0.873593349423673, 0.343762996244348, 0.0926998398521122,
0.4032220226816, 1.11478893458843, 0.638379800857769, 0.127686126485329,
0.205491420398984, 0.0373045088706055, 0.0690528476326209, 0.131632438990184,
0.855613065055675, 0.431829649815174, 0.293811717872611, 0.281505069126272,
0.0750432458826927, 0.0794121154952639, 0.573430776026928, 0.619524851803564,
0.00145425421888595, 0.293454772327095, 0.00388112329542141,
0.226285510256679, 0.139612795543615, 0.0747898903468417, 0.153858928423789,
0.00570957545035829, 0.0254745494457893, 0.550897035505235, 0.143339078769916,
0.0404224084103825, 0.067366984772013, 0.117999259210019, 0.190866797129813,
0.456250095817571, 0.00657726505219384, 1.18081553000957, 0.0429881147445283,
0.282393675297499, 0.216632073783937, 0.149597157058047, 0.113741623744351,
0.391708592961853, 0.515533500040571, 0.2374154256411, 0.0259715415886603,
0.0230054633898867, 0.0477308837806858, 0.560866792479323, 0.142101519390794,
0.198976110498835, 0.248684302800231, 0.866735726297419, 1.07057636024223,
0.899474703603321, 0.0690219509674029, 0.358368445049833, 0.168546031418912,
0.102299959056028, 0.140454616313542, 0.118988774173583, 0.0704230911581329,
0.20317273804297, 0.0672464629180333, 0.0358973485223639, 0.51774914556558,
1.03025768097076, 0.456892032797138, 0.308808724415333, 0.146789161818257,
0.387783243631323, 0.205159515487375, 0.162549623626142, 0.0334683641148904,
0.145379893604614, 0.16724745129856, 0.0373024876915022, 0.00346332926872289,
0.222806374283714, 0.464461655731106, 0.136204899418064, 0.129915714960252,
0.089398256202306, 0.103382771709692, 0.427676506909645, 0.0683140361356049,
0.112792410870531, 0.0108261046051565, 0.0455365419299967, 0.216234503796807,
0.0018321511818579, 0.0175543413152573, 0.0804489673874168, 0.436382527566618,
0.326960001554754, 0.526102442811761, 0.0274243173189461, 0.0392981691855109,
0.137949002044344, 0.449765799463623, 0.0910082225239387, 0.0518350137087206,
0.294851699085147, 0.108625558217884, 0.219222438625164, 0.0211130707692872,
0.142492612522026, 0.0489409803827854, 0.756295759534825, 0.840393272228539,
0.621174317500037, 0.302248462275774, 0.12394588816635, 0.0376811830447642,
0.205790750178966, 0.334451494083084, 0.157627308347502, 0.0207135869940329,
0.166934063205392, 0.296838345075095, 0.0265777693237868, 0.174640255109235,
0.120511653677871, 0.119143058994302, 0.0973360885056739, 0.803893078079758,
0.116860416760944, 0.274057569939436, 0.100684956250781, 0.319074881573518,
0.101590269922141, 0.0501373383621858, 0.168525255604268, 0.287883436453908,
0.206679137268414, 0.069464796912615, 0.461566356735097, 0.280723979612554,
0.764064701200419, 0.167379585931216, 0.221403461777502, 0.173475561232341,
0.356425109422869, 0.511952939408797, 0.149975006926171, 0.189948394347017,
0.180525022144947, 0.275456531611444, 0.0336467870769815, 0.379049689129547,
0.247719359170231, 0.558076074760821, 0.0995039996708295, 0.38539824841751,
0.302072892103482, 0.172816013749171, 0.745084608982628, 0.111799904550598,
0.102056805898125, 0.218620977597311, 0.19306206220278, 0.0918655707678732,
0.0695778437096764, 0.164499098607511, 0.0629894996268882, 0.986727657313976,
0.175347164531963, 0.348381023543576, 0.548338055507177, 0.231705827397053,
0.0131501098663581, 0.123755162092426, 0.44165479529787, 0.13637915281234,
0.132772361445758, 0.177262797593829, 0.369823410693142, 0.173167715590723,
0.111971011988957, 0.053195579132686, 0.161459708560465, 0.0857523450740027,
0.316449354023293, 0.183118221893286, 0.440703324300961, 0.0820397746197327,
0.296280383425592, 0.481307371806098, 0.980006703486045, 0.228920723242616,
0.12245018419344, 0.121832095810937, 0.259862604085356, 0.270937267871987,
0.239976344759473, 0.208080798594488, 0.398495878946657, 0.0464304050141167,
0.229202928797652, 0.557360387096802, 0.403279115480405, 0.309050350846654,
1.68389090895653, 0.124815660459852, 0.536219068423465, 0.472608629976296,
0.040730037536748, 0.0686242371917211, 0.277293244380012, 0.0634400609156324,
0.477874289687154, 0.0471162559438704, 0.311008637408829, 1.27346625323925,
0.254398139741237, 0.225811883479495, 0.0813447725959122, 0.529112425115373,
0.160582090848712, 0.0585018250858411, 0.173222970831611, 0.269516411961781,
0.0189939102683975, 0.109150449503903, 0.188315832133715, 0.0610238894285565,
0.253661468159407, 0.469848185661249, 0.585735582332644, 0.0588026607788547,
0.0208722823633623, 1.26075301319361, 0.315626785779993, 0.526952312879816,
0.0122736619022261, 0.10418893883104, 0.284204018871403, 1.56232295350896,
1.63583883725935, 0.364987385355764, 0.298843433019809, 0.876255303336721,
0.594992477343314, 0.0519349349110767, 0.106401982794826, 0.140608451773275,
0.355507677860765, 0.434799937324392, 0.246234031090151, 0.0766022491562008,
0.086089835398727, 0.0277604579201175, 0.383960664272308, 0.248812548350543,
0.0145375115141548, 0.0763464101861852, 0.117326199049179, 0.1014873833305,
0.608240043563354, 0.282618223513257, 0.122407153087099, 0.206692181568037,
0.205851784165673, 0.176359997441371, 0.12911947874818, 0.245199066134066,
0.00518539250414404, 0.0133006997898014, 0.32120074192062, 0.477129019952069,
0.249999567090223, 0.256802465913804, 0.185665505420831, 0.0971693155804166,
0.0249946014373563, 0.268494751123298, 0.0831004123255197, 1.10974078832401,
0.0754990705172531, 0.0844461636410819, 0.0729013672615919, 0.0545821334666538,
0.0936465209039549, 0.0237379242510845, 0.125909215442974, 0.0372224396258524,
0.453166437438793, 0.152222304898142, 0.195532255754289, 0.114921950959359,
0.0381609271496051, 0.0968284987051178, 0.244836064314263, 0.0746019155269972,
0.494448469317932, 0.270227311179042, 0.0775590632498885, 0.442101886250182,
0.0298162394987971, 0.159861483585296, 0.0209066165639174, 0.0999339270077784,
1.63208658496539, 0.0367292628054404, 0.96827157586813, 0.182793797933738,
0.558604445825848, 0.345581707415274, 0.216865073906741, 0.0413964132183335,
0.398213179523332, 0.154136329734077, 0.121509546345031, 0.450012205375565,
0.148466228576446, 0.365006555837614, 0.0620115316576428, 0.588792021722636,
0.213436796536876, 0.519170547693244, 0.354497584203879, 0.0907449659727583,
0.346474661457318, 0.0368037142066492, 0.0131112654796905, 0.0445401989836009,
0.210234068109895, 0.04209454330191, 0.301473798359641, 0.152590869904897,
0.0416314365003793, 0.14346876570818, 0.35512452156076, 0.0246281002527448,
0.0643803737282859, 0.0626107595960127, 0.0620768536011585, 0.0618970941243417,
0.120624242471186, 0.296281568576685, 0.112193776846484, 0.0291354677540733,
0.0443585258391168, 0.0436215620720759, 0.0239953606872371, 0.230876128879134,
0.0315850139293751, 0.0253168653256984, 0.06841787683812, 0.164578842212601,
0.169328257266898, 0.185040236593017, 0.243187068961561, 0.248747325605816,
0.0999756632631438, 0.0772856722792818, 0.323799527836619, 0.623136245128181,
0.175236258621293, 0.018578164586668, 0.266914151712424, 0.0101704416576669,
0.105634981080786, 0.331178425224843, 0.078073775999386, 0.574881496308889,
2.69230839941237, 0.173872007884913, 1.07130904713025, 1.27886656858027,
0.0274782511966165, 0.0294975149014068, 0.206740941645371, 0.222541533902081,
0.0504529064659167, 0.019619617675845, 0.18525190775162, 0.0437677745519775,
0.18449468019039, 0.144548727458136, 0.228436318601275, 0.746067370158724,
0.0524442585204573, 0.0712938897745011, 0.460990367560751, 0.0341522731164501,
0.173106630121496, 0.173320930813336, 0.265186972916126, 0.626157533584369,
0.0172758317655987, 0.381007925875666, 0.0441291489707375, 0.50566388749414,
0.803469800739549, 0.100499489770435, 0.632931836531498, 0.739987262835105,
0.205553113185387, 0.178261341501234, 0.212045046604342, 0.00706627776984263,
0.100365925580263, 0.321633486581656, 0.0845636825575234, 1.04561092549314,
1.12919647826089, 0.162286067355631, 0.275205418305834, 0.0218271926429157,
0.0289753787995626, 0.270668620036708, 0.43787267595245, 0.296138603205489,
0.529971440245087, 0.431804279434598, 0.154659123851969, 0.511680050985888,
0.0899524165714091, 0.100485335634504, 0.74504995935907, 0.11652983758702,
0.54325324545304, 0.359148667142209, 0.0449472713905076, 0.0465266118828569,
0.619922271305566, 0.00178300243310838, 0.545545379657091, 0.560213439127741,
0.893883174906174, 0.0575267532150503, 0.360893033978452, 0.124387453620632,
0.74609029369377, 0.115157765025894, 0.0923470577626075, 0.284932401296424,
0.48936669047301, 0.0783880334519954, 0.374240036213046, 0.485291688961701,
0.282280585295262, 0.78431532645805, 0.19976472651103, 0.0651442259334511,
0.0255597728149345, 0.0238262752606749, 0.217941129243829, 0.379455501556448,
0.28155155474734, 0.184326876674917, 0.129164151161806, 0.105059395143245,
0.0602519916170018, 0.00937047536933312, 0.00885073829084394,
0.082226076077118, 0.456088899324338, 0.105235151364468, 0.0544322785464357,
0.473227329427674, 0.0289606120948318, 0.0501528381891721, 0.0644975067787325,
0.186399284836457, 0.24752662341699, 0.0483806287973291, 0.00807946329263763,
0.588317839014861, 0.507653622448237, 0.93641627797236, 0.175259111268032,
0.674994991975837, 0.0362803435720572, 0.264721086546261, 0.65851497109462,
0.0273174271828288, 0.5425710681205, 0.665133363929474, 0.306238539689393,
0.365561941408057, 0.260492815920669, 0.0532341261342582, 0.491793931979272,
0.350060556549579, 0.0667509989062738, 0.0598542371902753, 1.02029607279433,
0.503869792929402, 0.143984763210432, 0.912163550758527, 0.122291790562923,
0.556046653797643, 0.013090386684915, 0.501102297540961, 0.248848243564781,
0.245994087101685, 0.0881329601354621, 0.133243005627365, 0.0928596637612726,
0.114394075228591, 0.114519053242273, 0.165344715825523, 0.0265942184422683,
0.0608769695283155, 0.0745085299713537, 0.179031871000512, 0.0800315679360345,
0.272088030042748, 0.054628752913602, 0.291060065229734, 0.358766113580377,
0.0391747290527241, 0.0611709409891369, 0.372964236212687, 0.119164785744269,
0.181920659555881, 0.0785057853769373, 0.0114134683411706, 0.0953729696640814,
0.183144775391729, 0.0491563184758787, 0.110776405678027, 0.0628570214483059,
0.0127996677636272, 0.195053869716099, 0.0801651454271956, 0.11023686668745,
0.0110707041770823, 0.321033008108821, 0.158996162453183, 0.0585163081781906,
0.0307687982793949, 0.0013159334193915, 0.48959444450318, 0.0226755443210196,
1.83484526971976, 0.0813822328927927, 0.00858379826079019, 0.178800821093049,
0.020967637210291, 0.350890034835579, 0.00939085251324017, 0.642677625537747,
0.0175171284074033, 0.651889242024885, 0.0233849769466798, 0.116029740608711,
0.081961901845514, 0.0653509564301068, 0.384264965075999, 0.0849947512184304,
0.0771464840573673, 0.0627667205874416, 0.0470437852113887, 0.464148635829689,
0.56662445070429, 0.23603138231017, 0.0917907140510916, 0.0476330054160725,
0.00516732580770083, 0.241231038442088, 0.133573166237006, 0.147703053688424,
0.155876746349451, 0.0276328836270194, 0.026134389469883, 0.206392737898838,
0.382417068946072, 0.058765436880532, 0.268416868350296, 0.551586566285955,
0.0498607482532626, 0.0794424226473051, 0.0068787162847541, 0.231643991855284,
0.232317031136955, 0.0123256839255595, 0.0847360323165992, 0.145466059032414,
0.128763201258456, 0.0978551779666709, 0.167214046094429, 0.0163745826230971,
0.0329392425526209, 0.0634357454945092, 0.0465386916120123, 0.0422474799841573,
0.1262111882248, 0.142017917918835, 0.0745360685201983, 0.164490870751992,
0.461910619439247, 0.0970954099730416, 0.421901056611979, 0.0819955903139931,
0.255090215070932, 0.0546334675066949, 0.0105333978534435, 0.0335700261682548,
0.149156170483265, 0.890461794411143, 0.0846140190605419, 0.104104920843383,
0.0484910506832724, 0.215421659225184, 0.165271166142904, 0.0816048002905316,
0.0140151137969008, 0.35548826628979, 0.153057537890466, 0.0433691123121039,
0.499596469655646, 0.21862711224498, 0.103821813329382, 0.136069052154198,
0.00402839521066872, 0.109200374361266, 0.263449329007589, 0.0913523927318036,
0.064720974329652, 0.147572628153419, 0.213728252643098, 0.139176141358567,
0.0554182293083243, 0.0744852767739859, 0.00361570957358237,
0.0941287568895388, 0.168228862005182, 0.269933765734432, 0.315020306294577,
0.183152327335578, 1.04175200229899, 0.0628846290055662, 0.522784900058199,
0.0929827432027431, 0.343798661539849, 0.0904747703817621, 0.261433168417878,
0.242846344554521, 0.125542963329483, 0.346043240097869, 0.0846278368971306,
0.0882513739806772, 0.280666723329988, 0.257613569118634, 0.100213225637735,
0.114668902740555, 0.03258498441816, 0.0492141437781457, 0.163062171742139,
0.0762008032502813, 0.304273921168513, 0.0109612640743661, 0.0688721961600499,
0.426596370008257, 0.361058238318138, 0.0114167535125657, 0.139896426296521,
0.0491734469757864, 0.156377348634932, 0.152644821546144, 0.0122356000270143,
0.0307875768178039, 0.333802611532587, 0.570370728738554, 0.176666837461569,
0.550953021842159, 0.212360164633504, 0.479023954658597, 0.215104298493652,
0.109789948104191, 0.829217484241882, 0.557423559153297, 0.465029899393105,
0.240074067688106, 0.0500095821140955, 0.383754095683495, 0.489102803118941,
0.20029685989074, 0.525155201450818, 0.196789386874082, 0.0487158188975796,
0.285041770759832, 0.152304341686734, 0.12170619761498, 0.195818681890766,
0.0420938134107187, 0.352469081059098, 0.232563997618854, 0.17271038743719,
0.0290450685812781, 0.152030013993176, 0.0862756480756043, 0.00144955834925726,
0.0300354009356212, 0.229605755227331, 0.0649393855001782, 0.0906034629464288,
0.135639490831333, 0.291832635075682, 0.523978710433261, 0.118034606451046,
0.0873904477684172, 0.243849047200961, 0.355989662950985, 0.0193134692181721,
0.0492054285253424, 0.00730590975662276, 0.111167838722597, 0.193161723238451,
0.163996845328559, 0.365512367889837, 0.215548317172323, 0.365445158823773,
0.244367158829441, 0.00262670083557842, 0.718919939464993, 0.242113282429744,
0.241886020120647, 0.137072533817479, 0.0547797369169227, 0.0157144434957041,
0.183002021888064, 0.338248547580507, 0.125789625639165, 0.218073768361743,
0.206981092829395, 0.0350272860895428, 0.296075070031091, 0.174846728815249,
0.0589970330636586, 0.11997593252454, 0.124254493008333, 0.0281213585533098,
0.423498440982291, 0.148668635524464, 0.233682373573107, 0.25431872298941,
0.00287981984998892, 0.100722023999508, 0.116695037767015, 0.401672886201629,
0.0241222245579896, 0.451696799033218, 0.0420063991548011, 0.314959257422877,
0.156505401625677, 0.256040254124889, 0.305191055388638, 0.0954468844639551,
0.0720448858466827, 0.213187555566913, 0.384772865015461, 0.0149948425133954,
0.615853181522753, 0.0627228382121151, 0.117240729944401, 0.105870422350967,
0.039300406935918, 1.33511867291398, 0.00223604930323307, 0.0676711857732799,
0.185771662080057, 0.0756379208954362, 0.181070474226511, 0.453583200979564,
0.797349002626207, 0.0635917979498454, 0.0481494556491574, 0.00520204046430688,
0.19292031664453, 0.140802530662364, 0.496697902136172, 0.670673174317926,
0.0458867258987286, 0.0958365540438401, 0.0666073101607186, 0.190930824002458,
0.15621204112001, 0.248684274343153, 0.366849071380717, 0.333154398327072,
0.3491601573769, 0.248899794494112, 0.158197990398751, 0.183306230939235,
0.38603596492774, 0.632458406044558, 0.565234140389495, 0.861585350500213,
0.00951078893720276, 0.215271120716352, 0.0846893273949347, 0.0929301342133571,
0.0627121464349329, 0.643111759313831, 0.12726479134074, 0.148371434981797,
0.288696362516256, 0.153933877412109, 0.210670220803607, 0.0748704051883477,
0.0377299639275643, 0.154435405455944, 0.284219752770797, 0.0174059968752166,
0.0436544185806135, 0.30141989512507, 0.0796431946068036, 0.0666836045544457,
0.472649203544414, 0.383515929622162, 0.00857214509785452, 0.175335468834318,
0.0946484352656019, 0.109839850329553, 0.0476315432514875, 0.0365571614497134,
0.244619445099185, 0.156054071633628, 0.0914489546687239, 0.171337564596561,
0.954590272158384, 1.0934103985524, 0.0681832160679968, 0.169389594234181,
0.0167921352700365, 0.349244022412879, 0.168679381494359, 0.105814297476576,
0.273556229968866, 0.173553186555014, 0.096773883726672, 0.230493274983019,
0.106598722636355, 0.64190698058034, 0.0725371410821767, 0.0408197972466479,
0.554085010179767, 0.355970801294057, 1.4387201132421, 0.0979932385272588,
0.607870073989034, 0.126081294121428, 0.12671053251769, 0.0944170656622629,
0.000922005298047289, 0.146629781134565, 0.245035515822194, 0.0813924969687057,
0.79885810903377, 0.00647136298034133, 0.0785000765247753, 0.336323840819575,
0.023884800560255, 0.260379240382463, 0.266026601644289, 0.012842307522617,
1.74518250177304, 0.0960346983004085, 0.0839052897731394, 0.533447103505885,
0.0513273059256823, 0.120256763193066, 0.249651279087023, 0.201872755262432,
0.766592804239028, 0.112882799772908, 1.2983059850004, 0.49042367314299,
0.143656965215794, 0.240760877383528, 1.00752536639468, 0.1053833899528,
0.157449144604875, 0.528474581764183), performance = c(1L, 0L,
0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 0L,
1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L,
1L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L,
1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 0L,
0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L,
1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
0L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L,
0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 1L,
1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L,
0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 0L,
0L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 0L,
1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 1L,
0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L,
1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L,
1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 0L,
1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L,
0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L,
0L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 0L,
1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
0L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 0L,
0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
1L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L,
0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 1L,
0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 0L,
0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L,
1L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 0L,
0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L,
0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L,
1L, 1L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L,
0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 0L,
0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L,
0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L,
0L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 1L,
1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L,
1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L,
1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L,
0L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 1L,
1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L,
1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L,
1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L,
0L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 1L,
0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L,
0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L,
1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L,
0L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L,
0L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L,
1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 0L,
1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L,
1L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L,
0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L,
1L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L,
0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L,
0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 0L,
1L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L,
0L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 0L,
1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L,
0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 1L,
1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L,
0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 0L,
0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 1L,
0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L,
0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L,
0L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L,
0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 1L,
0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 0L,
1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 1L,
1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 1L,
0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L,
0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L,
1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 0L,
0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L,
0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), mouse = c("ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04", "ChRM04",
"ChRM04", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15", "JawsM15",
"JawsM15", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03", "ACCM03",
"ACCM03", "ACCM03", "ACCM03", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04", "ACCM04",
"ACCM04", "ACCM04", "ACCM04", "ACCM04"), day = c(1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L)), class = "data.frame", row.names = c(NA,
-3072L))

     AIC      BIC   logLik deviance df.resid
  3232.5   3262.6  -1611.2   3222.5     3067

Scaled residuals:
    Min      1Q  Median      3Q     Max
-5.5757 -0.9212  0.4353  0.6020  1.0896

Random effects:
 Groups Name        Variance Std.Dev.
 mouse  (Intercept) 0.1523   0.3902
Number of obs: 3072, groups:  mouse, 4

Fixed effects:
                        Estimate Std. Error z value Pr(>|z|)
(Intercept)             -0.06706    0.23475  -0.286    0.775
sign_overlaps_MD_ED      0.09984    0.16654   0.600    0.549
day                      0.38719    0.03916   9.888   <2e-16 ***
sign_overlaps_MD_ED:day  0.01307    0.04024   0.325    0.745
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Correlation of Fixed Effects:
            (Intr) sg__MD_ED day
sgn_v_MD_ED -0.372
day         -0.479  0.494
sgn__MD_ED:  0.356 -0.903    -0.610
#+end_example

#+begin_src ipython
print(data.sign_overlaps_MD_ED.shape)
#+end_src

#+RESULTS:
: (3072,)

#+begin_src ipython
if df_dist['sign_overlaps_MD_ED'].isna().any():
    print("Warning: NaN values found in sign_overlaps_MD_ED")
#+end_src


#+RESULTS:

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_56.png]]

**** Performance ~ overlaps * days

#+begin_src ipython
  formula = 'performance ~ overlaps_MD_ED * day  + (1 + day | mouse)'

  data = df_dist[['performance', 'overlaps_MD_ED', 'mouse', 'day', 'tasks']].copy()
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~overlaps_MD_ED*day+(1+day|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3072	 Groups: {'mouse': 4.0}

Log-likelihood: -1606.683 	 AIC: 3227.366

Random effects:

              Name    Var    Std
mouse  (Intercept)  0.218  0.467
mouse          day  0.016  0.125

               IV1  IV2   Corr
mouse  (Intercept)  day -0.527

Fixed effects:

                    Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
(Intercept)           -0.018  -0.518    0.482  0.255  0.982      0.596
overlaps_MD_ED        -0.037  -0.504    0.430  0.238  0.964      0.604
day                    0.408   0.269    0.546  0.071  1.503      1.309
overlaps_MD_ED:day    -0.032  -0.160    0.095  0.065  0.968      0.853

                    OR_97.5_ci   Prob  Prob_2.5_ci  Prob_97.5_ci  Z-stat  \
(Intercept)              1.619  0.495        0.373         0.618  -0.071
overlaps_MD_ED           1.538  0.491        0.377         0.606  -0.154
day                      1.726  0.600        0.567         0.633   5.775
overlaps_MD_ED:day       1.100  0.492        0.460         0.524  -0.494

                    P-val  Sig
(Intercept)         0.943
overlaps_MD_ED      0.878
day                 0.000  ***
overlaps_MD_ED:day  0.621
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+.1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_58.png]]

**** Performance ~ overlaps * tasks

#+begin_src ipython
  formula = 'performance ~ tasks * overlaps_MD_ED  + (tasks | mouse)'

  data = df_dist.copy()
  # data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_MD_ED+(tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1886.853 	 AIC: 3797.706

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.354  0.595
mouse    tasksDualGo  0.072  0.269
mouse  tasksDualNoGo  0.014  0.119

               IV1            IV2   Corr
mouse  (Intercept)    tasksDualGo -0.319
mouse  (Intercept)  tasksDualNoGo -0.974
mouse  tasksDualGo  tasksDualNoGo  0.525

Fixed effects:

                              Estimate  2.5_ci  97.5_ci     SE     OR  \
(Intercept)                      1.546   0.999    2.094  0.279  4.694
tasksDualGo                     -0.341  -0.667   -0.014  0.166  0.711
tasksDualNoGo                   -0.144  -0.394    0.107  0.128  0.866
overlaps_MD_ED                  -0.534  -0.865   -0.203  0.169  0.586
tasksDualGo:overlaps_MD_ED       0.263  -0.164    0.690  0.218  1.301
tasksDualNoGo:overlaps_MD_ED     0.283  -0.164    0.731  0.228  1.327

                              OR_2.5_ci  OR_97.5_ci   Prob  Prob_2.5_ci  \
(Intercept)                       2.714       8.116  0.824        0.731
tasksDualGo                       0.513       0.986  0.416        0.339
tasksDualNoGo                     0.675       1.112  0.464        0.403
overlaps_MD_ED                    0.421       0.816  0.370        0.296
tasksDualGo:overlaps_MD_ED        0.849       1.993  0.565        0.459
tasksDualNoGo:overlaps_MD_ED      0.848       2.077  0.570        0.459

                              Prob_97.5_ci  Z-stat  P-val  Sig
(Intercept)                          0.890   5.534  0.000  ***
tasksDualGo                          0.496  -2.046  0.041    *
tasksDualNoGo                        0.527  -1.125  0.261
overlaps_MD_ED                       0.449  -3.165  0.002   **
tasksDualGo:overlaps_MD_ED           0.666   1.207  0.228
tasksDualNoGo:overlaps_MD_ED         0.675   1.240  0.215
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_60.png]]

**** Performance ~ overlaps * days * tasks

#+begin_src ipython
  formula = 'performance ~ day * tasks * overlaps_MD_ED  + (0 + day | mouse) + 0'

  data = df_dist.copy()
  # data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~day*tasks*overlaps_MD_ED+(0+day|mouse)+0

Family: binomial	 Inference: parametric

Number of observations: 3648	 Groups: {'mouse': 5.0}

Log-likelihood: -1761.203 	 AIC: 3548.406

Random effects:

      Name    Var    Std
mouse  day  0.038  0.196

No random effect correlations specified

Fixed effects:

                                  Estimate  2.5_ci  97.5_ci     SE     OR  \
day                                  0.573   0.369    0.777  0.104  1.774
tasksDPA                            -0.136  -0.449    0.176  0.159  0.872
tasksDualGo                         -0.252  -0.545    0.042  0.150  0.777
tasksDualNoGo                       -0.034  -0.338    0.269  0.155  0.966
overlaps_MD_ED                      -0.013  -0.734    0.709  0.368  0.987
day:tasksDualGo                     -0.078  -0.221    0.064  0.073  0.925
day:tasksDualNoGo                   -0.073  -0.220    0.074  0.075  0.929
day:overlaps_MD_ED                  -0.114  -0.345    0.117  0.118  0.893
tasksDualGo:overlaps_MD_ED          -0.492  -1.410    0.425  0.468  0.611
tasksDualNoGo:overlaps_MD_ED         0.325  -0.664    1.314  0.505  1.384
day:tasksDualGo:overlaps_MD_ED       0.224  -0.060    0.508  0.145  1.252
day:tasksDualNoGo:overlaps_MD_ED    -0.004  -0.313    0.305  0.158  0.996

                                  OR_2.5_ci  OR_97.5_ci   Prob  Prob_2.5_ci  \
day                                   1.446       2.176  0.639        0.591
tasksDPA                              0.638       1.193  0.466        0.390
tasksDualGo                           0.580       1.043  0.437        0.367
tasksDualNoGo                         0.713       1.309  0.491        0.416
overlaps_MD_ED                        0.480       2.032  0.497        0.324
day:tasksDualGo                       0.802       1.067  0.480        0.445
day:tasksDualNoGo                     0.802       1.076  0.482        0.445
day:overlaps_MD_ED                    0.708       1.124  0.472        0.415
tasksDualGo:overlaps_MD_ED            0.244       1.530  0.379        0.196
tasksDualNoGo:overlaps_MD_ED          0.515       3.720  0.580        0.340
day:tasksDualGo:overlaps_MD_ED        0.942       1.663  0.556        0.485
day:tasksDualNoGo:overlaps_MD_ED      0.731       1.356  0.499        0.422

                                  Prob_97.5_ci  Z-stat  P-val  Sig
day                                      0.685   5.496  0.000  ***
tasksDPA                                 0.544  -0.856  0.392
tasksDualGo                              0.510  -1.681  0.093    .
tasksDualNoGo                            0.567  -0.222  0.824
overlaps_MD_ED                           0.670  -0.035  0.972
day:tasksDualGo                          0.516  -1.076  0.282
day:tasksDualNoGo                        0.518  -0.977  0.328
day:overlaps_MD_ED                       0.529  -0.965  0.335
tasksDualGo:overlaps_MD_ED               0.605  -1.052  0.293
tasksDualNoGo:overlaps_MD_ED             0.788   0.644  0.520
day:tasksDualGo:overlaps_MD_ED           0.624   1.549  0.121
day:tasksDualNoGo:overlaps_MD_ED         0.576  -0.027  0.978
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

# Determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p < 0.1:
        return '.'
    else:
        return ''

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_62.png]]

**** Performance per day

#+begin_src ipython
results = []
formula = 'performance ~ tasks * overlaps_MD_ED  + (1 + tasks | mouse)'
for day in df_dist.day.unique():
  data = df_dist.copy()
  data = data[data.day==day]
  data = data[data.mouse!='JawsM18']
  data = data[data.mouse !='ACCM04']
  glm = Lmer(formula=formula, data=data, family='binomial')
  glm.fit();
  results.append(glm)
#+end_src

#+RESULTS:
#+begin_example
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_MD_ED+(1+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 768	 Groups: {'mouse': 3.0}

Log-likelihood: -491.143 	 AIC: 1006.287

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.096  0.311
mouse    tasksDualGo  0.021  0.145
mouse  tasksDualNoGo  0.000  0.009

               IV1            IV2  Corr
mouse  (Intercept)    tasksDualGo   1.0
mouse  (Intercept)  tasksDualNoGo  -1.0
mouse  tasksDualGo  tasksDualNoGo  -1.0

Fixed effects:
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_MD_ED+(1+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 768	 Groups: {'mouse': 3.0}

Log-likelihood: -291.946 	 AIC: 607.892

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.151  0.388
mouse    tasksDualGo  0.013  0.116
mouse  tasksDualNoGo  0.032  0.179

               IV1            IV2  Corr
mouse  (Intercept)    tasksDualGo   1.0
mouse  (Intercept)  tasksDualNoGo  -1.0
mouse  tasksDualGo  tasksDualNoGo  -1.0

Fixed effects:
Model failed to converge with max|grad| = 0.00551197 (tol = 0.002, component 1)

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~tasks*overlaps_MD_ED+(1+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 576	 Groups: {'mouse': 3.0}

Log-likelihood: -194.988 	 AIC: 413.977

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.251  0.501
mouse    tasksDualGo  0.002  0.047
mouse  tasksDualNoGo  0.038  0.194

               IV1            IV2   Corr
mouse  (Intercept)    tasksDualGo  0.999
mouse  (Intercept)  tasksDualNoGo -1.000
mouse  tasksDualGo  tasksDualNoGo -0.999

Fixed effects:
#+end_example

#+begin_src ipython
import pandas as pd

# Assuming you have the list of results from all sessions
combined_results = []

for i, result in enumerate(results):
    coefficients = {
        'coef': result.coefs['Estimate'],
        'lower_ci': result.coefs['2.5_ci'],
        'upper_ci': result.coefs['97.5_ci'],
        'p_value': result.coefs['P-val'],
        'Sig': result.coefs['Sig'],
        'day': df_dist.day.unique()[i]  # Add a session identifier
    }
    df_result = pd.DataFrame(coefficients)
    combined_results.append(df_result)

df_combined = pd.concat(combined_results)
#+end_src

#+RESULTS:

#+begin_src ipython
print(df_combined)
#+end_src

#+RESULTS:
#+begin_example
                                  coef  lower_ci  upper_ci       p_value  Sig  \
(Intercept)                   0.844239  0.384490  1.303987  3.193307e-04  ***
tasksDualGo                  -0.388374 -0.822313  0.045566  7.940334e-02    .
tasksDualNoGo                -0.064573 -0.471212  0.342066  7.556204e-01
overlaps_MD_ED               -0.405234 -1.159863  0.349394  2.925714e-01
tasksDualGo:overlaps_MD_ED    0.444396 -0.525808  1.414599  3.693192e-01
tasksDualNoGo:overlaps_MD_ED  0.474967 -0.556249  1.506183  3.666652e-01
(Intercept)                   2.495518  1.829005  3.162032  2.162070e-13  ***
tasksDualGo                  -1.059046 -1.685488 -0.432605  9.214694e-04  ***
tasksDualNoGo                -0.317807 -1.002601  0.366987  3.630325e-01
overlaps_MD_ED                0.715305 -0.629375  2.059986  2.971307e-01
tasksDualGo:overlaps_MD_ED   -1.287339 -2.894961  0.320282  1.165348e-01
tasksDualNoGo:overlaps_MD_ED -0.264164 -1.942503  1.414175  7.577088e-01
(Intercept)                   2.450735  1.626984  3.274486  5.507157e-09  ***
tasksDualGo                  -0.224050 -1.009082  0.560982  5.759035e-01
tasksDualNoGo                -0.620455 -1.384555  0.143645  1.114960e-01
overlaps_MD_ED               -0.943220 -1.902620  0.016179  5.399067e-02    .
tasksDualGo:overlaps_MD_ED    1.495875  0.349921  2.641829  1.051410e-02    *
tasksDualNoGo:overlaps_MD_ED  0.582070 -0.542338  1.706478  3.102915e-01

                                 day
(Intercept)                    first
tasksDualGo                    first
tasksDualNoGo                  first
overlaps_MD_ED                 first
tasksDualGo:overlaps_MD_ED     first
tasksDualNoGo:overlaps_MD_ED   first
(Intercept)                   middle
tasksDualGo                   middle
tasksDualNoGo                 middle
overlaps_MD_ED                middle
tasksDualGo:overlaps_MD_ED    middle
tasksDualNoGo:overlaps_MD_ED  middle
(Intercept)                     last
tasksDualGo                     last
tasksDualNoGo                   last
overlaps_MD_ED                  last
tasksDualGo:overlaps_MD_ED      last
tasksDualNoGo:overlaps_MD_ED    last
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# * Function to determine significance markers
def significance_marker(p):
    if p < 0.001:
        return '**'
    elif p < 0.01:
        return '*'
    elif p < 0.05:
        return '*'
    elif np.round(p, 2) == 0.05:
        return '.'
    else:
        return ''

# Set up the subplots
unique_coefs = df_combined.index.unique()
fig, axes = plt.subplots(nrows=len(unique_coefs) // 3, ncols=3, figsize=(width * 3, (len(unique_coefs) // 3 * height)), sharex=True, sharey=True)
axes = axes.flatten()

for coef, ax in zip(unique_coefs, axes):
    sub_df = df_combined.loc[coef].reset_index()  # Select data for the current coefficient

    sns.lineplot(x='day', y='coef', data=sub_df, ax=ax, marker='o')

    # Plotting the confidence intervals
    ax.fill_between(x=sub_df['day'], y1=sub_df['lower_ci'], y2=sub_df['upper_ci'], alpha=0.3)

    for idx in range(len(sub_df)):
        marker = significance_marker(sub_df.loc[idx, 'p_value'])
        if marker:
            ax.text(sub_df.loc[idx, 'day'], sub_df.loc[idx, 'coef'] + 1, marker, ha='center', fontsize=20, color='red')

    ax.set_title(f'{coef}', fontsize=14)
    ax.set_xlabel('Day')
    ax.set_ylabel('Coefficient Value')

fig.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[./figures/landscape/figure_62.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

*** Overlaps
**** Overlaps ~ day

#+begin_src ipython
  formula = 'overlaps_MD_ED ~ day + (1 + tasks | mouse)'

  data = df_dist.copy()
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse!='ACCM04']
  glm = Lmer(formula=formula, data=data, family='gaussian')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by REML [’lmerMod’]
Formula: overlaps_MD_ED~day+(1+tasks|mouse)

Family: gaussian	 Inference: parametric

Number of observations: 3072	 Groups: {'mouse': 4.0}

Log-likelihood: -2023.104 	 AIC: 4064.208

Random effects:

                   Name    Var    Std
mouse       (Intercept)  0.002  0.050
mouse       tasksDualGo  0.011  0.105
mouse     tasksDualNoGo  0.001  0.037
Residual                 0.217  0.466

               IV1            IV2   Corr
mouse  (Intercept)    tasksDualGo -0.994
mouse  (Intercept)  tasksDualNoGo -0.917
mouse  tasksDualGo  tasksDualNoGo  0.866

Fixed effects:

             Estimate  2.5_ci  97.5_ci     SE        DF  T-stat  P-val  Sig
(Intercept)     0.216   0.178    0.253  0.019  2720.891  11.208    0.0  ***
day            -0.063  -0.074   -0.053  0.005  3056.050 -11.697    0.0  ***
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)
df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+.1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_69.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

**** Overlaps ~ day * tasks

#+begin_src ipython
  formula = 'overlaps_MD_ED ~ 1 + day * tasks + (1 + tasks | mouse) '

  data = df_dist.copy()
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse!='ACCM04']
  glm = Lmer(formula=formula, data=data, family='gaussian')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
boundary (singular) fit: see help('isSingular')

Linear mixed model fit by REML [’lmerMod’]
Formula: overlaps_MD_ED~1+day*tasks+(1+tasks|mouse)

Family: gaussian	 Inference: parametric

Number of observations: 3072	 Groups: {'mouse': 4.0}

Log-likelihood: -1629.028 	 AIC: 3290.056

Random effects:

                   Name    Var    Std
mouse       (Intercept)  0.004  0.063
mouse       tasksDualGo  0.002  0.049
mouse     tasksDualNoGo  0.000  0.007
Residual                 0.166  0.408

               IV1            IV2  Corr
mouse  (Intercept)    tasksDualGo   1.0
mouse  (Intercept)  tasksDualNoGo  -1.0
mouse  tasksDualGo  tasksDualNoGo  -1.0

Fixed effects:

                         Estimate  2.5_ci  97.5_ci     SE        DF  T-stat  \
(Intercept)                 0.075   0.001    0.150  0.038     4.364   1.990
daylast                    -0.221  -0.286   -0.156  0.033  3047.519  -6.705
daymiddle                   0.002  -0.055    0.060  0.029  3059.956   0.082
tasksDualGo                 0.004  -0.071    0.079  0.038     7.477   0.103
tasksDualNoGo              -0.010  -0.068    0.048  0.030   226.713  -0.353
daylast:tasksDualGo         0.033  -0.059    0.124  0.047  3055.345   0.700
daymiddle:tasksDualGo      -0.007  -0.088    0.075  0.042  3059.956  -0.162
daylast:tasksDualNoGo      -0.004  -0.095    0.087  0.047  3059.868  -0.084
daymiddle:tasksDualNoGo    -0.002  -0.083    0.080  0.042  3059.956  -0.037

                         P-val  Sig
(Intercept)              0.112
daylast                  0.000  ***
daymiddle                0.935
tasksDualGo              0.921
tasksDualNoGo            0.725
daylast:tasksDualGo      0.484
daymiddle:tasksDualGo    0.872
daylast:tasksDualNoGo    0.933
daymiddle:tasksDualNoGo  0.970
#+end_example


#+RESULTS:

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+.1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_72.png]]

#+begin_src ipython

#+end_src
