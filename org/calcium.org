#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session calcium :kernel dual_data

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python

* Imports

#+begin_src ipython
  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  from scipy.stats import circmean
  from time import perf_counter

  import torch
  import torch.nn as nn
  import torch.optim as optim
  from skorch import NeuralNetClassifier

  from sklearn.base import clone
  from sklearn.model_selection import StratifiedKFold
  from sklearn.model_selection import cross_val_score, cross_validate
  from sklearn.ensemble import BaggingClassifier
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.pipeline import Pipeline
  from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, RepeatedStratifiedKFold, StratifiedKFold

  import statsmodels.api as sm
  import statsmodels.formula.api as smf
  import pandas as pd

  from mne.decoding import SlidingEstimator, cross_val_multiscore, GeneralizingEstimator
  from src.decode.my_mne import my_cross_val_multiscore
  from mne.decoding import SlidingEstimator, get_coef

  from src.common.plot_utils import add_vlines, add_vdashed
  from src.attractor.energy import run_energy, plot_energy
  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.decode.bump import decode_bump, circcvl
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.preprocess.helpers import avg_epochs

  import torch.optim as optim
  from torch.utils.data import Dataset, TensorDataset, DataLoader
#+end_src

#+RESULTS:

* Helpers
** Statistics
#+begin_src ipython
  from scipy.stats import bootstrap

  def get_bootstrap_ci(data, statistic=np.mean, confidence_level=0.95, n_resamples=1000, random_state=None):
      result = bootstrap((data,), statistic)
      ci_lower, ci_upper = result.confidence_interval
      return ci_lower, ci_upper
#+end_src

#+RESULTS:
* Data
** New setup
#+begin_src ipython
  from scipy.io import loadmat
  import mat73

  path = "/home/leon/dual_task/dual_data/data"
  mouse = "AP02"
  data = mat73.loadmat(path + "/" + mouse + "/dataProcessed.mat")
#+end_src

#+RESULTS:

#+begin_src ipython
  print(data.keys())
#+end_src

#+RESULTS:
: dict_keys(['AllAll', 'AllCorrect', 'AllWrong', 'CdecMean', 'CdecMeanAllNorm', 'CdecMeanNorm', 'CdecSEM', 'CdecSEMAllNorm', 'CdecSEMNorm', 'Cdec_Mice', 'Cdf_Mice', 'D1All', 'D1Correct', 'D1OffAll', 'D1OffCorrect', 'D1OffWrong', 'D1OnAll', 'D1OnCorrect', 'D1OnWrong', 'D1Wrong', 'D2All', 'D2Correct', 'D2OffAll', 'D2OffCorrect', 'D2OffWrong', 'D2OnAll', 'D2OnCorrect', 'D2OnWrong', 'D2Wrong', 'D3All', 'D3Correct', 'D3OffAll', 'D3OffCorrect', 'D3OffWrong', 'D3OnAll', 'D3OnCorrect', 'D3OnWrong', 'D3Wrong', 'D4All', 'D4Correct', 'D4OffAll', 'D4OffCorrect', 'D4OffWrong', 'D4OnAll', 'D4OnCorrect', 'D4OnWrong', 'D4Wrong', 'DD1All', 'DD1Correct', 'DD1OffAll', 'DD1OffCorrect', 'DD1OffWrong', 'DD1OnAll', 'DD1OnCorrect', 'DD1OnWrong', 'DD1Wrong', 'DD2All', 'DD2Correct', 'DD2OffAll', 'DD2OffCorrect', 'DD2OffWrong', 'DD2OnAll', 'DD2OnCorrect', 'DD2OnWrong', 'DD2Wrong', 'DD3All', 'DD3Correct', 'DD3OffAll', 'DD3OffCorrect', 'DD3OffWrong', 'DD3OnAll', 'DD3OnCorrect', 'DD3OnWrong', 'DD3Wrong', 'DD4All', 'DD4Correct', 'DD4OffAll', 'DD4OffCorrect', 'DD4OffWrong', 'DD4OnAll', 'DD4OnCorrect', 'DD4OnWrong', 'DD4Wrong', 'DRTAll', 'DRTCorrect', 'DRTOffAll', 'DRTOffCorrect', 'DRTOffWrong', 'DRTOnAll', 'DRTOnCorrect', 'DRTOnWrong', 'DRTWrong', 'DistAll', 'DistCorrect', 'DistOffAll', 'DistOffCorrect', 'DistOffWrong', 'DistOnAll', 'DistOnCorrect', 'DistOnWrong', 'DistWrong', 'FR_Trial', 'NDAll', 'NDCorrect', 'NDOffAll', 'NDOffCorrect', 'NDOffWrong', 'NDOnAll', 'NDOnCorrect', 'NDOnWrong', 'NDWrong', 'OffAll', 'OffCorrect', 'OffWrong', 'OnAll', 'OnCorrect', 'OnWrong', 'S1All', 'S1Correct', 'S1D1All', 'S1D1Correct', 'S1D1OffAll', 'S1D1OffCorrect', 'S1D1OffWrong', 'S1D1OnAll', 'S1D1OnCorrect', 'S1D1OnWrong', 'S1D1Wrong', 'S1D2All', 'S1D2Correct', 'S1D2OffAll', 'S1D2OffCorrect', 'S1D2OffWrong', 'S1D2OnAll', 'S1D2OnCorrect', 'S1D2OnWrong', 'S1D2Wrong', 'S1D3All', 'S1D3Correct', 'S1D3OffAll', 'S1D3OffCorrect', 'S1D3OffWrong', 'S1D3OnAll', 'S1D3OnCorrect', 'S1D3OnWrong', 'S1D3Wrong', 'S1D4All', 'S1D4Correct', 'S1D4OffAll', 'S1D4OffCorrect', 'S1D4OffWrong', 'S1D4OnAll', 'S1D4OnCorrect', 'S1D4OnWrong', 'S1D4Wrong', 'S1DistAll', 'S1DistCorrect', 'S1DistOffAll', 'S1DistOffCorrect', 'S1DistOffWrong', 'S1DistOnAll', 'S1DistOnCorrect', 'S1DistOnWrong', 'S1DistWrong', 'S1NDAll', 'S1NDCorrect', 'S1NDOffAll', 'S1NDOffCorrect', 'S1NDOffWrong', 'S1NDOnAll', 'S1NDOnCorrect', 'S1NDOnWrong', 'S1NDWrong', 'S1OffAll', 'S1OffCorrect', 'S1OffWrong', 'S1OnAll', 'S1OnCorrect', 'S1OnWrong', 'S1Wrong', 'S2All', 'S2Correct', 'S2D1All', 'S2D1Correct', 'S2D1OffAll', 'S2D1OffCorrect', 'S2D1OffWrong', 'S2D1OnAll', 'S2D1OnCorrect', 'S2D1OnWrong', 'S2D1Wrong', 'S2D2All', 'S2D2Correct', 'S2D2OffAll', 'S2D2OffCorrect', 'S2D2OffWrong', 'S2D2OnAll', 'S2D2OnCorrect', 'S2D2OnWrong', 'S2D2Wrong', 'S2D3All', 'S2D3Correct', 'S2D3OffAll', 'S2D3OffCorrect', 'S2D3OffWrong', 'S2D3OnAll', 'S2D3OnCorrect', 'S2D3OnWrong', 'S2D3Wrong', 'S2D4All', 'S2D4Correct', 'S2D4OffAll', 'S2D4OffCorrect', 'S2D4OffWrong', 'S2D4OnAll', 'S2D4OnCorrect', 'S2D4OnWrong', 'S2D4Wrong', 'S2DistAll', 'S2DistCorrect', 'S2DistOffAll', 'S2DistOffCorrect', 'S2DistOffWrong', 'S2DistOnAll', 'S2DistOnCorrect', 'S2DistOnWrong', 'S2DistWrong', 'S2NDAll', 'S2NDCorrect', 'S2NDOffAll', 'S2NDOffCorrect', 'S2NDOffWrong', 'S2NDOnAll', 'S2NDOnCorrect', 'S2NDOnWrong', 'S2NDWrong', 'S2OffAll', 'S2OffCorrect', 'S2OffWrong', 'S2OnAll', 'S2OnCorrect', 'S2OnWrong', 'S2Wrong', 'S3All', 'S3Correct', 'S3D1All', 'S3D1Correct', 'S3D1OffAll', 'S3D1OffCorrect', 'S3D1OffWrong', 'S3D1OnAll', 'S3D1OnCorrect', 'S3D1OnWrong', 'S3D1Wrong', 'S3D2All', 'S3D2Correct', 'S3D2OffAll', 'S3D2OffCorrect', 'S3D2OffWrong', 'S3D2OnAll', 'S3D2OnCorrect', 'S3D2OnWrong', 'S3D2Wrong', 'S3D3All', 'S3D3Correct', 'S3D3OffAll', 'S3D3OffCorrect', 'S3D3OffWrong', 'S3D3OnAll', 'S3D3OnCorrect', 'S3D3OnWrong', 'S3D3Wrong', 'S3D4All', 'S3D4Correct', 'S3D4OffAll', 'S3D4OffCorrect', 'S3D4OffWrong', 'S3D4OnAll', 'S3D4OnCorrect', 'S3D4OnWrong', 'S3D4Wrong', 'S3DistAll', 'S3DistCorrect', 'S3DistOffAll', 'S3DistOffCorrect', 'S3DistOffWrong', 'S3DistOnAll', 'S3DistOnCorrect', 'S3DistOnWrong', 'S3DistWrong', 'S3NDAll', 'S3NDCorrect', 'S3NDOffAll', 'S3NDOffCorrect', 'S3NDOffWrong', 'S3NDOnAll', 'S3NDOnCorrect', 'S3NDOnWrong', 'S3NDWrong', 'S3OffAll', 'S3OffCorrect', 'S3OffWrong', 'S3OnAll', 'S3OnCorrect', 'S3OnWrong', 'S3Wrong', 'S4All', 'S4Correct', 'S4D1All', 'S4D1Correct', 'S4D1OffAll', 'S4D1OffCorrect', 'S4D1OffWrong', 'S4D1OnAll', 'S4D1OnCorrect', 'S4D1OnWrong', 'S4D1Wrong', 'S4D2All', 'S4D2Correct', 'S4D2OffAll', 'S4D2OffCorrect', 'S4D2OffWrong', 'S4D2OnAll', 'S4D2OnCorrect', 'S4D2OnWrong', 'S4D2Wrong', 'S4D3All', 'S4D3Correct', 'S4D3OffAll', 'S4D3OffCorrect', 'S4D3OffWrong', 'S4D3OnAll', 'S4D3OnCorrect', 'S4D3OnWrong', 'S4D3Wrong', 'S4D4All', 'S4D4Correct', 'S4D4OffAll', 'S4D4OffCorrect', 'S4D4OffWrong', 'S4D4OnAll', 'S4D4OnCorrect', 'S4D4OnWrong', 'S4D4Wrong', 'S4DistAll', 'S4DistCorrect', 'S4DistOffAll', 'S4DistOffCorrect', 'S4DistOffWrong', 'S4DistOnAll', 'S4DistOnCorrect', 'S4DistOnWrong', 'S4DistWrong', 'S4NDAll', 'S4NDCorrect', 'S4NDOffAll', 'S4NDOffCorrect', 'S4NDOffWrong', 'S4NDOnAll', 'S4NDOnCorrect', 'S4NDOnWrong', 'S4NDWrong', 'S4OffAll', 'S4OffCorrect', 'S4OffWrong', 'S4OnAll', 'S4OnCorrect', 'S4OnWrong', 'S4Wrong', 'basBin', 'basFrame', 'binNum', 'binNumDRT', 'blockPerDay', 'datePath', 'delayBin', 'delayBinDRT', 'delayFrame', 'delayFrameDRT', 'delayPeriodBin', 'delayPeriodFrame', 'frameNum', 'frameNumDRT', 'frameRate', 'laserTag', 'lifeSpar', 'lifeSparAllNorm', 'lifeSparNorm', 'miceNum', 'neuronSource', 'periodBin', 'periodBinDRT', 'periodFrame', 'periodFrameDRT', 'rewardBin', 'rewardFrame', 'sampleBin', 'sampleFrame', 'task', 'testBin', 'testFrame', 'trialMice', 'trialPerBlock', 'trialPerDay'])

#+begin_src ipython
print(data['trialPerBlock']*2)
print(data['trialPerDay'])
print(data['trialMice'])
print(data['blockPerDay'])
print(2*176)
#+end_src

#+RESULTS:
: 176.0
: 176.0
: 176.0
: 2.0
: 352

#+begin_src ipython
print(len(data['S1All'][0]))
print(len(data['S2All'][0]))
print(len(data['S3All'][0]))
print(len(data['S4All'][0]))
#+end_src

#+RESULTS:
: 420
: 420
: 420
: 420

#+begin_src ipython
84*5
#+end_src

#+RESULTS:
: 420

#+begin_src ipython
print(len(data['S1NDAll'][0]))
print(len(data['S2NDAll'][0]))
print(len(data['S3NDAll'][0]))
print(len(data['S4NDAll'][0]))
#+end_src

#+RESULTS:
: 84
: 84
: 84
: 84

#+begin_src ipython
print(len(data['S1D1All'][0]))
print(len(data['S2D2All'][0]))
print(len(data['S3D3All'][0]))
print(data['S4D4All'][0])
#+end_src

#+RESULTS:
: 84
: 84
: 84
: [  43.   64.   70.   75.  119.  140.  156.  170.  210.  228.  245.  259.
:   272.  285.  293.  342.  376.  392.  398.  406.  465.  471.  496.  517.
:   564.  581.  591.  603.  618.  629.  646.  698.  708.  719.  755.  768.
:   820.  835.  848.  865.  881.  895.  906.  910.  972. 1001. 1033. 1039.
:  1072. 1115. 1134. 1136. 1153. 1154. 1184. 1202. 1265. 1281. 1297. 1300.
:  1326. 1379. 1388. 1400. 1422. 1438. 1440. 1447. 1498. 1532. 1539. 1580.
:  1591. 1630. 1658. 1668. 1696. 1700. 1708. 1751. 1771. 1786. 1802. 1848.]

#+begin_src ipython
print(len(data['D1All'][0]))
print(len(data['D2All'][0]))
print(len(data['D3All'][0]))
print(len(data['D4All'][0]))
#+end_src

#+RESULTS:
: 336
: 336
: 336
: 336

#+begin_src ipython
print(np.sum(data['S1DistAll'][0]==data['D1All'][0]))
#+end_src

#+RESULTS:
: 22

#+begin_src ipython
print(data['D4All'])
#+end_src

#+RESULTS:
#+begin_example
[array([   2.,    4.,   17.,   19.,   31.,   38.,   43.,   45.,   59.,
         64.,   70.,   72.,   75.,   76.,   77.,   86.,   91.,  112.,
        119.,  128.,  133.,  137.,  138.,  140.,  143.,  150.,  152.,
        153.,  156.,  162.,  170.,  175.,  186.,  192.,  197.,  199.,
        210.,  215.,  218.,  226.,  227.,  228.,  244.,  245.,  251.,
        259.,  262.,  263.,  272.,  276.,  279.,  280.,  285.,  293.,
        302.,  303.,  306.,  310.,  315.,  319.,  322.,  334.,  337.,
        342.,  355.,  357.,  359.,  363.,  372.,  376.,  388.,  392.,
        398.,  401.,  405.,  406.,  408.,  412.,  415.,  440.,  459.,
        464.,  465.,  466.,  471.,  478.,  481.,  486.,  495.,  496.,
        497.,  499.,  502.,  512.,  517.,  528.,  533.,  535.,  551.,
        560.,  562.,  564.,  567.,  573.,  575.,  578.,  581.,  582.,
        591.,  598.,  601.,  603.,  618.,  619.,  629.,  631.,  640.,
        642.,  646.,  652.,  654.,  664.,  665.,  669.,  687.,  694.,
        695.,  698.,  708.,  710.,  716.,  717.,  719.,  723.,  730.,
        731.,  755.,  760.,  768.,  770.,  773.,  776.,  777.,  781.,
        794.,  799.,  800.,  811.,  820.,  824.,  827.,  829.,  835.,
        846.,  848.,  850.,  859.,  865.,  867.,  878.,  881.,  885.,
        887.,  891.,  892.,  895.,  896.,  904.,  906.,  910.,  917.,
        925.,  933.,  945.,  961.,  968.,  972.,  975.,  979.,  984.,
        986.,  988.,  991.,  996., 1001., 1004., 1006., 1022., 1033.,
       1039., 1048., 1055., 1069., 1072., 1075., 1092., 1093., 1097.,
       1104., 1114., 1115., 1118., 1122., 1124., 1128., 1134., 1136.,
       1144., 1145., 1153., 1154., 1161., 1164., 1171., 1176., 1181.,
       1184., 1191., 1192., 1196., 1200., 1202., 1218., 1220., 1235.,
       1236., 1237., 1238., 1243., 1245., 1248., 1259., 1265., 1270.,
       1281., 1286., 1288., 1297., 1298., 1300., 1323., 1326., 1327.,
       1338., 1343., 1345., 1366., 1368., 1379., 1385., 1387., 1388.,
       1394., 1397., 1400., 1403., 1422., 1425., 1434., 1438., 1440.,
       1442., 1445., 1447., 1452., 1464., 1470., 1473., 1481., 1489.,
       1491., 1493., 1498., 1510., 1519., 1526., 1527., 1528., 1530.,
       1532., 1533., 1539., 1540., 1551., 1553., 1572., 1579., 1580.,
       1586., 1591., 1592., 1593., 1606., 1609., 1614., 1627., 1630.,
       1632., 1639., 1646., 1650., 1653., 1658., 1668., 1686., 1688.,
       1690., 1695., 1696., 1700., 1701., 1703., 1705., 1708., 1717.,
       1722., 1725., 1744., 1751., 1757., 1766., 1770., 1771., 1786.,
       1792., 1795., 1802., 1810., 1815., 1827., 1829., 1836., 1838.,
       1842., 1847., 1848.])]
#+end_example

** ACC
#+begin_src ipython
  from scipy.io import loadmat

  path = "/home/leon/dual_task/dual_data/data"
  mouse = "ACCM03"
  data = loadmat(path + "/" + mouse + "/SamedROI/" + mouse + "_all_days" + ".mat")
#+end_src

#+RESULTS:

#+begin_src ipython
  print(data.keys())
#+end_src

#+RESULTS:
:RESULTS:
dict_keys(['__header__', '__version__', '__globals__', 'FR_Trial', 'basFrame', 'blockPerDay', 'delayFrame', 'delayPeriodFrame', 'frameRate', 'laserTag', 'rewardFrame', 'sampleFrame', 'testFrame', 'trialPerBlock', 'dff_Mice', 'Cdf_Mice', 'Events', 'trialPerDay'])
:END:

#+begin_src ipython
  print(data['Events'].shape[0]/192)
#+end_src

#+RESULTS:
:RESULTS:
5.0
:END:

#+begin_src ipython
  print(data['blockPerDay'])
  print(data['trialPerBlock'])
  print(data['trialPerDay'])
#+end_src

#+RESULTS:
:RESULTS:
[[4]]
[[48]]
[[192]]
:END:

#+begin_src ipython
  print(data['dff_Mice'].shape)
#+end_src

#+RESULTS:
:RESULTS:
(361, 960, 84)
:END:

#+begin_src ipython
  print(data['Events'])
#+end_src

#+RESULTS:
:RESULTS:
[[17 12  3 ...  0  0  0]
 [18 12  1 ...  0  0  0]
 [17 11  1 ...  0  0  0]
 ...
 [17 11  1 ...  0  0  0]
 [18 11  4 ...  0  0  0]
 [17 12  4 ...  0  0  0]]
:END:

#+begin_src ipython
  print(np.sum(data['Events'][:, 4]==0))
#+end_src

#+RESULTS:
:RESULTS:
320
:END:

* Parameters

#+begin_src ipython
  DEVICE = 'cuda:1'
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  tasks = ['DPA', 'DualGo', 'DualNoGo']

  kwargs = {
      'mouse': 'JawsM15',
      'trials': '', 'reload': 0, 'data_type': 'dF', 'preprocess': True,
      'scaler_BL': None, 'avg_noise':True, 'unit_var_BL':False,
      'random_state': None, 'T_WINDOW': 0.0,
      'l1_ratio': 0.95, 'DCVL': 0
  }

  options = set_options(**kwargs)
#+end_src

#+RESULTS:

#+begin_src ipython
    X_days, y_days = get_X_y_days(**options)
    y_days['tasks'] = y_days['tasks'].astype('category')
    #  y_days = y_days[y_days['laser']==0]
    print('X', X_days.shape, 'y', y_days.shape)
    print(y_days.keys())
#+end_src

#+RESULTS:
: X (1152, 693, 84) y (1152, 6)
: Index(['sample_odor', 'test_odor', 'response', 'tasks', 'laser', 'day'], dtype='object')

* Activity timing

#+begin_src ipython
  day = 5
  options['day'] = day
  options['task'] = 'DualGo'
  options['T_WINDOW'] = 0.0

  X_data, y_data = get_X_y_S1_S2(X_days, y_days, **options)
  print('data', X_data.shape)

  size = X_data.shape[0] // 2
  X = X_data[:, :, options['bins_LD']].mean(0)
  print('X', X.shape)
  peak_times = np.argmax(X, axis=1)
  idx = np.argsort(peak_times)

  # options['epochs'] = ['LD']
  # X_avg = avg_epochs(X_data, **options).astype('float32').mean(0)
  # idx = np.argsort(X_avg)
  # print(idx.shape)
#+end_src

#+RESULTS:
: DATA: FEATURES sample TASK DualGo TRIALS  DAYS 5 LASER 0
: data (64, 361, 84)
: X (361, 9)

#+begin_src ipython
  fig, ax = plt.subplots(2, 3, figsize=0.75 * np.array([3 * width, 2 * height]))

  size = X_data.shape[0]

  for i in range(options['n_days'] // 2):
      options['day'] = i+1
      X_data, y_data = get_X_y_S1_S2(X_days, y_days, **options)

      data = circcvl(np.nanmean(X_data[:size, idx], 0), windowSize=2, axis=0)

      ax[0][i].imshow(data,
                      aspect='auto', cmap='viridis',
                      extent=[0, 14, 0, 693],
                      vmin=-0.5, vmax=1.0,
                      )

      add_vlines(ax=ax[0][i])
      add_vlines(ax=ax[0][i])
      add_vlines(ax=ax[0][i])

  for i in range(options['n_days'] // 2, options['n_days']):
      options['day'] = i+1
      X_data, y_data = get_X_y_S1_S2(X_days, y_days, **options)

      data = circcvl(np.nanmean(X_data[:size, idx], 0), windowSize=2, axis=0)
      ax[1][i-3].imshow(data,
                        aspect='auto', cmap='viridis',
                        extent=[0, 14, 0, 693],
                        vmin=-0.5, vmax=1.0,
                      )
      add_vlines(ax=ax[1][i-3])
      add_vlines(ax=ax[1][i-3])
      add_vlines(ax=ax[1][i-3])
  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: DATA: FEATURES sample TASK DualGo TRIALS  DAYS 1 LASER 0
: DATA: FEATURES sample TASK DualGo TRIALS  DAYS 2 LASER 0
: DATA: FEATURES sample TASK DualGo TRIALS  DAYS 3 LASER 0
: DATA: FEATURES sample TASK DualGo TRIALS  DAYS 4 LASER 0
: DATA: FEATURES sample TASK DualGo TRIALS  DAYS 5 LASER 0
[[file:./.ob-jupyter/f3aa81ebfbc41c31fa5444e0079f314d04638bc9.png]]
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

* GLM vs Days

#+begin_src ipython
    X_days, y_days = get_X_y_days(**options)
    y_days['tasks'] = y_days['tasks'].astype('category')
    #  y_days = y_days[y_days['laser']==0]
    print('X', X_days.shape, 'y', y_days.shape)
    print(y_days.keys())
#+end_src

#+RESULTS:
: X (1152, 693, 84) y (1152, 6)
: Index(['sample_odor', 'test_odor', 'response', 'tasks', 'laser', 'day'], dtype='object')

X_days is an np array (trials x neurons x timesteps)

#+begin_src ipython
plt.plot(X_days[0, 0])
plt.xlabel('time')
plt.ylabel('DF')
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/470aabe3edaeecfcba220951a3f3220a2919c6bc.png]]

#+begin_src ipython
print(y_days.head())
#+end_src

#+RESULTS:
:    sample_odor  test_odor      response     tasks  laser  day
: 0          0.0        1.0   correct_rej  DualNoGo    0.0  1.0
: 1          1.0        0.0  incorrect_fa  DualNoGo    1.0  1.0
: 2          1.0        0.0   correct_rej    DualGo    0.0  1.0
: 3          0.0        0.0   correct_hit    DualGo    0.0  1.0
: 4          1.0        1.0   correct_hit  DualNoGo    1.0  1.0

#+begin_src ipython
  options['epochs'] = ['ED']
  X_avg = avg_epochs(X_days, **options).astype('float32')
  print('X_avg', X_avg.shape)
  #+end_src

#+RESULTS:
: X_avg (960, 361)

  #+begin_src ipython
    formula = 'df ~ sample_odor * tasks'
    options['task'] = 'DPA'

    results = []
    for day in range(1, 2): # , options['n_days']+1):
            options['day'] = day
            X, y = get_X_y_S1_S2(X_days, y_days, **options)
            res = []

            # data = y_days
            data = y_days[(y_days['day'] == day) & (y_days['laser']==0) & (y_days['tasks']=='DPA')]
            # print(data.shape)

            for neuron in range(1): #, X_avg.shape[1]): # over neurons
                for time in range(1): #, X_avg.shape[-1]):  # over time
                    data.loc[:, ['df']] = X[:, neuron, time]
                    print(data.head())
                    # glm_gauss = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())
                    # res.append(glm_gauss.fit())

            results.append(res)
#+end_src

#+RESULTS:
: X_S1 (16, 693, 84) X_S2 (16, 693, 84)
:     sample_odor  test_odor        response tasks  laser  day        df
: 5           0.0        1.0     correct_rej   DPA    0.0  1.0 -0.113828
: 8           0.0        0.0  incorrect_miss   DPA    0.0  1.0 -0.042089
: 14          1.0        1.0     correct_hit   DPA    0.0  1.0  0.089193
: 21          1.0        0.0    incorrect_fa   DPA    0.0  1.0 -0.014657
: 25          1.0        1.0     correct_hit   DPA    0.0  1.0 -0.004175

#+begin_src ipython
  results = np.array(results)
#+end_src

#+RESULTS:

#+begin_src ipython
  print(results[0][2].summary())
#+end_src

#+RESULTS:
#+begin_example
                   Generalized Linear Model Regression Results
  ==============================================================================
  Dep. Variable:                     df   No. Observations:                   64
  Model:                            GLM   Df Residuals:                       62
  Model Family:                Gaussian   Df Model:                            1
  Link Function:               Identity   Scale:                          5.3946
  Method:                          IRLS   Log-Likelihood:                -143.73
  Date:                Mon, 22 Jul 2024   Deviance:                       334.46
  Time:                        13:01:05   Pearson chi2:                     334.
  No. Iterations:                     3   Pseudo R-squ. (CS):           0.009346
  Covariance Type:            nonrobust
  =================================================================================================
                                      coef    std err          z      P>|z|      [0.025      0.975]
  -------------------------------------------------------------------------------------------------
  Intercept                         0.3405      0.411      0.829      0.407      -0.464       1.145
  tasks[T.DualGo]                        0          0        nan        nan           0           0
  tasks[T.DualNoGo]                      0          0        nan        nan           0           0
  sample_odor                      -0.4380      0.581     -0.754      0.451      -1.576       0.700
  sample_odor:tasks[T.DualGo]            0          0        nan        nan           0           0
  sample_odor:tasks[T.DualNoGo]          0          0        nan        nan           0           0
  =================================================================================================
#+end_example

  #+begin_src ipython
    selective = []
    beta = []
    for day in range(options['n_days']):
        sel = []
        bet = []
        for neuron in range(X_avg.shape[1]-1):
            p_value = results[day, neuron].pvalues['sample_odor']
            if p_value < 0.05:
                sel.append(neuron)
            bet.append(results[day, neuron].params['sample_odor'])
        selective.append(sel)
        beta.append(bet)
#+end_src

#+RESULTS:

#+begin_src ipython
  print(selective[0])
  print(selective[-1])
#+end_src

#+RESULTS:
: [19, 110, 113, 129, 134, 148, 154, 170, 210, 229, 244, 268, 306, 333, 341]
: [22, 79, 80, 104, 158, 227, 233, 252, 253, 265, 282, 290]

#+begin_src ipython
  sparse = []
  for i in range(options['n_days']):
      sparse.append(len(selective[i]))
  #+end_src

#+RESULTS:

#+begin_src ipython
  plt.plot(sparse)
#+end_src

#+RESULTS:
:RESULTS:
| <matplotlib.lines.Line2D | at | 0x7f0220323c90> |
[[file:./.ob-jupyter/b78490388854279e38e76d5bfd1dc5b8113d5a6f.png]]
:END:

#+begin_src ipython
  print(beta[0])
  print(beta[-1])
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: IndexError                                Traceback (most recent call last)
: Cell In[135], line 1
: ----> 1 print(beta[0])
:       2 print(beta[-1])
:
: IndexError: list index out of range
:END:

#+begin_src ipython
  idx = np.array(beta[-1]).argsort()
  # print(np.array(beta[-1])[idx])
#+end_src

#+RESULTS:

#+begin_src ipython
  day = options['n_days']
  options['day'] = day
  fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
  X_data, y_data = get_X_y_S1_S2(X_days, y_days, **options)
  print(X_data.shape)

  size = X_data.shape[0] // 2

  data = circcvl(np.nanmean(X_data[:size, idx], 0), windowSize=10, axis=0)

  ax[0].imshow(data,
            aspect='auto', cmap='jet',
            extent=[0, 14, 0, len(selective[day-1])],
            vmin=-0.5, vmax=1.5,
            interpolation='lanczos')

  data = circcvl(np.nanmean(X_data[size:, idx], 0), windowSize=10, axis=0)

  ax[1].imshow(data,
            aspect='auto', cmap='jet',
            extent=[0, 14, 0, len(selective[day-1])],
            vmin=-0.5, vmax=1.5,
            interpolation='lanczos')

  # add_vdashed(ax)
  # cb = ax.set_colorbar()
  # cb.set_label('$\Delta F / F$')

  ax[0].set_xticks(np.arange(0, 16, 4))
  ax[0].set_xlabel('Time')
  ax[0].set_ylabel('Neuron')

  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: DATA: FEATURES sample TASK DPA TRIALS  DAYS 5 LASER 0
: (64, 361, 84)
[[file:./.ob-jupyter/5e826e58a48536e59f48d5b0c7a35df223775132.png]]
:END:

#+begin_src ipython
  fig, ax = plt.subplots(2, 3, figsize=0.75 * np.array([3 * width, 2 * height]))

  size = X_data.shape[0]

  for i in range(options['n_days'] // 2):
      options['day'] = i+1
      X_data, y_data = get_X_y_S1_S2(X_days, y_days, **options)

      data = circcvl(np.nanmean(X_data[:size, idx], 0), windowSize=10, axis=0)

      ax[0][i].imshow(data,
                      aspect='auto', cmap='jet',
                      extent=[0, 14, 0, 693],
                      vmin=-0.5, vmax=1.5,
                      )

      add_vlines(ax=ax[0][i])
      add_vlines(ax=ax[0][i])
      add_vlines(ax=ax[0][i])

  for i in range(options['n_days'] // 2, options['n_days']):
      options['day'] = i+1
      X_data, y_data = get_X_y_S1_S2(X_days, y_days, **options)

      data = circcvl(np.nanmean(X_data[:size, idx], 0), windowSize=10, axis=0)
      ax[1][i-3].imshow(data,
                        aspect='auto', cmap='jet',
                        extent=[0, 14, 0, 693],
                        vmin=-0.5, vmax=1.5,
                      )
      add_vlines(ax=ax[1][i-3])
      add_vlines(ax=ax[1][i-3])
      add_vlines(ax=ax[1][i-3])
  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: DATA: FEATURES sample TASK DPA TRIALS  DAYS 1 LASER 0
: DATA: FEATURES sample TASK DPA TRIALS  DAYS 2 LASER 0
: DATA: FEATURES sample TASK DPA TRIALS  DAYS 3 LASER 0
: DATA: FEATURES sample TASK DPA TRIALS  DAYS 4 LASER 0
: DATA: FEATURES sample TASK DPA TRIALS  DAYS 5 LASER 0
[[file:./.ob-jupyter/4b4e4167916aef7828483f297a53c40c09e94c45.png]]
:END:

* Data

#+begin_src ipython
  X_days, y_days = get_X_y_days(**options)
  y_days['tasks'] = y_days['tasks'].astype('category')
  # y_days = y_days[y_days['laser']==0]

  options['day'] = 1
  X_data, y_data = get_X_y_S1_S2(X_days, y_days, **options)
#+end_src

#+RESULTS:
#+begin_example
  Reading data from source file
  mouse JawsM15 n_days 6 day 1 type dF all data: X (192, 693, 84) y (9, 192)
  mouse JawsM15 n_days 6 day 2 type dF all data: X (192, 693, 84) y (9, 192)
  mouse JawsM15 n_days 6 day 3 type dF all data: X (192, 693, 84) y (9, 192)
  mouse JawsM15 n_days 6 day 4 type dF all data: X (192, 693, 84) y (9, 192)
  mouse JawsM15 n_days 6 day 5 type dF all data: X (192, 693, 84) y (9, 192)
  mouse JawsM15 n_days 6 day 6 type dF all data: X (192, 693, 84) y (9, 192)
  ##########################################
  PREPROCESSING: SCALER None AVG MEAN False AVG NOISE True UNIT VAR False
  ##########################################
  DATA: FEATURES sample TASK DualGo TRIALS  DAYS 1 LASER 0
#+end_example

  #+begin_src ipython
  plt.plot(X_data[:10, 1].T, alpha=.5)
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/18c1919442723cfcc0b6bc34b542eb35c8041ca7.png]]

* GLM

#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf
  import pandas as pd
#+end_src

#+RESULTS:

#+begin_src ipython
  print(X_days.shape, y_days.shape)
#+end_src

#+RESULTS:
: (1152, 693, 84) (1152, 6)

#+begin_src ipython
  print(y_days.keys())
#+end_src

#+RESULTS:
: Index(['sample_odor', 'test_odor', 'response', 'tasks', 'laser', 'day'], dtype='object')

#+begin_src ipython
  print(X_data.shape, y_data.shape)
#+end_src

#+RESULTS:
: (32, 693, 84) (32,)

#+begin_src ipython
  print(X_days.shape)
#+end_src

#+RESULTS:
: (1152, 693, 84)

#+begin_src ipython
  data = y_days

  options['epochs'] = ['ED']
  X_avg = avg_epochs(X_days, **options).astype('float32')
  print(X_avg.shape)

  data['df'] = X_avg[:, 0]
  data['tasks'] = data['tasks'].astype('category')
  print(data.keys())
#+end_src

#+RESULTS:
: (1152, 693)
: Index(['sample_odor', 'test_odor', 'response', 'tasks', 'laser', 'day', 'df'], dtype='object')

#+begin_src ipython
  print(data['tasks'].head())
#+end_src

#+RESULTS:
: 0    DualNoGo
: 1    DualNoGo
: 2      DualGo
: 3      DualGo
: 4    DualNoGo
: Name: tasks, dtype: category
: Categories (3, object): ['DPA', 'DualGo', 'DualNoGo']

#+begin_src ipython
  #  Specify the formula
  formula = 'df ~ sample_odor * tasks'
#+end_src

#+RESULTS:

#+begin_src ipython
  results = []
  for neuron in range(X_avg.shape[1]):
      data['df'] = X_avg[:, neuron]
      glm_gauss = smf.glm(formula=formula, data=data, family=sm.families.Poisson(link=sm.families.links.log()))
      # glm_gauss = smf.glm(formula=formula, data=data, family=sm.families.Gaussian())
      results.append(glm_gauss.fit())
#+end_src

#+RESULTS:

#+begin_src ipython
  #  Output the summary of the model
  print(results[3].summary())
#+end_src

#+RESULTS:
#+begin_example
                   Generalized Linear Model Regression Results
  ==============================================================================
  Dep. Variable:                     df   No. Observations:                 1152
  Model:                            GLM   Df Residuals:                     1146
  Model Family:                 Poisson   Df Model:                            5
  Link Function:                    log   Scale:                          1.0000
  Method:                          IRLS   Log-Likelihood:                -92.189
  Date:                Mon, 15 Jul 2024   Deviance:                       78.499
  Time:                        17:45:21   Pearson chi2:                     231.
  No. Iterations:                     6   Pseudo R-squ. (CS):          0.0005789
  Covariance Type:            nonrobust
  =================================================================================================
                                      coef    std err          z      P>|z|      [0.025      0.975]
  -------------------------------------------------------------------------------------------------
  Intercept                        -4.0236      0.540     -7.457      0.000      -5.081      -2.966
  tasks[T.DualGo]                   0.0967      0.745      0.130      0.897      -1.364       1.557
  tasks[T.DualNoGo]                 0.1371      0.738      0.186      0.853      -1.310       1.584
  sample_odor                      -0.4792      0.873     -0.549      0.583      -2.189       1.231
  sample_odor:tasks[T.DualGo]       0.3606      1.150      0.313      0.754      -1.894       2.615
  sample_odor:tasks[T.DualNoGo]     0.3045      1.148      0.265      0.791      -1.945       2.554
  =================================================================================================
#+end_example

#+begin_src ipython
  selective_neuron = []
  for neuron in range(X_avg.shape[1]):
      p_value = results[neuron].pvalues['sample_odor']
      if p_value < 0.05:
          selective_neuron.append(neuron)
#+end_src

#+RESULTS:

#+begin_src ipython
  print(selective_neuron)
#+end_src

#+RESULTS:
: [17, 169, 317, 372, 460, 464, 516, 560, 647]

* Fluorescence

#+begin_src ipython
  x_time =  np.linspace(0, 14, 84)
#+end_src

#+RESULTS:

#+begin_src ipython
  # plt.imshow(X_data.mean(1), aspect='auto', cmap='viridis', extent=[0, 14, 0, 30])
  plt.imshow(np.nanmean(X_days, 0), aspect='auto', cmap='jet', extent=[0, 14, 0, 1152], vmax=0.1)

  cb = plt.colorbar()
  cb.set_label('$\Delta F / F$')

  plt.xticks(np.arange(0, 16, 2))
  plt.xlabel('Time')
  plt.ylabel('$\Delta F/F$')
  plt.ylabel('Trial')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/22de8b0a6fc9e81afc0e6d3b936fe3cd274ff4f1.png]]
