#+TITLE: Performance in the Dual Task
#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session performance :kernel dual_data

* Notebook Settings
#+begin_src ipython
    %load_ext autoreload
    %autoreload 2
    %reload_ext autoreload

    %run /home/leon/dual_task/dual_data/notebooks/setup.py
    %matplotlib inline
    %config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python

* Imports

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')
  from src.performance.perf_tasks import run_perf_tasks
  from src.common.fig_grid import create_grid
  from src.common.options import set_options
#+end_src

#+RESULTS:

* Performance
** Parameters

#+begin_src ipython
  mouse = 'ACCM03'
  perf_type = 'correct'
  tasks = ["DPA", 'DualGo', 'DualNoGo']
  options = set_options()
#+end_src

#+RESULTS:

** Single Mouse

#+begin_src ipython
  tasks = ['DPA', "DualGo", 'DualNoGo']
  run_perf_tasks(mouse=mouse, perf_type=perf_type, sample='AB', tasks=tasks, pal=options['pal'])
  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: Loading files from /home/leon/dual_task/dual_data/data/ACCM03
: PREPROCESSING: SCALER robust AVG MEAN False AVG NOISE True UNIT VAR False
: DPA 960 (960, 6) (320, 6)
: DualGo 960 (960, 6) (320, 6)
: DualNoGo 960 (960, 6) (320, 6)
[[file:./.ob-jupyter/af63465f21a8d09e1eea73f27fb29bbe5d7e3ce0.png]]
:END:

#+begin_src ipython
  options = set_options()
  tasks = ["DualGo"]
  perf_A = run_perf_tasks(mouse=mouse, perf_type=perf_type, sample='A', tasks=tasks, pal=options['pal'])
  options['pal'][1] = options['pal'][0]
  perf_B = run_perf_tasks(mouse=mouse, perf_type=perf_type, sample='B', tasks=tasks, pal=options['pal'])
  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
  loading files from /home/leon/dual_task/src.data/ACCM03
  X_days (960, 361, 84) y_days (960, 6)
  ##########################################
  PREPROCESSING: SCALER robust AVG MEAN False AVG NOISE True UNIT VAR False
  ##########################################
  0.5
  DualGo 960 (960, 6) (80, 6)
  loading files from /home/leon/dual_task/src.data/ACCM03
  X_days (960, 361, 84) y_days (960, 6)
  ##########################################
  PREPROCESSING: SCALER robust AVG MEAN False AVG NOISE True UNIT VAR False
  ##########################################
  0.5
  DualGo 960 (960, 6) (80, 6)
#+end_example
[[file:./.ob-jupyter/040d5a43551181ded98de798540edefbf31ebc2e.png]]
:END:
:RESULTS:

#+begin_src ipython
  # print(perf_A.shape)
  # print(perf_B.shape)
  # print(np.stack((perf_A, perf_B)).shape)
  Delta_perf = perf_A - perf_B

  plt.plot(np.mean(Delta_perf,0))
  plt.show()
#+end_src


#+begin_example
  loading files from /home/leon/dual_task/src.data/ACCM03
  X_days (960, 361, 84) y_days (960, 6)
  ##########################################
  PREPROCESSING: SCALER robust AVG MEAN 0 AVG NOISE True UNIT VAR False
  ##########################################
  DPA 960 (960, 6) (160, 6)
  DualGo 960 (960, 6) (160, 6)
  DualNoGo 960 (960, 6) (160, 6)
  loading files from /home/leon/dual_task/src.data/ACCM03
  X_days (960, 361, 84) y_days (960, 6)
  ##########################################
  PREPROCESSING: SCALER robust AVG MEAN 0 AVG NOISE True UNIT VAR False
  ##########################################
  DPA 960 (960, 6) (160, 6)
  DualGo 960 (960, 6) (160, 6)
#+end_example


#+begin_src ipython
  # print(perf_A.shape)
  # print(perf_B.shape)
  # print(np.stack((perf_A, perf_B)).shape)
  Delta_perf = perf_A - perf_B

  plt.plot(np.mean(Delta_perf,0))
  plt.show()
#+end_src

** All Mice

#+begin_src ipython
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  # mice = ['AP02', 'AP12', 'PP09']
  # mice = ['PP09','PP17', 'RP13']
  # mice = ['ChRM04','JawsM15', 'JawsM18']

  perf_type = 'correct'

  perfs = []

  for mouse in mice:
      perf = np.array(run_perf_tasks(mouse=mouse, perf_type=perf_type, sample='all', tasks=tasks, pal=options['pal']))
      plt.close('all')

      if perf.shape[-1] !=6:
          perf = np.append(perf, np.nan * np.zeros((3, 1)), axis=-1)

      print(perf.shape)
      perfs.append(perf)

  perfs = np.array(perfs)
  print(perfs.shape)
#+end_src

#+RESULTS:
#+begin_example
  DPA 1152 (1152, 6) (192, 6)
  DualGo 1152 (1152, 6) (192, 6)
  DualNoGo 1152 (1152, 6) (192, 6)
  (3, 6)
  DPA 1152 (1152, 6) (192, 6)
  DualGo 1152 (1152, 6) (192, 6)
  DualNoGo 1152 (1152, 6) (192, 6)
  (3, 6)
  DPA 1152 (1152, 6) (192, 6)
  DualGo 1152 (1152, 6) (192, 6)
  DualNoGo 1152 (1152, 6) (192, 6)
  (3, 6)
  DPA 960 (960, 6) (320, 6)
  DualGo 960 (960, 6) (320, 6)
  DualNoGo 960 (960, 6) (320, 6)
  (3, 6)
  DPA 960 (960, 6) (320, 6)
  DualGo 960 (960, 6) (320, 6)
  DualNoGo 960 (960, 6) (320, 6)
  (3, 6)
  (5, 3, 6)
#+end_example

#+begin_src ipython
    from scipy import stats

    mean_perf = np.nanmean(perfs, 0)
    sem = stats.sem(perfs, axis=0)
    # Number of comparisons
    num_tests = perfs.shape[1]  # This is the number of confidence intervals you are calculating

    # Family-wise Confidence Level (for all tests)
    family_confidence_level = 0.95

    # Per-comparison Confidence Level for Bonferroni correction
    bonferroni_confidence_level = 1 - (1 - family_confidence_level) / num_tests

    # Calculate the t-statistic for the Bonferroni-adjusted confidence level
    t_stat = stats.t.ppf((1 + bonferroni_confidence_level) / 2., perfs.shape[0] - 1)

    # Calculate the Bonferroni-corrected CI for each time point
    ci_bound = sem * t_stat
    print(mean_perf.shape, ci_bound.shape)
#+end_src

#+RESULTS:
: (3, 6) (3, 6)

#+begin_src ipython
  from src.common.options import set_options
  opts = set_options()
#+end_src

#+RESULTS:


*** perf

#+begin_src ipython
  tasks = ['DPA', 'DualGo', 'DualNoGo']
  days = np.arange(1, 7)
  fig, ax = plt.subplots()

  for i in range(3):
      plt.plot(days, mean_perf[i], '-o', color=opts['pal'][i], label=tasks[i])
      plt.fill_between(days,
                       mean_perf[i] - ci_bound[i]/5,
                       mean_perf[i] + ci_bound[i]/5,
                       alpha=0.1, color=opts['pal'][i])

  plt.xlabel('Day')

  plt.ylabel('Performance')
  plt.ylim([0.5, 1])
  plt.yticks([.5, .75, 1])

  plt.xticks([1, 2, 3, 4, 5, 6])
  legend = ax.legend(loc='lower right', fontsize=14, frameon=0)
  bbox = legend.get_window_extent().transformed(ax.transAxes.inverted())
  text_y_coord = bbox.y1 + 0.1  # Add a small offset above the legend
  plt.plot([1, 6], [.5, .5], '--k')
  # Add text above the legend
  ax.text(1.0, text_y_coord, 'n=5     ',
          verticalalignment='bottom',
          horizontalalignment='right',
          transform=ax.transAxes)

  plt.savefig('../figs/perf/performance_all_mice.svg', dpi=300)

  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/89a4e83f268dad79ab8cdb336f39c8ca01fd203f.png]]
:END:


*** hits
#+begin_src ipython
  tasks = ['DPA', 'DualGo', 'DualNoGo']
  days = np.arange(1, 7)
  fig, ax = plt.subplots()

  for i in range(3):
      plt.plot(days, mean_perf[i], '-o', color=opts['pal'][i], label=tasks[i])
      plt.fill_between(days,
                       mean_perf[i] - ci_bound[i]/5,
                       mean_perf[i] + ci_bound[i]/5,
                       alpha=0.1, color=opts['pal'][i])

  plt.xlabel('Day')

  plt.ylabel('Hits')
  plt.ylim([0.5, 1])
  plt.yticks([.5, .75, 1])

  plt.xticks([1, 2, 3, 4, 5, 6])
  legend = ax.legend(loc='lower right', fontsize=14, frameon=0)
  bbox = legend.get_window_extent().transformed(ax.transAxes.inverted())
  text_y_coord = bbox.y1 + 0.1  # Add a small offset above the legend
  plt.plot([1, 6], [.5, .5], '--k')
  # Add text above the legend
  ax.text(1.0, text_y_coord, 'n=5     ',
          verticalalignment='bottom',
          horizontalalignment='right',
          transform=ax.transAxes)

  plt.savefig('../figs/perf/hits_all_mice.svg', dpi=300)

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/98ddbb4ffcd0e616d36760834b7a9783e1154d64.png]]


*** fa

#+begin_src ipython
  tasks = ['DPA', 'DualGo', 'DualNoGo']
  days = np.arange(1, 7)
  fig, ax = plt.subplots()

  for i in range(3):
      plt.plot(days, mean_perf[i], '-o', color=opts['pal'][i], label=tasks[i])
      plt.fill_between(days,
                       mean_perf[i] - ci_bound[i]/5,
                       mean_perf[i] + ci_bound[i]/5,
                       alpha=0.1, color=opts['pal'][i])

  plt.xlabel('Day')

  if 'fa' in perf_type:
      plt.ylabel('False Alarms')
      plt.ylim([0., 1])
      plt.yticks([0, .25, .5, .75, 1])

  plt.xticks([1, 2, 3, 4, 5, 6])
  legend = ax.legend(loc='upper right', fontsize=14, frameon=0)
  bbox = legend.get_window_extent().transformed(ax.transAxes.inverted())
  text_y_coord = bbox.y1 + 0.1  # Add a small offset above the legend
  plt.plot([1, 6], [.5, .5], '--k')
  # Add text above the legend
  ax.text(1.0, text_y_coord, 'n=5     ',
          verticalalignment='bottom',
          horizontalalignment='right',
          transform=ax.transAxes)

  if 'fa' in perf_type:
      plt.savefig('../figs/perf/fa_all_mice.svg', dpi=300)

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/787a9e749f7a13f92b5debe46f50ddbe719d8363.png]]

* GLM

#+begin_src ipython
  options = set_options()
#+end_src

#+RESULTS:

#+begin_src ipython
  from src.common.get_data import get_X_y_mice
  options['reload']=0
  X, y = get_X_y_mice(**options)
#+end_src

#+RESULTS:
: Loading files from /home/leon/dual_task/dual_data/data/mice

#+begin_src ipython
  print(y.keys())
  print(y['mouse'].unique())
  print(y['response'].unique())
#+end_src

#+RESULTS:
: Index(['sample_odor', 'test_odor', 'response', 'tasks', 'laser', 'day',
:        'mouse'],
:       dtype='object')
: ['ChRM04' 'JawsM15' 'JawsM18' 'ACCM03' 'ACCM04']
: ['incorrect_fa' 'correct_hit' 'correct_rej' 'incorrect_miss']

#+begin_src ipython
  df = y[y['laser']==0].copy()
  df['behavior'] = df['response'].apply(lambda x: 0 if 'incorrect' in x else 1)
  df['learning'] = df['day'].apply(lambda x: 0 if x<4 else 1)
  print(df.keys())
#+end_src

#+RESULTS:
: Index(['sample_odor', 'test_odor', 'response', 'tasks', 'laser', 'day',
:        'mouse', 'behavior', 'learning'],
:       dtype='object')


#+begin_src ipython
  import statsmodels.api as sm
  import statsmodels.formula.api as smf
  import pandas as pd
#+end_src

#+RESULTS:

#+begin_src ipython
  print(df.keys())
#+end_src

#+RESULTS:
: Index(['sample_odor', 'test_odor', 'response', 'tasks', 'laser', 'day',
:        'mouse', 'behavior', 'learning'],
:       dtype='object')

#+begin_src ipython
  df['response'] = df['response'].astype('category')
  df['mouse'] = df['mouse'].astype('category')
  # df['tasks'] = df['tasks'].astype('category')
#+end_src

#+RESULTS:

#+begin_src ipython
  print(df['tasks'].unique())
#+end_src

#+RESULTS:
: ['DualNoGo' 'DualGo' 'DPA']

#+begin_src ipython
  from statsmodels.stats.anova import anova_lm
  formula = 'behavior ~ tasks * tasks'
  results = []
  anovas = []
  df2 = df[df['tasks']!='DualNoGo'].copy()
  df2['tasks'] = df2['tasks'].astype('category')
  print(df2['tasks'].unique())

  df2 = df2[(df2['response']=='incorrect_fa') | (df2['response'] == 'correct_rej')].copy()
  for i in range(5):
      df3 = df2[df2['day']==i+1].copy()
      model = smf.glm(formula=formula, data=df3, family=sm.families.Gaussian())
      results.append(model.fit())
#+end_src

#+RESULTS:
: ['DualGo', 'DPA']
: Categories (2, object): ['DPA', 'DualGo']

#+begin_src ipython
  colors = ['r', 'b', 'g']
  fig, ax = plt.subplots(1, 1)
  for j in range(5):

      model = results[j]
      params = model.params
      # print(params)
      conf = model.conf_int()
      # print(conf)
      for i in range(2):
          yerr = np.array([params[i] - conf[0][i], conf[1][i] - params[i]])[:, np.newaxis]
          ax.errorbar(x=j, y=params[i], yerr=yerr, fmt='o', color=colors[i])

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/32c2e647671c6483785a872dd2db54bd0f5f87d8.png]]

#+begin_src ipython
      model = results[3]
      print(model.summary())
#+end_src

#+RESULTS:
#+begin_example
                   Generalized Linear Model Regression Results
  ==============================================================================
  Dep. Variable:               behavior   No. Observations:                  224
  Model:                            GLM   Df Residuals:                      222
  Model Family:                Gaussian   Df Model:                            1
  Link Function:               Identity   Scale:                         0.20463
  Method:                          IRLS   Log-Likelihood:                -139.15
  Date:                Mon, 29 Jul 2024   Deviance:                       45.429
  Time:                        16:16:06   Pearson chi2:                     45.4
  No. Iterations:                     3   Pseudo R-squ. (CS):           0.006254
  Covariance Type:            nonrobust
  ===================================================================================
                        coef    std err          z      P>|z|      [0.025      0.975]
  -----------------------------------------------------------------------------------
  Intercept           0.7500      0.043     17.546      0.000       0.666       0.834
  tasks[T.DualGo]    -0.0714      0.060     -1.182      0.237      -0.190       0.047
  ===================================================================================
#+end_example


#+begin_src ipython
  df2 = df[(df['response']=='incorrect_fa') | (df['response'] == 'correct_rej')].copy()
  formula = 'behavior ~ tasks * day'
  glm_gauss = smf.glm(formula=formula, data=df2, family=sm.families.Gaussian())
  result = glm_gauss.fit()
  print(result.summary())
#+end_src

#+RESULTS:
#+begin_example
                   Generalized Linear Model Regression Results
  ==============================================================================
  Dep. Variable:               behavior   No. Observations:                 1824
  Model:                            GLM   Df Residuals:                     1818
  Model Family:                Gaussian   Df Model:                            5
  Link Function:               Identity   Scale:                         0.19642
  Method:                          IRLS   Log-Likelihood:                -1100.8
  Date:                Mon, 29 Jul 2024   Deviance:                       357.08
  Time:                        15:37:03   Pearson chi2:                     357.
  No. Iterations:                     3   Pseudo R-squ. (CS):             0.1755
  Covariance Type:            nonrobust
  =========================================================================================
                              coef    std err          z      P>|z|      [0.025      0.975]
  -----------------------------------------------------------------------------------------
  Intercept                 0.2671      0.041      6.520      0.000       0.187       0.347
  tasks[T.DualGo]          -0.0991      0.058     -1.710      0.087      -0.213       0.014
  tasks[T.DualNoGo]         0.0127      0.058      0.219      0.827      -0.101       0.126
  day                       0.1222      0.011     10.746      0.000       0.100       0.145
  tasks[T.DualGo]:day       0.0016      0.016      0.102      0.918      -0.030       0.033
  tasks[T.DualNoGo]:day    -0.0075      0.016     -0.464      0.642      -0.039       0.024
  =========================================================================================
#+end_example

#+begin_src ipython
  params = model.params
  conf = model.conf_int()
  print(conf[1])
#+end_src

#+RESULTS:
: Intercept                0.599949
: tasks[T.DualGo]          0.015597
: tasks[T.DualNoGo]        0.082136
: day                      0.088624
: tasks[T.DualGo]:day      0.022168
: tasks[T.DualNoGo]:day    0.014315
: Name: 1, dtype: float64

#+begin_src ipython
  fig, ax = plt.subplots(1, 1)
  for i in range(3):
      ax.errorbar(x=days, y=params[i], yerr=[params[i] - conf[0][i], conf[1][i] - params[i]], fmt='o')

#+end_src

#+begin_src ipython
    formula = 'behavior ~ tasks * learning'
    glm_gauss = smf.glm(formula=formula, data=df, family=sm.families.Gaussian())
    result = glm_gauss.fit()
    print(result.summary())
#+end_src

#+RESULTS:
#+begin_example
                   Generalized Linear Model Regression Results
  ==============================================================================
  Dep. Variable:               behavior   No. Observations:                 3648
  Model:                            GLM   Df Residuals:                     3642
  Model Family:                Gaussian   Df Model:                            5
  Link Function:               Identity   Scale:                         0.16913
  Method:                          IRLS   Log-Likelihood:                -1931.8
  Date:                Mon, 29 Jul 2024   Deviance:                       615.96
  Time:                        13:26:18   Pearson chi2:                     616.
  No. Iterations:                     3   Pseudo R-squ. (CS):            0.05829
  Covariance Type:            nonrobust
  ==============================================================================================
                                   coef    std err          z      P>|z|      [0.025      0.975]
  ----------------------------------------------------------------------------------------------
  Intercept                      0.7009      0.016     44.181      0.000       0.670       0.732
  tasks[T.DualGo]               -0.0655      0.022     -2.918      0.004      -0.109      -0.022
  tasks[T.DualNoGo]             -0.0015      0.022     -0.066      0.947      -0.045       0.042
  learning                       0.1943      0.024      8.193      0.000       0.148       0.241
  tasks[T.DualGo]:learning       0.0287      0.034      0.856      0.392      -0.037       0.094
  tasks[T.DualNoGo]:learning    -0.0224      0.034     -0.668      0.504      -0.088       0.043
  ==============================================================================================
#+end_example

#+begin_src ipython
    formula = 'behavior ~ tasks'
    glm_gauss = smf.glm(formula=formula, data=df, family=sm.families.Gaussian())
    result = glm_gauss.fit()
    print(result.summary())
#+end_src

#+RESULTS:
#+begin_example
                   Generalized Linear Model Regression Results
  ==============================================================================
  Dep. Variable:               behavior   No. Observations:                 3648
  Model:                            GLM   Df Residuals:                     3645
  Model Family:                Gaussian   Df Model:                            2
  Link Function:               Identity   Scale:                         0.17864
  Method:                          IRLS   Log-Likelihood:                -2033.2
  Date:                Mon, 29 Jul 2024   Deviance:                       651.15
  Time:                        13:23:04   Pearson chi2:                     651.
  No. Iterations:                     3   Pseudo R-squ. (CS):           0.002853
  Covariance Type:            nonrobust
  =====================================================================================
                          coef    std err          z      P>|z|      [0.025      0.975]
  -------------------------------------------------------------------------------------
  Intercept             0.7878      0.012     64.999      0.000       0.764       0.812
  tasks[T.DualGo]      -0.0526      0.017     -3.070      0.002      -0.086      -0.019
  tasks[T.DualNoGo]    -0.0115      0.017     -0.672      0.502      -0.045       0.022
  =====================================================================================
#+end_example

#+begin_src ipython
  import statsmodels.formula.api as smf
  import matplotlib.pyplot as plt
  import pandas as pd
  import numpy as np

  # Assuming you have a DataFrame named df containing your data
  # and the formula you mentioned.
  model = smf.glm(formula='behavior ~ tasks * day', data=df).fit()

  # Extract the parameters (weights) and standard errors
  params = model.params
  conf = model.conf_int()
  conf['mean'] = params
  conf.columns = ['2.5%', '97.5%', 'mean']

  # Create a plot for each task
  tasks = df['tasks'].unique()
  days = df['day'].unique()
  n_tasks = len(tasks)
  n_days = len(days)

  fig, ax = plt.subplots(n_tasks, 1, figsize=(8, n_tasks * 4))

  if n_tasks == 1:
      ax = [ax]  # Ensure ax is iterable when there's only one task

  for i, task in enumerate(tasks):
      task_params = conf.loc[[f'tasks[T.{task}]:day[T.{day}]' for day in days], :]

      # If any main effects exist, add them too
      if f'tasks[T.{task}]' in conf.index:
          task_main = conf.loc[f'tasks[T.{task}]']
          task_params.loc[:, 'mean'] += task_main['mean']
          task_params.loc[:, '2.5%'] += task_main['2.5%']
          task_params.loc[:, '97.5%'] += task_main['97.5%']
      if 'Intercept' in conf.index:
          intercept = conf.loc['Intercept']
          task_params.loc[:, 'mean'] += intercept['mean']
          task_params.loc[:, '2.5%'] += intercept['2.5%']
          task_params.loc[:, '97.5%'] += intercept['97.5%']

      ax[i].errorbar(x=days, y=task_params['mean'], yerr=[task_params['mean'] - task_params['2.5%'], task_params['97.5%'] - task_params['mean']], fmt='o')
      ax[i].set_title(f'Task: {task}')
      ax[i].set_xlabel('Day')
      ax[i].set_ylabel('Weight')

  plt.tight_layout()
  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
  ---------------------------------------------------------------------------
  KeyError                                  Traceback (most recent call last)
  Cell In[74], line 28
       25     ax = [ax]  # Ensure ax is iterable when there's only one task
       27 for i, task in enumerate(tasks):
  ---> 28     task_params = conf.loc[[f'tasks[T.{task}]:day[T.{day}]' for day in days], :]
       30     # If any main effects exist, add them too
       31     if f'tasks[T.{task}]' in conf.index:

  File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/indexing.py:1147, in _LocationIndexer.__getitem__(self, key)
     1145     if self._is_scalar_access(key):
     1146         return self.obj._get_value(*key, takeable=self._takeable)
  -> 1147     return self._getitem_tuple(key)
     1148 else:
     1149     # we by definition only have the 0th axis
     1150     axis = self.axis or 0

  File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/indexing.py:1339, in _LocIndexer._getitem_tuple(self, tup)
     1336 if self._multi_take_opportunity(tup):
     1337     return self._multi_take(tup)
  -> 1339 return self._getitem_tuple_same_dim(tup)

  File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/indexing.py:994, in _LocationIndexer._getitem_tuple_same_dim(self, tup)
      991 if com.is_null_slice(key):
      992     continue
  --> 994 retval = getattr(retval, self.name)._getitem_axis(key, axis=i)
      995 # We should never have retval.ndim < self.ndim, as that should
      996 #  be handled by the _getitem_lowerdim call above.
      997 assert retval.ndim == self.ndim

  File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/indexing.py:1382, in _LocIndexer._getitem_axis(self, key, axis)
     1379     if hasattr(key, "ndim") and key.ndim > 1:
     1380         raise ValueError("Cannot index with multidimensional key")
  -> 1382     return self._getitem_iterable(key, axis=axis)
     1384 # nested tuple slicing
     1385 if is_nested_tuple(key, labels):

  File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/indexing.py:1322, in _LocIndexer._getitem_iterable(self, key, axis)
     1319 self._validate_key(key, axis)
     1321 # A collection of keys
  -> 1322 keyarr, indexer = self._get_listlike_indexer(key, axis)
     1323 return self.obj._reindex_with_indexers(
     1324     {axis: [keyarr, indexer]}, copy=True, allow_dups=True
     1325 )

  File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/indexing.py:1520, in _LocIndexer._get_listlike_indexer(self, key, axis)
     1517 ax = self.obj._get_axis(axis)
     1518 axis_name = self.obj._get_axis_name(axis)
  -> 1520 keyarr, indexer = ax._get_indexer_strict(key, axis_name)
     1522 return keyarr, indexer

  File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/indexes/base.py:6114, in Index._get_indexer_strict(self, key, axis_name)
     6111 else:
     6112     keyarr, indexer, new_indexer = self._reindex_non_unique(keyarr)
  -> 6114 self._raise_if_missing(keyarr, indexer, axis_name)
     6116 keyarr = self.take(indexer)
     6117 if isinstance(key, Index):
     6118     # GH 42790 - Preserve name from an Index

  File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pandas/core/indexes/base.py:6175, in Index._raise_if_missing(self, key, indexer, axis_name)
     6173     if use_interval_msg:
     6174         key = list(key)
  -> 6175     raise KeyError(f"None of [{key}] are in the [{axis_name}]")
     6177 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique())
     6178 raise KeyError(f"{not_found} not in index")

  KeyError: "None of [Index(['tasks[T.DualNoGo]:day[T.1.0]', 'tasks[T.DualNoGo]:day[T.2.0]',\n       'tasks[T.DualNoGo]:day[T.3.0]', 'tasks[T.DualNoGo]:day[T.4.0]',\n       'tasks[T.DualNoGo]:day[T.5.0]', 'tasks[T.DualNoGo]:day[T.6.0]'],\n      dtype='object')] are in the [index]"
#+end_example
[[file:./.ob-jupyter/951b7b0122a7f374ae7d3e4592b43147403faf38.png]]
:END:

* Summary

#+begin_src ipython
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04', 'AP02', 'AP12', 'PP09','PP17', 'RP13']

  def figname(mouse):
      return mouse + "_behavior_tasks_correct" + ".svg"

  figlist = ['../figs/' + figname(mouse) for mouse in mice]
  print(figlist)

  golden_ratio = (5**.5 - 1) / 2
  width = 4.3
  height = width * golden_ratio * 1.4
  figsize = [width, height]
  matplotlib.rcParams['lines.markersize'] = 5.5

  create_grid(figlist, "../figs/performance_all_mice.svg", dim=[4,3], fontsize=22)

#+end_src

#+RESULTS:
: ['../figs/ChRM04_behavior_tasks_correct.svg', '../figs/JawsM15_behavior_tasks_correct.svg', '../figs/JawsM18_behavior_tasks_correct.svg', '../figs/ACCM03_behavior_tasks_correct.svg', '../figs/ACCM04_behavior_tasks_correct.svg', '../figs/AP02_behavior_tasks_correct.svg', '../figs/AP12_behavior_tasks_correct.svg', '../figs/PP09_behavior_tasks_correct.svg', '../figs/PP17_behavior_tasks_correct.svg', '../figs/RP13_behavior_tasks_correct.svg']
: 504.0 311.48913
: ['2016pt', '934pt']

#+NAME: fig:temporal_decoding
#+CAPTION: Temporal Decoding
#+ATTR_ORG: :width 1200
#+ATTR_LATEX: :width 5in
[[file:../figs/performance_all_mice.svg]]
