#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session at :kernel dual_data

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload
  
  %run /home/leon/dual_task/dual_data/notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python


* [#C] Imports

#+begin_src ipython
  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  
  from src.overlap.get_cos import run_get_cos
  from src.common.options import set_options
#+end_src

#+RESULTS:
* Linear Classification
** Parameters

#+begin_src ipython
  tasks = ['DPA', 'DualGo', 'DualNoGo']
  days = ['first', 'last']

  kwargs = dict()
  kwargs = {'prescreen': None, 'pval': 0.05, 'trials': 'correct', 'balance': 'under', 'laser':0,
            'method': None,
            'bolasso_pval':0.05, 'bolasso_penalty': 'l2',
            'bootstrap': False, 'n_boots': 1000,
            'preprocess': True, 'scaler_BL':'robust',
            'avg_noise': True, 'unit_var_BL':False,
            'clf': 'LDA', 'scaler': None,
            'tol':0.001, 'penalty': 'l1',
            'shrinkage': 'auto',
            'class_weight': None, 'random_state': None,
            'in_fold': 'stratified', 'n_in': 10,
            'n_repeats': 10,
            'n_lambda': 20,
            'T_WINDOW': 0.25,
            }
  
  kwargs['mouse'] = 'ACCM03'
  kwargs['reload']= False
  kwargs['data_type'] = 'raw'
#+end_src

#+RESULTS:

** Classification

#+begin_src ipython  
  day = 'first'
  X_first, y_first, coefs_first = run_get_cos(day=day, **kwargs)
  
  day = 'last'
  kwargs['reload']= False 
  X_last, y_last, coefs_last = run_get_cos(day=day, **kwargs)
#+end_src

#+RESULTS:
#+begin_example
  loading files from /home/leon/dual_task/dual_data/data/ACCM03
  X_days (960, 361, 84) y_days (960, 6)
  ##########################################
  PREPROCESSING: SCALER robust AVG MEAN False AVG NOISE True UNIT VAR False
  ##########################################
  ##########################################
  MODEL: LDA FOLDS stratified RESAMPLE under SCALER None PRESCREEN None PCA False METHOD None
  ##########################################
  DATA: FEATURES distractor TASK Dual TRIALS correct DAYS first LASER 0
  ##########################################
  multiple days 0 3 0
  X_S1 (82, 361, 84) X_S2 (104, 361, 84)
  coefs dist (361,)
  non_zeros 169
  ##########################################
  MODEL: LDA FOLDS stratified RESAMPLE under SCALER None PRESCREEN None PCA False METHOD None
  ##########################################
  DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
  ##########################################
  multiple days 0 3 0
  X_S1 (148, 361, 84) X_S2 (143, 361, 84)
  coefs ED (361,)
  non_zeros 189
  ##########################################
  MODEL: LDA FOLDS stratified RESAMPLE under SCALER None PRESCREEN None PCA False METHOD None
  ##########################################
  DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
  ##########################################
  multiple days 0 3 0
  X_S1 (148, 361, 84) X_S2 (143, 361, 84)
  coefs MD (361,)
  non_zeros 197
  ##########################################
  MODEL: LDA FOLDS stratified RESAMPLE under SCALER None PRESCREEN None PCA False METHOD None
  ##########################################
  DATA: FEATURES sample TASK all TRIALS correct DAYS first LASER 0
  ##########################################
  multiple days 0 3 0
  X_S1 (148, 361, 84) X_S2 (143, 361, 84)
  coefs LD (361,)
  non_zeros 196
  idx (361,) c_sample (361,)
  ##########################################
  DATA: FEATURES sample TASK DPA TRIALS correct DAYS first LASER 0
  ##########################################
  multiple days 0 3 0
  X_S1 (51, 361, 84) X_S2 (54, 361, 84)
  ##########################################
  DATA: FEATURES sample TASK DualGo TRIALS correct DAYS first LASER 0
  ##########################################
  multiple days 0 3 0
  X_S1 (44, 361, 84) X_S2 (38, 361, 84)
  ##########################################
  DATA: FEATURES sample TASK DualNoGo TRIALS correct DAYS first LASER 0
  ##########################################
  multiple days 0 3 0
  X_S1 (53, 361, 84) X_S2 (51, 361, 84)
  Done
  (4, 361)
  loading files from /home/leon/dual_task/dual_data/data/ACCM03
  X_days (960, 361, 84) y_days (960, 6)
  ##########################################
  PREPROCESSING: SCALER robust AVG MEAN False AVG NOISE True UNIT VAR False
  ##########################################
  ##########################################
  MODEL: LDA FOLDS stratified RESAMPLE under SCALER None PRESCREEN None PCA False METHOD None
  ##########################################
  DATA: FEATURES distractor TASK Dual TRIALS correct DAYS last LASER 0
  ##########################################
  multiple days 0 3 0
  X_S1 (134, 361, 84) X_S2 (146, 361, 84)
  coefs dist (361,)
  non_zeros 184
  ##########################################
  MODEL: LDA FOLDS stratified RESAMPLE under SCALER None PRESCREEN None PCA False METHOD None
  ##########################################
  DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
  ##########################################
  multiple days 0 3 0
  X_S1 (216, 361, 84) X_S2 (214, 361, 84)
  coefs ED (361,)
  non_zeros 180
  ##########################################
  MODEL: LDA FOLDS stratified RESAMPLE under SCALER None PRESCREEN None PCA False METHOD None
  ##########################################
  DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
  ##########################################
  multiple days 0 3 0
  X_S1 (216, 361, 84) X_S2 (214, 361, 84)
  coefs MD (361,)
  non_zeros 173
  ##########################################
  MODEL: LDA FOLDS stratified RESAMPLE under SCALER None PRESCREEN None PCA False METHOD None
  ##########################################
  DATA: FEATURES sample TASK all TRIALS correct DAYS last LASER 0
  ##########################################
  multiple days 0 3 0
  X_S1 (216, 361, 84) X_S2 (214, 361, 84)
  coefs LD (361,)
  non_zeros 166
  idx (361,) c_sample (361,)
  ##########################################
  DATA: FEATURES sample TASK DPA TRIALS correct DAYS last LASER 0
  ##########################################
  multiple days 0 3 0
  X_S1 (73, 361, 84) X_S2 (77, 361, 84)
  ##########################################
  DATA: FEATURES sample TASK DualGo TRIALS correct DAYS last LASER 0
  ##########################################
  multiple days 0 3 0
  X_S1 (70, 361, 84) X_S2 (64, 361, 84)
  ##########################################
  DATA: FEATURES sample TASK DualNoGo TRIALS correct DAYS last LASER 0
  ##########################################
  multiple days 0 3 0
  X_S1 (73, 361, 84) X_S2 (73, 361, 84)
  Done
  (4, 361)
#+end_example
#+RESULTS:

#+begin_src ipython
  width = 7
  golden_ratio = (5**.5 - 1) / 2
  fig, ax = plt.subplots(1, 2, figsize= [1.5*width, width * golden_ratio])

  ax[0].scatter(coefs_first[0], coefs_first[1], s=1)
  ax[0].set_xlim([-0.15, 0.15]) 
  ax[0].set_ylim([-0.15, 0.15])
  ax[0].set_ylabel('Distractor Axis')
  ax[0].set_xlabel('Sample Axis')
  ax[0].set_title('First')

  ax[1].scatter(coefs_last[0], coefs_last[1], s=1)
  ax[1].set_xlim([-0.15, 0.15]) 
  ax[1].set_ylim([-0.15, 0.15])
  ax[1].set_xlabel('Sample Axis')
  ax[1].set_title('Last')

  plt.savefig("../figs/landscape/"+ kwargs['mouse'] + "_memories_" + kwargs['penalty'] + '.svg', dpi=300)

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/32df4bc29747b7ad6cf0d7fcc33d5262342bace0.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

**** save/load

#+begin_src ipython
  filename = "../data/" + kwargs['mouse'] + "/coefs_first_" + kwargs['penalty'] + ".pkl"
  pkl.dump(coefs_first, open(filename + ".pkl", "wb"))

  filename = "../data/" + kwargs['mouse'] + "/coefs_last_" + kwargs['penalty'] + ".pkl"
  pkl.dump(coefs_last, open(filename + ".pkl", "wb"))
#+end_src

#+RESULTS:

#+begin_src ipython
  filename = "../data/" + kwargs['mouse'] + "/coefs_first_" + kwargs['penalty'] + ".pkl"
  coefs_first = pkl.load(open(filename + ".pkl", "rb"))

  filename = "../data/" + kwargs['mouse'] + "/coefs_last_" + kwargs['penalty'] + ".pkl"
  coefs_last = pkl.load(open(filename + ".pkl", "rb"))
#+end_src

#+RESULTS:

* valente

#+begin_src ipython
  sys.path.append('/home/leon/populations_paper_code/')

  from matplotlib.patches import Ellipse
  from low_rank_rnns import helpers, raposo, mante, regressions, clustering
  import low_rank_rnns.mixedselectivity as ms
  color = sns.color_palette('deep')[0]
  
#+end_src

#+RESULTS:

** Scatter

#+begin_src ipython
  def plot_scatter(coefs_first, ax=None):

    if ax is None:
      fig, ax = plt.subplots(figsize=(4, 4))

    ax.scatter(coefs_first[0], coefs_first[1], color=color, s=1)
    helpers.center_axes(ax)
    # ax.set_xlim(-.1, .1)
    # ax.set_ylim(-.1, .1)

    X = coefs_first.T

    cov = X.T @ X / X.shape[0]
    eigvals, eigvecs = np.linalg.eig(cov)
    v1 = eigvecs[:, 0]
    angle = np.arctan(v1[1] / v1[0])
    angle = angle * 180 / np.pi
    std_factor = 1
    ax.add_artist(Ellipse(xy=[0, 0], 
                          angle=angle,
                          width=np.sqrt(eigvals[0]) * 2 * std_factor, 
                          height=np.sqrt(eigvals[1]) * 2 * std_factor, 
                          fill=True, fc='silver', ec='black', lw=1, zorder=-1, alpha=0.2))
    
#+end_src

#+RESULTS:

#+begin_src ipython
  i,j= 1,2
  vec_first = np.array([coefs_first[i], coefs_first[j]])
  vec_last = np.array([coefs_last[i], coefs_last[j]])
#+end_src

#+RESULTS:

#+begin_src ipython
  fig, ax = plt.subplots(1, 2, figsize=(8, 4))
  plot_scatter(vec_first, ax=ax[0])
  plot_scatter(vec_last, ax=ax[1])
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/053411999bc91c5c2212e3bd7393f3ace12d78d8.png]]

** Clustering 

#+begin_src ipython
  def plot_cluster(vecs, n_pop=2, ax=None, n_init=10):
    if ax is None:
      fig, ax = plt.subplots(figsize=(4, 4))

    z, model = clustering.gmm_fit(vecs.T, n_pops, algo='bayes', n_init=n_init, random_state=None)
    z = 1 - z   # inverting population labels for presentation purposes
    
    clustering.pop_scatter_linreg(vecs[0], vecs[1], z, n_pop, colors=colors, linreg=False, ax=ax)
    # plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
  colors = ['seagreen', 'rebeccapurple', 'r']
  n_pops=2
  
  fig, ax = plt.subplots(1, 2, figsize=(8, 4))
  plot_cluster(vec_first, n_pops, ax=ax[0])
  plot_cluster(vec_last, n_pops, ax=ax[1])
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/b7c571cba086312e8eee686213e880ad0071819f.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

** ePAIRS

#+begin_src ipython
  figsize=(8,4)
  fig, ax = plt.subplots(1, 2, figsize=(8, 4))  
  ms.epairs(vec_first.T, 1, 30, figsize=figsize, col=color, ax=ax[0])
  ms.epairs(vec_last.T, 1, 30, figsize=figsize, col=color, ax=ax[1])

  ax[0].set_xlim([0, .25])
  ax[1].set_xlim([0, .25])
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
  (1, 361)
  clusteriness: 0.3775757401811493
  data mean: 0.144, mc mean: 0.154
  KS 2 sample test: p=0.0001746269528398624
  Wilcoxon rank-sum test: p=0.35896278827634764
  Kruskal-Wallis test: p=0.3589627882763018
  (1, 361)
  clusteriness: -0.03710028321436825
  data mean: 0.155, mc mean: 0.154
  KS 2 sample test: p=0.1653171003886774
  Wilcoxon rank-sum test: p=0.6351695714434906
  Kruskal-Wallis test: p=0.6351695714433694
#+end_example
| 0.0 | 0.25 |
[[file:./.ob-jupyter/e6ff6f6b2e16d51979b162fe14c0ca223414bbc3.png]]
:END:

* RNN trained on DMS

#+begin_src ipython
from low_rank_rnns.modules import *
from low_rank_rnns import dms, ranktwo, clustering, helpers
#+end_src

#+RESULTS:

#+begin_src ipython
  hidden_size = 500
  noise_std = 5e-2
  alpha = 0.2
  net = LowRankRNN(2, hidden_size, 1, noise_std, alpha, rank=2)
  net.load_state_dict(torch.load(f'/home/leon/populations_paper_code/models/dms_rank2_500.pt', map_location='cpu'))
  net.svd_reparametrization()
#+end_src

#+RESULTS:

#+begin_src ipython
  m1 = -net.m[:,0].detach().numpy()
  n1 = -net.n[:,0].detach().numpy()

  m2 = -net.m[:,1].detach().numpy()
  n2 = -net.n[:,1].detach().numpy()

  wi1 = net.wi[0].detach().numpy()
  wi2 = net.wi[1].detach().numpy()
  
  wo = net.wo[:,0].detach().numpy()
#+end_src

#+RESULTS:

#+begin_src ipython
  print(net.m.shape)
  print(net.wi.shape)
  print(net.wo.shape)
#+end_src

#+RESULTS:
: torch.Size([500, 2])
: torch.Size([2, 500])
: torch.Size([500, 1])

#+begin_src ipython
  figsize = plt.rcParams['figure.figsize']
  figsize = (figsize[0], figsize[1])
  conn_space = np.array([wi1, wi2, n1, m2, n2, m2]).transpose()
  ms.epairs(conn_space, 500, figsize=figsize, xlim=(.1, .8), col=color)
  # plt.savefig('figure_1/epairs_raposo.pdf', bbox_inches='tight')
#+end_src

#+RESULTS:
:RESULTS:
: (500, 500)
: clusteriness: 0.4792883552976995
: data mean: 0.426, mc mean: 0.457
: KS 2 sample test: p=2.824946510036737e-16
: Wilcoxon rank-sum test: p=1.8536968332396158e-25
: Kruskal-Wallis test: p=1.8536714349629932e-25
| 1.8536968332396158e-25 | 0.4792883552976995 |
[[file:./.ob-jupyter/f37ae52302b8bfae8e61a6bcd3b229bba2a8afd0.png]]
:END:

#+begin_src ipython
  int(2*np.random.uniform())
#+end_src

#+RESULTS:
: 1

#+begin_src ipython
  plot_scatter(np.array([wi1, wi2]))
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/08e6fc25554feed0a436d1d496d0abe7acfee2e3.png]]

#+begin_src ipython
  colors = ['seagreen', 'rebeccapurple', 'r']

  n_pop = 2
  vecs = clustering.make_vecs(net)
  
  z, model = clustering.gmm_fit(vecs, n_pops, algo='bayes', n_init=50, random_state=2020)
  z = 1 - z   # inverting population labels for presentation purposes

  clustering.pop_scatter_linreg(wi1, wi2, z, n_pop, colors=colors, linreg=False)
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/72648d62bc65fe44c2745e544ca0db41e418e0d6.png]]

#+begin_src ipython

#+end_src
