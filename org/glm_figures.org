#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session glm :kernel dual_data :exports results :output-dir ./figures/overlaps :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run /home/leon/dual_task/dual_data/notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/dual_data/bin/python

* Imports
#+begin_src ipython
  from sklearn.exceptions import ConvergenceWarning
  warnings.filterwarnings("ignore")
  import traceback

  import sys
  sys.path.insert(0, '/home/leon/dual_task/dual_data/')

  import os
  if not sys.warnoptions:
    warnings.simplefilter("ignore")
    os.environ["PYTHONWARNINGS"] = "ignore"

  import pickle as pkl
  import numpy as np
  import matplotlib.pyplot as plt
  import pandas as pd

  from time import perf_counter

  from sklearn.base import clone
  from sklearn.metrics import make_scorer, roc_auc_score
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.model_selection import RepeatedStratifiedKFold, LeaveOneOut, StratifiedKFold

  from src.common.plot_utils import add_vlines, add_vdashed
  from src.common.options import set_options
  from src.stats.bootstrap import my_boots_ci
  from src.common.get_data import get_X_y_days, get_X_y_S1_S2
  from src.preprocess.helpers import avg_epochs

  from src.torch.classificationCV import ClassificationCV
  from src.torch.main import get_classification
#+end_src

#+RESULTS:

* Helpers

#+begin_src ipython
def pad_with_nans(array, target_shape):
    result = np.full(target_shape, np.nan)  # Create an array filled with NaNs
    print(result.shape)
    slices = tuple(slice(0, min(dim, target)) for dim, target in zip(array.shape, target_shape))
    result[slices] = array[slices]
    return result
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import numpy as np

  def safe_roc_auc_score(y_true, y_score):
      y_true = np.asarray(y_true)
      if len(np.unique(y_true)) == 1:
          return np.nan  # return np.nan where the score cannot be calculated
      return roc_auc_score(y_true, y_score)
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def rescale_coefs(model, coefs, bias):

          try:
                  means = model.named_steps["scaler"].mean_
                  scales = model.named_steps["scaler"].scale_

                  # Rescale the coefficients
                  rescaled_coefs = np.true_divide(coefs, scales)

                  # Adjust the intercept
                  rescaled_bias = bias - np.sum(rescaled_coefs * means)

                  return rescaled_coefs, rescaled_bias
          except:
                  return coefs, bias

#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  from scipy.stats import bootstrap

  def get_bootstrap_ci(data, statistic=np.mean, confidence_level=0.95, n_resamples=1000, random_state=None):
      result = bootstrap((data,), statistic)
      ci_lower, ci_upper = result.confidence_interval
      return np.array([ci_lower, ci_upper])
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

* Parameters

#+begin_src ipython
  DEVICE = 'cuda:0'
  mice = ['ChRM04','JawsM15', 'JawsM18', 'ACCM03', 'ACCM04']
  N_NEURONS = [668, 693, 444, 361, 113]

  tasks = ['DPA', 'DualGo', 'DualNoGo']
  mice = ['AP02', 'AP12', 'PP09', 'PP17', 'RP17']
  mice = ['AP02']

  kwargs = {
      'mouse': 'ChRM04', 'laser': 0,
      'trials': '', 'reload': 0, 'data_type': 'dF',
      'prescreen': None, 'pval': 0.05,
      'preprocess': False, 'scaler_BL': 'robust',
      'avg_noise':True, 'unit_var_BL': True,
      'random_state': None, 'T_WINDOW': 0.0,
      'l1_ratio': 0.95,
      'n_comp': None, 'scaler': None,
      'bootstrap': 1, 'n_boots': 128,
      'n_splits': 3, 'n_repeats': 32,
      'class_weight': 0,
      'multilabel':0,
  }

  kwargs['days'] = ['first', 'middle', 'last']
  # kwargs['days'] = np.arange(1, options['n_days']+1)
  options = set_options(**kwargs)
  safe_roc_auc = make_scorer(safe_roc_auc_score, needs_proba=True)
  options['hp_scoring'] = safe_roc_auc
  options['n_jobs'] = 30
#+end_src

#+RESULTS:

#+begin_src ipython
def overlaps_scorer(estimator, X_test, y_test, IF_SIGN=0):
    coef = estimator.named_steps["net"].coef_.flatten()
    if IF_SIGN:
        dot_product = (2*y_test -1) * np.dot(X_test, coef) / np.linalg.norm(coef)
    else:
        dot_product = -np.dot(X_test, coef) / np.linalg.norm(coef)

    return dot_product.mean()


options['scoring'] = overlaps_scorer
# options['hp_scoring'] = 'overlaps_scorer'
#+end_src

#+RESULTS:

#+begin_src ipython
def signed_overlaps_scorer(estimator, X_test, y_test, IF_SIGN=1):
    coef = estimator.named_steps["net"].coef_.flatten()
    if IF_SIGN:
        dot_product = (2*y_test -1) * np.dot(X_test, coef) / np.linalg.norm(coef)
    else:
        dot_product = -np.dot(X_test, coef) / np.linalg.norm(coef)

    return dot_product.mean()


options['scoring'] = overlaps_scorer
# options['hp_scoring'] = 'overlaps_scorer'
#+end_src

#+RESULTS:

* Plots

#+begin_src ipython
def significance_marker(p):
    if p < 0.001:
        return '***'
    elif p < 0.01:
        return '**'
    elif p < 0.05:
        return '*'
    elif p <.1:
        return '.'
    else:
        return ''
#+end_src

#+RESULTS:

#+begin_src ipython
import rpy2.robjects as robjects
from rpy2.robjects.packages import importr

# Set the .libPaths in R
custom_r_libpath = '~/R/x86_64-pc-linux-gnu-library/4.3/'
robjects.r('.libPaths("{0}")'.format(custom_r_libpath))

from pymer4.models import Lmer
#+end_src

#+RESULTS:
: Warning message:
: package ‘methods’ was built under R version 4.3.3
: During startup - Warning messages:
: 1: package ‘datasets’ was built under R version 4.3.3
: 2: package ‘utils’ was built under R version 4.3.3
: 3: package ‘grDevices’ was built under R version 4.3.3
: 4: package ‘graphics’ was built under R version 4.3.3
: 5: package ‘stats’ was built under R version 4.3.3

#+begin_src ipython
def plot_overlaps(df, day, epoch, ax, n_boots=1000):
    df_ = df[df.day == day].copy()
    colors = ['r', 'b', 'g']
    time_points = np.linspace(0, 14, 84)

    mean_overlaps = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: np.mean(np.stack(x), axis=0))
    lower_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, n_boots, 0))
    upper_cis = df_.groupby('tasks')['overlaps_%s' % epoch].apply(lambda x: bootstrap_ci_per_task(x, n_boots, 1))

    for i, task in enumerate(mean_overlaps.index):
        ax.plot(time_points, mean_overlaps[task], label=f"Day {task}", color=colors[i])
        ax.fill_between(time_points, lower_cis[task], upper_cis[task], color=colors[i], alpha=0.1)

    ax.set_xlabel('Time (s)')
    ax.set_ylabel('Overlap')
    add_vlines(ax)

def bootstrap_ci_per_task(x, n_bootstrap, ci_idx):
    stacked = np.stack(x)
    return np.array([bootstrap_ci(stacked[:, i], n_bootstrap)[ci_idx] for i in range(stacked.shape[1])])
#+end_src

#+RESULTS:

#+begin_src ipython
def bootstrap_ci(data, n_bootstrap=1000, ci=95):
    bootstrapped_means = np.array([np.mean(np.random.choice(data, size=len(data))) for _ in range(n_bootstrap)])
    lower_bound = np.percentile(bootstrapped_means, (100-ci)/2)
    upper_bound = np.percentile(bootstrapped_means, 100 - (100-ci)/2)
    return lower_bound, upper_bound
#+end_src

#+RESULTS:

* Data
** Sample
#+begin_src ipython
name = 'df_sample_overlaps'
df_sample = pkl_load(name, path="../data/mice/overlaps")
#+end_src

#+RESULTS:
: loading from ../data/mice/overlaps/df_sample_overlaps.pkl

 #+begin_src ipython
df_sample['overlaps_diag'] = df_sample['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
#+end_src

#+RESULTS:

 #+begin_src ipython
options['epochs'] = ['ED']
df_sample['overlaps_ED'] = df_sample['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src
#+RESULTS:

 #+begin_src ipython
options['epochs'] = ['MD']
df_sample['overlaps_MD'] = df_sample['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['LD']
df_sample['overlaps_ED_LD'] = df_sample['overlaps_ED'].apply(lambda x: avg_epochs(np.array(x), **options))
df_sample['overlaps_diag_LD'] = df_sample['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_sample['overlaps_MD_LD'] = df_sample['overlaps_MD'].apply(lambda x: avg_epochs(np.array(x), **options))
# print(df_sample.head())
#+end_src

#+RESULTS:

** Distractor

#+begin_src ipython
name = 'df_distractor_overlaps'
df_dist = pkl_load(name, path="../data/mice/overlaps")
#+end_src

#+RESULTS:
: loading from ../data/mice/overlaps/df_distractor_overlaps.pkl

#+begin_src ipython
df_dist['overlaps_diag'] = df_dist['overlaps'].apply(lambda x: np.diag(np.array(x).reshape(84, 84)))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['MD']
df_dist['overlaps_MD'] = df_dist['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['DIST']
df_dist['overlaps_DIST'] = df_dist['overlaps'].apply(lambda x: avg_epochs(np.array(x).reshape(84, 84).T, **options))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['ED']
df_dist['overlaps_MD_ED'] = df_dist['overlaps_MD'].apply(lambda x: avg_epochs(np.array(x), **options))
df_dist['overlaps_diag_ED'] = df_dist['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_dist['sign_overlaps_MD_ED'] = df_dist['overlaps_MD'].apply(lambda x: np.sign(avg_epochs(np.array(x), **options)))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['MD']
df_dist['overlaps_MD_MD'] = df_dist['overlaps_MD'].apply(lambda x: avg_epochs(np.array(x), **options))
df_dist['overlaps_diag_MD'] = df_dist['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_dist['sign_overlaps_MD_MD'] = df_dist['overlaps_MD'].apply(lambda x: np.sign(avg_epochs(np.array(x), **options)))
#+end_src

#+RESULTS:

#+begin_src ipython
options['epochs'] = ['LD']
df_dist['overlaps_MD_LD'] = df_dist['overlaps_MD'].apply(lambda x: avg_epochs(np.array(x), **options))
df_dist['overlaps_diag_LD'] = df_dist['overlaps_diag'].apply(lambda x: avg_epochs(np.array(x), **options))
df_dist['sign_overlaps_MD_LD'] = df_dist['overlaps_MD'].apply(lambda x: np.sign(avg_epochs(np.array(x), **options)))
#+end_src

#+RESULTS:

** Performance and overlaps

#+begin_src ipython
import seaborn as sns

df = df_sample.copy()
df = df[df.mouse != 'JawsM18']
# df = df[df.mouse != 'ACCM04']

fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(3*width, height), sharex=True, sharey=False)
sns.lineplot(data=df, x='day', y='performance', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'], ax=ax[0])
ax[0].set_xlabel('Day')
ax[0].set_ylabel('Performance')

sns.lineplot(data=df, x='day', y='overlaps_ED_LD', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'], ax=ax[1])
ax[1].set_xlabel('Day')
ax[1].set_ylabel('Sample Overlap')

df = df_dist.copy()
df = df[df.mouse != 'JawsM18']
# df = df[df.mouse != 'ACCM04']

sns.lineplot(data=df, x='day', y='overlaps_MD_ED', hue='tasks', marker='o', legend=0, palette=['r', 'b', 'g'], ax=ax[2])
ax[2].set_xlabel('Day')
ax[2].set_ylabel('Dist. Overlap')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_27.png]]

#+begin_src ipython
fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(3*width, 2*height))

df = df_sample.copy()
df = df[df.mouse != 'JawsM18']

plot_overlaps(df, 'first', 'ED', ax[0][0])
plot_overlaps(df, 'middle', 'ED', ax[0][1])
plot_overlaps(df, 'last', 'ED', ax[0][2])

df = df_dist.copy()
df = df[df.mouse != 'JawsM18']

plot_overlaps(df, 'first', 'MD', ax[1][0])
plot_overlaps(df, 'middle', 'MD', ax[1][1])
plot_overlaps(df, 'last', 'MD', ax[1][2])

ax[1][2].legend(fontsize=10)

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_28.png]]

** GLMs
*** Performance ~ day * tasks

#+begin_src ipython
  formula = 'performance ~ day * tasks + (day + tasks | mouse)'
  data = df_sample.copy()
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  # data = data[data.mouse !='ChRM04']

  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Model failed to converge with max|grad| = 0.00584566 (tol = 0.002, component 1)

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~day*tasks+(day+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3072	 Groups: {'mouse': 4.0}

Log-likelihood: -1600.476 	 AIC: 3248.952

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.202  0.449
mouse        daylast  0.331  0.576
mouse      daymiddle  0.140  0.374
mouse    tasksDualGo  0.112  0.335
mouse  tasksDualNoGo  0.013  0.115

               IV1            IV2   Corr
mouse  (Intercept)        daylast -0.359
mouse  (Intercept)      daymiddle  0.819
mouse  (Intercept)    tasksDualGo -0.371
mouse  (Intercept)  tasksDualNoGo -0.857
mouse      daylast      daymiddle  0.236
mouse      daylast    tasksDualGo -0.556
mouse      daylast  tasksDualNoGo -0.073
mouse    daymiddle    tasksDualGo -0.771
mouse    daymiddle  tasksDualNoGo -0.960
mouse  tasksDualGo  tasksDualNoGo  0.796

Fixed effects:

                         Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
(Intercept)                 0.642   0.147    1.137  0.253  1.900      1.158
daylast                     1.546   0.814    2.277  0.373  4.691      2.258
daymiddle                   1.286   0.760    1.812  0.268  3.619      2.139
tasksDualGo                -0.242  -0.694    0.211  0.231  0.785      0.500
tasksDualNoGo               0.002  -0.331    0.335  0.170  1.002      0.719
daylast:tasksDualGo        -0.121  -0.738    0.496  0.315  0.886      0.478
daymiddle:tasksDualGo      -0.399  -0.871    0.073  0.241  0.671      0.419
daylast:tasksDualNoGo      -0.355  -0.969    0.260  0.313  0.701      0.379
daymiddle:tasksDualNoGo    -0.154  -0.644    0.336  0.250  0.857      0.525

                         OR_97.5_ci   Prob  Prob_2.5_ci  Prob_97.5_ci  Z-stat  \
(Intercept)                   3.117  0.655        0.537         0.757   2.540
daylast                       9.746  0.824        0.693         0.907   4.143
daymiddle                     6.125  0.784        0.681         0.860   4.792
tasksDualGo                   1.235  0.440        0.333         0.552  -1.047
tasksDualNoGo                 1.398  0.501        0.418         0.583   0.012
daylast:tasksDualGo           1.641  0.470        0.323         0.621  -0.386
daymiddle:tasksDualGo         1.076  0.402        0.295         0.518  -1.656
daylast:tasksDualNoGo         1.296  0.412        0.275         0.565  -1.132
daymiddle:tasksDualNoGo       1.400  0.462        0.344         0.583  -0.616

                         P-val  Sig
(Intercept)              0.011    *
daylast                  0.000  ***
daymiddle                0.000  ***
tasksDualGo              0.295
tasksDualNoGo            0.990
daylast:tasksDualGo      0.700
daymiddle:tasksDualGo    0.098    .
daylast:tasksDualNoGo    0.258
daymiddle:tasksDualNoGo  0.538
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)


df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_30.png]]

*** Performance ~ sample overlaps * days

#+begin_src ipython
  formula = 'performance ~ day * overlaps_ED_LD  + (1 + day + tasks | mouse)'

  data = df_sample.copy()
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  # data = data[data.mouse !='ChRM04']

  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
#+begin_example
Model failed to converge with max|grad| = 0.00638875 (tol = 0.002, component 1)

Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: performance~day*overlaps_ED_LD+(1+day+tasks|mouse)

Family: binomial	 Inference: parametric

Number of observations: 3072	 Groups: {'mouse': 4.0}

Log-likelihood: -1602.801 	 AIC: 3247.601

Random effects:

                Name    Var    Std
mouse    (Intercept)  0.181  0.425
mouse        daylast  0.365  0.604
mouse      daymiddle  0.173  0.416
mouse    tasksDualGo  0.232  0.482
mouse  tasksDualNoGo  0.016  0.125

               IV1            IV2   Corr
mouse  (Intercept)        daylast -0.300
mouse  (Intercept)      daymiddle  0.795
mouse  (Intercept)    tasksDualGo -0.226
mouse  (Intercept)  tasksDualNoGo -0.768
mouse      daylast      daymiddle  0.338
mouse      daylast    tasksDualGo -0.708
mouse      daylast  tasksDualNoGo -0.227
mouse    daymiddle    tasksDualGo -0.699
mouse    daymiddle  tasksDualNoGo -0.923
mouse  tasksDualGo  tasksDualNoGo  0.792

Fixed effects:

                          Estimate  2.5_ci  97.5_ci     SE     OR  OR_2.5_ci  \
(Intercept)                  0.617   0.091    1.143  0.268  1.853      1.096
daylast                      1.047   0.387    1.707  0.337  2.849      1.473
daymiddle                    0.922   0.370    1.474  0.282  2.514      1.448
overlaps_ED_LD               0.036  -0.187    0.260  0.114  1.037      0.829
daylast:overlaps_ED_LD       0.275  -0.186    0.737  0.235  1.317      0.830
daymiddle:overlaps_ED_LD    -0.087  -0.475    0.300  0.198  0.916      0.622

                          OR_97.5_ci   Prob  Prob_2.5_ci  Prob_97.5_ci  \
(Intercept)                    3.135  0.650        0.523         0.758
daylast                        5.512  0.740        0.596         0.846
daymiddle                      4.367  0.715        0.591         0.814
overlaps_ED_LD                 1.296  0.509        0.453         0.565
daylast:overlaps_ED_LD         2.089  0.568        0.454         0.676
daymiddle:overlaps_ED_LD       1.350  0.478        0.383         0.575

                          Z-stat  P-val Sig
(Intercept)                2.300  0.021   *
daylast                    3.110  0.002  **
daymiddle                  3.273  0.001  **
overlaps_ED_LD             0.317  0.751
daylast:overlaps_ED_LD     1.171  0.242
daymiddle:overlaps_ED_LD  -0.442  0.659
#+end_example

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_32.png]]

*** Performance ~ distractor overlaps * days

#+begin_src ipython
  formula = 'performance ~ day * overlaps_MD_ED  + (1 + day + tasks| mouse)'

  data = df_dist.copy()
  data = data[data.mouse!='JawsM18']
  # data = data[data.mouse !='ACCM04']
  # data = data[data.mouse !='ChRM04']

  glm = Lmer(formula=formula, data=data, family='binomial')
  result = glm.fit()
  print(result)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
RRuntimeError                             Traceback (most recent call last)
Cell In[123], line 9
      5 # data = data[data.mouse !='ACCM04']
      6 # data = data[data.mouse !='ChRM04']
      8 glm = Lmer(formula=formula, data=data, family='binomial')
----> 9 result = glm.fit()
     10 print(result)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/pymer4/models/Lmer.py:440, in Lmer.fit(self, conf_int, n_boot, factors, permute, ordered, verbose, REML, rank, rank_group, rank_exclude_cols, no_warnings, control, old_optimizer, **kwargs)
    438         _fam = self.family
    439     lmc = robjects.r(f"glmerControl({control})")
--> 440     self.model_obj = lmer.glmer(
    441         self.formula,
    442         data=data,
    443         family=_fam,
    444         control=lmc,
    445         contrasts=contrasts,
    446     )
    448 # Store design matrix and get number of IVs for inference
    449 design_matrix = stats.model_matrix(self.model_obj)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:208, in SignatureTranslatedFunction.__call__(self, *args, **kwargs)
    206         v = kwargs.pop(k)
    207         kwargs[r_k] = v
--> 208 return (super(SignatureTranslatedFunction, self)
    209         .__call__(*args, **kwargs))

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/robjects/functions.py:131, in Function.__call__(self, *args, **kwargs)
    129     else:
    130         new_kwargs[k] = cv.py2rpy(v)
--> 131 res = super(Function, self).__call__(*new_args, **new_kwargs)
    132 res = cv.rpy2py(res)
    133 return res

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/rinterface_lib/conversion.py:45, in _cdata_res_to_rinterface.<locals>._(*args, **kwargs)
     44 def _(*args, **kwargs):
---> 45     cdata = function(*args, **kwargs)
     46     # TODO: test cdata is of the expected CType
     47     return _cdata_to_rinterface(cdata)

File ~/mambaforge/envs/dual_data/lib/python3.11/site-packages/rpy2/rinterface.py:817, in SexpClosure.__call__(self, *args, **kwargs)
    810     res = rmemory.protect(
    811         openrlib.rlib.R_tryEval(
    812             call_r,
    813             call_context.__sexp__._cdata,
    814             error_occured)
    815     )
    816     if error_occured[0]:
--> 817         raise embedded.RRuntimeError(_rinterface._geterrmessage())
    818 return res

RRuntimeError: Error in eval(predvars, data, env) : object 'task' not found
#+end_example
:END:

#+begin_src ipython
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Assuming you already have model and glm.coef()
coefficients = {
    'coef': glm.coefs['Estimate'],
    'lower_ci': glm.coefs['2.5_ci'],
    'upper_ci': glm.coefs['97.5_ci'],
    'p_value': glm.coefs['P-val']
}

df_coefs = pd.DataFrame(coefficients)

df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

#  Plot coefficients with error bars and significance markers
plt.figure(figsize=(10, 6))
plt.errorbar(df_coefs.index, df_coefs['coef'], yerr=[df_coefs['coef'] - df_coefs['lower_ci'], df_coefs['upper_ci'] - df_coefs['coef']], fmt='o')
plt.axhline(y=0, color='grey', linestyle='--')
plt.xlabel('Coefficient')
plt.ylabel('Estimate')
# plt.title('Coefficient Estimates with 95% Confidence Intervals')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Add significance markers
for i, (coef, marker) in enumerate(zip(df_coefs['coef'], df_coefs['marker'])):
    plt.text(i, coef+1, f'{marker}', fontsize=22, ha='center', va='bottom')

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[124], line 7
      3 import numpy as np
      5 # Assuming you already have model and glm.coef()
      6 coefficients = {
----> 7     'coef': glm.coefs['Estimate'],
      8     'lower_ci': glm.coefs['2.5_ci'],
      9     'upper_ci': glm.coefs['97.5_ci'],
     10     'p_value': glm.coefs['P-val']
     11 }
     13 df_coefs = pd.DataFrame(coefficients)
     15 df_coefs['marker'] = df_coefs['p_value'].apply(significance_marker)

TypeError: 'NoneType' object is not subscriptable
#+end_example
:END:

*** Performance ~ sign distractor overlaps

#+begin_src ipython
df_dist['sign_overlaps_MD_ED'] = df_dist['overlaps_MD_ED'].apply(lambda x: (np.sign(x) + 1 ) / 2)
print(df_dist.sign_overlaps_MD_ED.unique())
formula = 'performance ~ day * sign_overlaps_MD_ED + ( 1 + day | mouse)'
data = df_dist[['overlaps_MD_ED', 'sign_overlaps_MD_ED', 'performance', 'mouse', 'day']]
data = data[data.mouse != 'JawsM18']
#+end_src

#+RESULTS:
: [0. 1.]

#+begin_src ipython
from rpy2.robjects import r
from rpy2.robjects.packages import importr
from rpy2.robjects import pandas2ri
pandas2ri.activate()

lme4 = importr('lme4')

# Convert dataframe to R dataframe
r_dataframe = pandas2ri.py2rpy(data)

# Fit the model
formula = 'performance ~ day * sign_overlaps_MD_ED + (1 + day| mouse)'
glm = lme4.glmer(formula, data=r_dataframe, family='binomial') ;
#+end_src

#+RESULTS:

#+begin_src ipython
summary = ro.r.summary(glm)
print(summary)
#+end_src

#+RESULTS:

#+begin_src ipython
labels = ['(Intercept)',
    'daylast',
    'daymiddle',
    'sign_overlaps_MD_ED',
    'daylast:sign_overlaps_MD_ED',
    'daymiddle:sign_overlaps_MD_ED']
#+end_src

#+RESULTS:

#+begin_src ipython
import numpy as np
import matplotlib.pyplot as plt
from rpy2.robjects import pandas2ri
import rpy2.robjects as ro

pandas2ri.activate()

# Extract model summary
summary = ro.r.summary(glm)
coefs = np.array(summary.rx2('coefficients'))

# Extract coefficient estimates and confidence intervals
estimates = coefs[:,0]
stderr = coefs[:,1]
p_values = coefs[:, 3]
ci_low = estimates - 1.96 * stderr
ci_high = estimates + 1.96 * stderr

# Labels for the coefficients
# labels = summary.rx2('coefficients').rownames

# Plotting
plt.figure(figsize=(8, 6))
plt.errorbar(range(len(estimates)), estimates, yerr=[estimates - ci_low, ci_high - estimates], fmt='o')
plt.axhline(0, color='gray', linestyle='--')
plt.xticks(np.arange(len(labels)), labels, rotation=45, ha='right', fontsize=10)
plt.xlabel('Coefficients')
plt.ylabel('Estimate')
# plt.title('Coefficients with 95% Confidence Intervals')
for i, (est, ci_l, ci_h, p) in enumerate(zip(estimates, ci_low, ci_high, p_values)):
    significance = significance_marker(p)
    plt.text(i, ci_h + 0.05, significance, ha='center', va='bottom', color='red', fontsize=20)

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[./figures/overlaps/figure_39.png]]
